import sys
from pathlib import Path
BASE_DIR = Path(__file__).resolve().parents[1]
if str(BASE_DIR) not in sys.path:
    # Ensure our project root takes precedence so we import the local utils module
    # instead of any similarly named third-party package that might exist.
    sys.path.insert(0, str(BASE_DIR))

from io import BytesIO

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from urllib.parse import urlencode
from datetime import date, datetime

from utils import (
    compute_results,
    detect_quality_issues,
    detect_anomalies,
    summarize_segment_performance,
)
from standard_rate_core import DEFAULT_PARAMS, sanitize_params, compute_rates
from components import (
    apply_user_theme,
    get_active_theme_palette,
    render_help_button,
    render_onboarding,
    render_page_tutorial,
    render_stepper,
    render_sidebar_nav,
)
from offline import restore_session_state_from_cache, sync_offline_cache
import os
from typing import Dict, Any, List, Optional, Tuple

from reportlab.lib import colors
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle

from openai import OpenAI

PASTEL_PALETTE = [
    "#2F6776",
    "#79A3B1",
    "#F2C57C",
    "#9BC0A0",
    "#DDA0BC",
    "#AEC9EB",
]
PASTEL_ACCENT = "#2F6776"
PASTEL_BG = "#F4F7FA"
_PASTEL_THEME_NAME = "pastel_mck"
_PASTEL_THEME_CONFIG = {
    "config": {
        "background": PASTEL_BG,
        "view": {"stroke": "transparent"},
        "range": {"category": PASTEL_PALETTE},
        "title": {"color": "#1F2A44"},
        "axis": {
            "titleColor": "#1F2A44",
            "labelColor": "#30405B",
            "gridColor": "#D7E2EA",
        },
        "legend": {"labelColor": "#30405B", "titleColor": "#1F2A44"},
    }
}

_palette = get_active_theme_palette()
PASTEL_BG = _palette["surface"]
PASTEL_ACCENT = _palette["accent"]
_PASTEL_THEME_CONFIG["config"]["background"] = PASTEL_BG
_PASTEL_THEME_CONFIG["config"]["title"]["color"] = _palette["text"]
_PASTEL_THEME_CONFIG["config"]["axis"]["titleColor"] = _palette["text"]
_PASTEL_THEME_CONFIG["config"]["axis"]["labelColor"] = _palette["text"]
_PASTEL_THEME_CONFIG["config"]["axis"]["gridColor"] = _palette["border"]
_PASTEL_THEME_CONFIG["config"]["legend"]["labelColor"] = _palette["text"]
_PASTEL_THEME_CONFIG["config"]["legend"]["titleColor"] = _palette["text"]


apply_user_theme()

restore_session_state_from_cache()


def _register_pastel_theme() -> None:
    """Register and enable the custom Altair theme across Altair versions."""

    try:
        theme_api = alt.theme
        if _PASTEL_THEME_NAME not in theme_api.names():

            @theme_api.register(_PASTEL_THEME_NAME, enable=False)
            def _pastel_theme():
                return _PASTEL_THEME_CONFIG

        theme_api.enable(_PASTEL_THEME_NAME)
    except (AttributeError, TypeError):
        if _PASTEL_THEME_NAME not in alt.themes.names():
            alt.themes.register(_PASTEL_THEME_NAME, _PASTEL_THEME_CONFIG)
        alt.themes.enable(_PASTEL_THEME_NAME)


_register_pastel_theme()

METRIC_LABELS = {
    "actual_unit_price": "å®Ÿéš›å£²å˜ä¾¡",
    "material_unit_cost": "ææ–™åŸä¾¡",
    "minutes_per_unit": "åˆ†/å€‹",
    "daily_qty": "æ—¥ç”£æ•°",
    "va_per_min": "ä»˜åŠ ä¾¡å€¤/åˆ†",
    "rate_gap_vs_required": "å¿…è¦è³ƒç‡å·®",
    "required_selling_price": "å¿…è¦è²©å£²å˜ä¾¡",
}

ANOMALY_REVIEW_CHOICES: List[Dict[str, Any]] = [
    {
        "key": "exception",
        "label": "ä¾‹å¤–çš„ãªå€¤ã¨ã—ã¦è¨±å®¹",
        "description": "å•†æµã®æ€¥å¤‰ã‚„å­£ç¯€è¦å› ãªã©æ­£å½“ãªç†ç”±ãŒã‚ã‚‹ç•°å¸¸å€¤ã¨ã—ã¦æ‰±ã„ã¾ã™ã€‚",
        "requires_value": False,
    },
    {
        "key": "input_error",
        "label": "èª¤å…¥åŠ›ã¨ã—ã¦ä¿®æ­£",
        "description": "å…¥åŠ›ãƒŸã‚¹ã¨åˆ¤æ–­ã—è¨‚æ­£å€¤ã‚’ç™»éŒ²ã—ã¾ã™ã€‚ä¿å­˜ã™ã‚‹ã¨å³æ™‚ã«ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã¸åæ˜ ã•ã‚Œã¾ã™ã€‚",
        "requires_value": True,
    },
    {
        "key": "monitor",
        "label": "è¦èª¿æŸ»ã¨ã—ã¦è¨˜éŒ²",
        "description": "åŸå› èª¿æŸ»ä¸­ã®ç•°å¸¸å€¤ã¨ã—ã¦æ‰±ã„ã€ãƒ¡ãƒ¢ã ã‘æ®‹ã—ã¦ãŠãã¾ã™ã€‚",
        "requires_value": False,
    },
]

ANOMALY_REVIEW_LABELS: Dict[str, str] = {
    choice["key"]: choice["label"] for choice in ANOMALY_REVIEW_CHOICES
}
ANOMALY_REVIEW_DESCRIPTIONS: Dict[str, str] = {
    choice["key"]: choice.get("description", "") for choice in ANOMALY_REVIEW_CHOICES
}
ANOMALY_REVIEW_REQUIRES_VALUE: Dict[str, bool] = {
    choice["key"]: bool(choice.get("requires_value")) for choice in ANOMALY_REVIEW_CHOICES
}
ANOMALY_REVIEW_UNSET_LABEL = "æœªåˆ†é¡"


def _normalize_review_classification(record: Optional[Dict[str, Any]]) -> Optional[str]:
    """Resolve the stored review classification from legacy or new schema."""

    if not record:
        return None
    classification = record.get("classification")
    if classification:
        return classification
    decision = record.get("decision")
    if decision == "corrected":
        return "input_error"
    return decision

st.markdown(
    """
    <style>
    .main > div {
        background-color: var(--app-bg);
    }
    [data-testid="stMetric"] {
        background-color: var(--app-surface);
        border-radius: 18px;
        border: 1px solid var(--app-border);
        padding: 12px 16px;
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.06);
        color: var(--app-text);
    }
    [data-testid="stMetricDelta"] span {
        font-weight: 600;
    }
    .metric-badge {
        text-align: right;
        color: var(--app-accent);
        font-weight: 600;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


def _apply_plotly_theme(fig: go.Figure, *, show_spikelines: bool = False, legend_bottom: bool = False) -> go.Figure:
    """Apply a consistent pastel style across plotly figures."""

    legend_conf = dict(
        orientation="h",
        yanchor="bottom",
        y=1.02,
        xanchor="right",
        x=1.0,
        bgcolor=_palette["surface"],
        bordercolor=_palette["border"],
        borderwidth=1,
    )
    if legend_bottom:
        legend_conf.update({"y": -0.2, "x": 0.5, "xanchor": "center"})

    fig.update_layout(
        plot_bgcolor=PASTEL_BG,
        paper_bgcolor=PASTEL_BG,
        font=dict(color=_palette["text"]),
        legend=legend_conf,
        margin=dict(l=40, r=30, t=60, b=60),
    )
    if show_spikelines:
        fig.update_layout(
            hovermode="x unified",
            xaxis=dict(showspikes=True, spikethickness=1, spikedash="dot"),
        )
        if "yaxis" in fig.layout:
            fig.update_layout(yaxis=dict(showspikes=True, spikethickness=1, spikedash="dot"))
    else:
        fig.update_layout(hovermode="closest")
    return fig


def _build_plotly_config() -> Dict[str, Any]:
    draw_tools = st.session_state.get(
        "plotly_draw_tools",
        ["drawline", "drawrect", "drawopenpath", "drawcircle", "eraseshape"],
    )
    return {
        "displaylogo": False,
        "responsive": True,
        "scrollZoom": True,
        "modeBarButtonsToAdd": draw_tools,
        "toImageButtonOptions": {"format": "png", "scale": 2},
    }


def _normalize_month(value: Any) -> Optional[pd.Timestamp]:
    """Convert arbitrary date-like input to the first day of its month."""

    if value is None:
        return None
    if isinstance(value, pd.Timestamp):
        ts = value
    elif isinstance(value, (datetime, date)):
        ts = pd.Timestamp(value)
    else:
        try:
            ts = pd.to_datetime(value)
        except Exception:
            return None
    if pd.isna(ts):
        return None
    return ts.to_period("M").to_timestamp()


def _pct_change(previous: float, current: float) -> float:
    """Compute percentage change while guarding against invalid denominators."""

    if previous in (None, 0) or pd.isna(previous):
        return np.nan
    if current in (None,) or pd.isna(current):
        return np.nan
    return (current / previous - 1.0) * 100.0


def _determine_pdca_comment(
    *, required_rate: float, va_per_min: float, delta_va: float, delta_ach: float
) -> str:
    """Generate a PDCA oriented commentary for KPI trend tracking."""

    tol = 0.05  # 5éŠ­å˜ä½ã®å¾®ç´°ãªå¤‰åŒ–ã¯ãƒã‚¤ã‚ºã¨ã—ã¦æ‰±ã†
    if pd.isna(va_per_min) or pd.isna(required_rate):
        return "Plan: KPIãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚åŸºæº–å€¤ã®å†ç¢ºèªãŒå¿…è¦ã§ã™ã€‚"

    gap = va_per_min - required_rate
    improving = np.isfinite(delta_va) and delta_va > tol
    worsening = np.isfinite(delta_va) and delta_va < -tol

    if gap >= tol:
        if improving:
            return "Act: å¿…è¦è³ƒç‡è¶…éå¹…ãŒåºƒãŒã£ã¦ãŠã‚Šæ”¹å–„ã‚’å®šç€ã•ã›ã¦ã„ã¾ã™ã€‚"
        return "Act: å¿…è¦è³ƒç‡ã‚’ä¸Šå›ã£ã¦ãŠã‚Šç¾çŠ¶ç¶­æŒãƒ•ã‚§ãƒ¼ã‚ºã§ã™ã€‚"

    if gap <= -tol:
        if improving:
            return "Check: ã¾ã æœªé”ã§ã™ãŒæ”¹å–„å‚¾å‘ã‚’ç¢ºèªã§ãã¾ã—ãŸã€‚"
        return "Do: å¿…è¦è³ƒç‡ã‚’ä¸‹å›ã£ã¦ã„ã‚‹ãŸã‚è¿½åŠ æ–½ç­–ã®å®Ÿè¡ŒãŒå¿…è¦ã§ã™ã€‚"

    if improving:
        return "Check: åŸºæº–ä»˜è¿‘ã§æ”¹å–„ãŒé€²ã‚“ã§ã„ã¾ã™ã€‚"
    if worsening:
        return "Do: åŸºæº–ä»˜è¿‘ã§ã™ãŒæ‚ªåŒ–å‚¾å‘ã®ãŸã‚æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚"

    if np.isfinite(delta_ach) and abs(delta_ach) > 0.2:
        if delta_ach > 0:
            return "Check: é”æˆç‡ãŒä¸Šæ˜‡ã—ã¦ãŠã‚Šæ–½ç­–åŠ¹æœã‚’ç¢ºèªã§ãã¦ã„ã¾ã™ã€‚"
        return "Do: é”æˆç‡ãŒä½ä¸‹ã—ã¦ã„ã‚‹ãŸã‚åŸå› åˆ†æãŒæ±‚ã‚ã‚‰ã‚Œã¾ã™ã€‚"

    return "Plan: å¤§ããªå¤‰åŒ–ã¯ãªãåŸºæº–æ°´æº–ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚"


def _build_pdca_summary(trend_df: pd.DataFrame) -> pd.DataFrame:
    """Build PDCA commentary rows for each scenario-period combination."""

    columns = [
        "scenario",
        "period",
        "required_rate",
        "va_per_min",
        "ach_rate",
        "delta_va",
        "delta_ach",
        "pdca_comment",
    ]
    if trend_df is None or trend_df.empty:
        return pd.DataFrame(columns=columns)

    df = trend_df.copy()
    df["period"] = pd.to_datetime(df["period"])
    df = df.dropna(subset=["period"])
    if df.empty:
        return pd.DataFrame(columns=columns)

    records: List[Dict[str, Any]] = []
    for scenario, group in df.groupby("scenario"):
        g = group.sort_values("period")
        prev_va = np.nan
        prev_ach = np.nan
        for _, row in g.iterrows():
            va = float(row.get("va_per_min", np.nan))
            req = float(row.get("required_rate", np.nan))
            ach = float(row.get("ach_rate", np.nan))
            delta_va = (
                va - prev_va
                if np.isfinite(va) and np.isfinite(prev_va)
                else np.nan
            )
            delta_ach = (
                ach - prev_ach
                if np.isfinite(ach) and np.isfinite(prev_ach)
                else np.nan
            )
            comment = _determine_pdca_comment(
                required_rate=req,
                va_per_min=va,
                delta_va=delta_va,
                delta_ach=delta_ach,
            )
            records.append(
                {
                    "scenario": scenario,
                    "period": row["period"],
                    "required_rate": req,
                    "va_per_min": va,
                    "ach_rate": ach,
                    "delta_va": delta_va,
                    "delta_ach": delta_ach,
                    "pdca_comment": comment,
                }
            )
            prev_va = va if np.isfinite(va) else prev_va
            prev_ach = ach if np.isfinite(ach) else prev_ach

    return pd.DataFrame(records, columns=columns)


def _sku_to_str(value: Any) -> str:
    """Normalize product numbers for consistent dictionary keys."""

    if value is None or (isinstance(value, float) and np.isnan(value)):
        return "nan"
    if isinstance(value, (int, np.integer)):
        return str(int(value))
    if isinstance(value, float) and float(value).is_integer():
        return str(int(value))
    return str(value)


def _format_number(value: Any) -> str:
    """Format numeric values for concise display in anomaly prompts."""

    if value is None or pd.isna(value):
        return "N/A"
    val = float(value)
    if abs(val) >= 1000:
        return f"{val:,.0f}"
    return f"{val:,.2f}"


def _format_currency(value: Any, unit: str = "å††", decimals: int = 0) -> str:
    """Format numeric values as currency text with thousands separators."""

    if value is None or pd.isna(value):
        return "N/A"
    try:
        val = float(value)
    except (TypeError, ValueError):
        return "N/A"
    fmt = f"{{:,.{decimals}f}}" if decimals > 0 else "{:,}"  # type: ignore[str-format]
    return f"{fmt.format(val)}{unit}"


def _format_roi(value: Any) -> str:
    """Format ROI months with guard for non-finite numbers."""

    if value is None or pd.isna(value):
        return "N/A"
    try:
        val = float(value)
    except (TypeError, ValueError):
        return "N/A"
    if not np.isfinite(val):
        return "âˆ"
    return f"{val:.1f}"


def _format_delta(value: float, suffix: str) -> str:
    """Format change metrics with sign and suffix, handling NaN gracefully."""

    if value is None or pd.isna(value) or not np.isfinite(value):
        return "N/A"
    return f"{value:+.1f}{suffix}"


SIMULATION_PRESETS: Dict[str, Dict[str, Any]] = {
    "è²©å£²ä¾¡æ ¼+5%": {
        "adjustments": {
            "quick_price": 5,
            "quick_ct": 0,
            "quick_material": 0,
            "quick_volume": 0,
        },
        "description": "ã™ã¹ã¦ã®è£½å“ã§è²©å£²å˜ä¾¡ã‚’ä¸€å¾‹5%å¼•ãä¸Šã’ã‚‹ã‚±ãƒ¼ã‚¹",
    },
    "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ -10%": {
        "adjustments": {
            "quick_price": 0,
            "quick_ct": -10,
            "quick_material": 0,
            "quick_volume": 0,
        },
        "description": "1è£½å“å½“ãŸã‚Šã®è£½é€ æ™‚é–“ï¼ˆåˆ†/å€‹ï¼‰ã‚’10%åœ§ç¸®ã™ã‚‹ã‚±ãƒ¼ã‚¹",
    },
    "ææ–™è²»-3%": {
        "adjustments": {
            "quick_price": 0,
            "quick_ct": 0,
            "quick_material": -3,
            "quick_volume": 0,
        },
        "description": "åŸææ–™ã‚³ã‚¹ãƒˆã‚’å¹³å‡ã§3%å‰Šæ¸›ã™ã‚‹ã‚±ãƒ¼ã‚¹",
    },
    "å¢—ç”£+15%": {
        "adjustments": {
            "quick_price": 0,
            "quick_ct": 0,
            "quick_material": 0,
            "quick_volume": 15,
        },
        "description": "æ—¥ç”£æ•°ã‚’15%æ‹¡å¤§ã™ã‚‹ã‚±ãƒ¼ã‚¹",
    },
}


def apply_simulation_preset(label: str) -> None:
    """Apply predefined what-if adjustments to quick simulation controls."""

    preset = SIMULATION_PRESETS.get(label)
    if not preset:
        return
    adjustments = preset.get("adjustments", {})
    for key, value in adjustments.items():
        st.session_state[key] = value
    st.session_state["active_simulation"] = label


def _detect_simulation_label(qp: int, qc: int, qm: int, qv: int) -> str:
    """Return a human friendly label for the current quick adjustments."""

    for label, preset in SIMULATION_PRESETS.items():
        adjustments = preset.get("adjustments", {})
        if (
            adjustments.get("quick_price", 0) == qp
            and adjustments.get("quick_ct", 0) == qc
            and adjustments.get("quick_material", 0) == qm
            and adjustments.get("quick_volume", 0) == qv
        ):
            return label
    if qp == 0 and qc == 0 and qm == 0 and qv == 0:
        return "ãƒ™ãƒ¼ã‚¹"
    return "ã‚«ã‚¹ã‚¿ãƒ è¨­å®š"


def _resolve_scenario_label(
    qp: int,
    qc: int,
    qm: int,
    qv: int,
    saved: Optional[Dict[str, Dict[str, Any]]],
) -> str:
    """Determine the most relevant scenario label for quick simulation values."""

    if saved:
        for name, config in saved.items():
            if (
                int(config.get("quick_price", 0)) == int(qp)
                and int(config.get("quick_ct", 0)) == int(qc)
                and int(config.get("quick_material", 0)) == int(qm)
                and int(config.get("quick_volume", 0)) == int(qv)
            ):
                return str(name)
    return _detect_simulation_label(qp, qc, qm, qv)


def _simulate_scenario(
    df_template: pd.DataFrame,
    *,
    price_pct: float,
    ct_pct: float,
    volume_pct: float,
    material_pct: float,
    be_rate: float,
    req_rate: float,
    delta_low: float,
    delta_high: float,
) -> Tuple[pd.DataFrame, Dict[str, float]]:
    """Apply percentage adjustments and compute KPI metrics for a scenario."""

    df_sim = df_template.copy()
    if price_pct:
        df_sim["actual_unit_price"] *= 1 + float(price_pct) / 100.0
    if ct_pct:
        df_sim["minutes_per_unit"] *= 1 + float(ct_pct) / 100.0
    if volume_pct:
        df_sim["daily_qty"] *= 1 + float(volume_pct) / 100.0
    if material_pct:
        df_sim["material_unit_cost"] *= 1 + float(material_pct) / 100.0

    df_sim["gp_per_unit"] = df_sim["actual_unit_price"] - df_sim["material_unit_cost"]
    df_sim["daily_total_minutes"] = df_sim["minutes_per_unit"] * df_sim["daily_qty"]
    df_sim["daily_va"] = df_sim["gp_per_unit"] * df_sim["daily_qty"]
    with np.errstate(divide="ignore", invalid="ignore"):
        df_sim["va_per_min"] = df_sim["daily_va"] / df_sim["daily_total_minutes"]

    df_result = compute_results(df_sim, be_rate, req_rate, delta_low, delta_high)
    if len(df_result) > 0:
        ach_rate = float(df_result["meets_required_rate"].mean() * 100.0)
    else:
        ach_rate = float("nan")

    avg_vapm = _safe_series_mean(df_result.get("va_per_min"))
    avg_gap = _safe_series_mean(df_result.get("rate_gap_vs_required"))
    avg_required_price = _safe_series_mean(df_result.get("required_selling_price"))

    if "daily_va" in df_result:
        daily_total = float(
            np.nansum(pd.to_numeric(df_result["daily_va"], errors="coerce"))
        )
    else:
        daily_total = float("nan")

    return df_result, {
        "ach_rate": ach_rate,
        "avg_vapm": float(avg_vapm) if np.isfinite(avg_vapm) else float("nan"),
        "daily_va_total": daily_total,
        "avg_gap": float(avg_gap) if np.isfinite(avg_gap) else float("nan"),
        "avg_required_price": float(avg_required_price)
        if np.isfinite(avg_required_price)
        else float("nan"),
    }


def _sanitize_metrics(metrics: Dict[str, float]) -> Dict[str, float]:
    """Normalize metric dictionary to safe numeric values for display."""

    ach = metrics.get("ach_rate", float("nan"))
    if not np.isfinite(ach):
        ach = 0.0
    avg = metrics.get("avg_vapm", float("nan"))
    if not np.isfinite(avg):
        avg = np.nan
    daily = metrics.get("daily_va_total", float("nan"))
    if not np.isfinite(daily):
        daily = np.nan
    avg_gap = metrics.get("avg_gap", float("nan"))
    if not np.isfinite(avg_gap):
        avg_gap = np.nan
    avg_required_price = metrics.get("avg_required_price", float("nan"))
    if not np.isfinite(avg_required_price):
        avg_required_price = np.nan
    return {
        "ach_rate": ach,
        "avg_vapm": avg,
        "daily_va_total": daily,
        "avg_gap": avg_gap,
        "avg_required_price": avg_required_price,
    }


def _format_adjustment_summary(adjustments: Dict[str, Any]) -> str:
    """Return a compact text description of percentage adjustments."""

    qp = int(adjustments.get("quick_price", 0))
    qc = int(adjustments.get("quick_ct", 0))
    qv = int(adjustments.get("quick_volume", 0))
    qm = int(adjustments.get("quick_material", 0))
    return f"ä¾¡æ ¼{qp:+d}%ãƒ»ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ {qc:+d}%ãƒ»ç”Ÿç”£é‡{qv:+d}%ãƒ»ææ–™{qm:+d}%"


def _summarize_scenario_effect(
    *,
    ach_delta: float,
    vapm_delta: float,
    daily_delta: float,
    annual_delta: float,
    req_price_delta: float,
    gap_delta: float,
) -> str:
    """Build a one-line summary describing KPI deltas for the active scenario."""

    pieces: List[str] = []
    if np.isfinite(ach_delta) and abs(ach_delta) >= 0.05:
        pieces.append(f"é”æˆç‡ {ach_delta:+.1f}pt")
    if np.isfinite(vapm_delta) and abs(vapm_delta) >= 0.01:
        pieces.append(f"å¹³å‡VA/åˆ† {vapm_delta:+.2f}å††")
    if np.isfinite(daily_delta) and abs(daily_delta) >= 100.0:
        pieces.append(f"æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤ {daily_delta:+,.0f}å††")
    if np.isfinite(annual_delta) and abs(annual_delta) >= 1000.0:
        pieces.append(f"å¹´é–“åˆ©ç›Š {annual_delta / 10000:+,.1f}ä¸‡å††")
    if np.isfinite(req_price_delta) and abs(req_price_delta) >= 1.0:
        direction = "ä½ä¸‹" if req_price_delta < 0 else "ä¸Šæ˜‡"
        pieces.append(
            f"å¹³å‡å¿…è¦è²©å£²å˜ä¾¡ {abs(req_price_delta):,.0f}å††{direction}"
        )
    if np.isfinite(gap_delta) and abs(gap_delta) >= 0.01:
        direction = "æ”¹å–„" if gap_delta >= 0 else "æ‚ªåŒ–"
        pieces.append(
            f"å¿…è¦è³ƒç‡ã¨ã®å·® {abs(gap_delta):.2f}å††/åˆ†{direction}"
        )
    return " / ".join(pieces)


def _safe_series_mean(series: Optional[pd.Series]) -> float:
    """Return a finite mean value for the provided numeric series if possible."""

    if series is None:
        return float("nan")
    cleaned = pd.to_numeric(series, errors="coerce")
    cleaned = cleaned.replace([np.inf, -np.inf], np.nan).dropna()
    if cleaned.empty:
        return float("nan")
    return float(cleaned.mean())


def _analyze_driver_impacts(
    df_template: pd.DataFrame,
    df_base: pd.DataFrame,
    base_metrics: Dict[str, float],
    *,
    price_pct: float,
    ct_pct: float,
    volume_pct: float,
    material_pct: float,
    be_rate: float,
    req_rate: float,
    delta_low: float,
    delta_high: float,
    working_days: float,
) -> Tuple[pd.DataFrame, List[str]]:
    """Simulate each adjustment factor independently and summarise KPI deltas."""

    base_daily = float(base_metrics.get("daily_va_total", float("nan")))
    if not np.isfinite(base_daily):
        base_daily = float("nan")
    base_avg_va = float(base_metrics.get("avg_vapm", float("nan")))
    if not np.isfinite(base_avg_va):
        base_avg_va = float("nan")
    base_avg_gap = float(base_metrics.get("avg_gap", float("nan")))
    if not np.isfinite(base_avg_gap):
        base_avg_gap = float("nan")
    base_avg_req_price = float(
        base_metrics.get("avg_required_price", float("nan"))
    )
    if not np.isfinite(base_avg_req_price):
        base_avg_req_price = float("nan")

    driver_configs = [
        ("è²©å£²ä¾¡æ ¼", price_pct, "price"),
        ("ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ", ct_pct, "lead_time"),
        ("ç”Ÿç”£é‡", volume_pct, "volume"),
        ("ææ–™è²»", material_pct, "material"),
    ]

    records: List[Dict[str, Any]] = []
    insights: List[str] = []
    valid_working_days = (
        working_days is not None and np.isfinite(working_days) and working_days > 0
    )

    for label, pct_value, key in driver_configs:
        if pct_value in (None, 0) or not np.isfinite(float(pct_value)):
            continue

        kwargs = {
            "price_pct": 0.0,
            "ct_pct": 0.0,
            "volume_pct": 0.0,
            "material_pct": 0.0,
        }
        kwargs["price_pct"] = kwargs["price_pct"] if key != "price" else pct_value
        kwargs["ct_pct"] = kwargs["ct_pct"] if key != "lead_time" else pct_value
        kwargs["volume_pct"] = kwargs["volume_pct"] if key != "volume" else pct_value
        kwargs["material_pct"] = (
            kwargs["material_pct"] if key != "material" else pct_value
        )

        df_driver, driver_metrics = _simulate_scenario(
            df_template,
            price_pct=kwargs["price_pct"],
            ct_pct=kwargs["ct_pct"],
            volume_pct=kwargs["volume_pct"],
            material_pct=kwargs["material_pct"],
            be_rate=be_rate,
            req_rate=req_rate,
            delta_low=delta_low,
            delta_high=delta_high,
        )
        driver_metrics_clean = _sanitize_metrics(driver_metrics)

        daily_candidate = driver_metrics_clean.get("daily_va_total", float("nan"))
        daily_delta = daily_candidate - base_daily
        if not np.isfinite(daily_delta):
            daily_delta = float("nan")
        annual_delta = float("nan")
        if valid_working_days and np.isfinite(daily_delta):
            annual_delta = daily_delta * float(working_days)

        avg_va = float(driver_metrics_clean.get("avg_vapm", float("nan")))
        avg_gap = float(driver_metrics_clean.get("avg_gap", float("nan")))
        avg_req_price = float(
            driver_metrics_clean.get("avg_required_price", float("nan"))
        )

        avg_va_delta = (
            avg_va - base_avg_va
            if np.isfinite(avg_va) and np.isfinite(base_avg_va)
            else float("nan")
        )
        avg_gap_delta = (
            avg_gap - base_avg_gap
            if np.isfinite(avg_gap) and np.isfinite(base_avg_gap)
            else float("nan")
        )
        req_price_delta = (
            avg_req_price - base_avg_req_price
            if np.isfinite(avg_req_price) and np.isfinite(base_avg_req_price)
            else float("nan")
        )

        records.append(
            {
                "æ–½ç­–": label,
                "å¤‰åŒ–ç‡(%)": float(pct_value),
                "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤å·®(å††)": daily_delta,
                "å¹´é–“åˆ©ç›Šå·®(ä¸‡å††)": annual_delta / 10000.0
                if np.isfinite(annual_delta)
                else float("nan"),
                "å¹³å‡VA/åˆ†å·®(å††)": avg_va_delta,
                "å¹³å‡å¿…è¦è³ƒç‡å·®(å††/åˆ†)": avg_gap_delta,
                "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡å·®(å††)": req_price_delta,
            }
        )

        if key in {"price", "volume", "material"} and np.isfinite(daily_delta):
            direction_daily = "å¢—åŠ " if daily_delta >= 0 else "æ¸›å°‘"
            daily_abs = abs(daily_delta)
            annual_phrase = ""
            if np.isfinite(annual_delta):
                annual_abs = abs(annual_delta) / 10000.0
                direction_annual = "å¢—åŠ " if annual_delta >= 0 else "æ¸›å°‘"
                annual_phrase = (
                    f"ã€å¹´é–“åˆ©ç›ŠãŒ{annual_abs:,.1f}ä¸‡å††{direction_annual}"
                )
            insights.append(
                f"{label}ã‚’{int(pct_value):+d}%èª¿æ•´ã™ã‚‹ã¨æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤ãŒ{daily_abs:,.0f}å††{direction_daily}{annual_phrase}ã—ã¾ã™ã€‚"
            )
        elif key == "lead_time":
            parts: List[str] = []
            if np.isfinite(avg_va_delta):
                direction = "å¢—åŠ " if avg_va_delta >= 0 else "æ¸›å°‘"
                parts.append(
                    f"å¹³å‡VA/åˆ†ãŒ{abs(avg_va_delta):.2f}å††{direction}"
                )
            if np.isfinite(avg_gap_delta):
                direction = "æ”¹å–„" if avg_gap_delta >= 0 else "æ‚ªåŒ–"
                parts.append(
                    f"å¿…è¦è³ƒç‡ã¨ã®å·®ãŒ{abs(avg_gap_delta):.2f}å††/åˆ†{direction}"
                )
            if np.isfinite(req_price_delta):
                direction = "ä½ä¸‹" if req_price_delta < 0 else "ä¸Šæ˜‡"
                parts.append(
                    f"å¿…è¦è²©å£²å˜ä¾¡ãŒ{abs(req_price_delta):,.0f}å††{direction}"
                )
            if parts:
                joined = "ã€".join(parts)
                insights.append(
                    f"{label}ã‚’{int(pct_value):+d}%èª¿æ•´ã™ã‚‹ã¨{joined}ã—ã¾ã™ã€‚"
                )

    if records:
        df_summary = pd.DataFrame(records)
    else:
        df_summary = pd.DataFrame(
            columns=[
                "æ–½ç­–",
                "å¤‰åŒ–ç‡(%)",
                "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤å·®(å††)",
                "å¹´é–“åˆ©ç›Šå·®(ä¸‡å††)",
                "å¹³å‡VA/åˆ†å·®(å††)",
                "å¹³å‡å¿…è¦è³ƒç‡å·®(å††/åˆ†)",
                "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡å·®(å††)",
            ]
        )

    return df_summary, insights


def _format_fermi_estimate(delta_daily_va: float, working_days: float, scenario_label: str) -> str:
    """Build a short Fermi style estimate text for annual profit impact."""

    if working_days is None or working_days <= 0:
        return "ç¨¼åƒæ—¥æ•°ã®æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚å¹´é–“å½±éŸ¿ã‚’æ¦‚ç®—ã§ãã¾ã›ã‚“ã€‚"
    if delta_daily_va is None or not np.isfinite(delta_daily_va):
        return "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‹ã‚‰æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤ã®å¤‰åŒ–ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    if abs(delta_daily_va) < 1:
        return "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤ã®å¤‰åŒ–ãŒã”ãå°ã•ã„ãŸã‚å¹´é–“å½±éŸ¿ã¯é™å®šçš„ã¨æ¨å®šã•ã‚Œã¾ã™ã€‚"

    annual_change = float(delta_daily_va) * float(working_days)
    lower = abs(annual_change) * 0.8
    upper = abs(annual_change) * 1.2
    sign = "å¢—åŠ " if annual_change >= 0 else "æ¸›å°‘"
    scenario = scenario_label or "ã‚«ã‚¹ã‚¿ãƒ è¨­å®š"
    return (
        f"{scenario} ã‚’é©ç”¨ã™ã‚‹ã¨æ—¥æ¬¡ã®ä»˜åŠ ä¾¡å€¤(ç²—åˆ©ç›¸å½“)ãŒ {delta_daily_va:+,.0f} å††å¤‰åŒ– â†’ "
        f"å¹´é–“åˆ©ç›Šã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã¯{sign}æ–¹å‘ã«æ¦‚ã­ {lower:,.0f} ï½ {upper:,.0f} å††ã¨æ¨å®šã•ã‚Œã¾ã™ã€‚"
    )


def _upsert_trend_record(
    *,
    scenario: str,
    period: pd.Timestamp,
    ach_rate: float,
    va_per_min: float,
    required_rate: float,
    be_rate: float,
    note: str = "",
) -> pd.DataFrame:
    """Insert or update a monthly KPI snapshot for trend analysis."""

    record = {
        "scenario": scenario,
        "period": period,
        "ach_rate": float(ach_rate) if ach_rate is not None else np.nan,
        "va_per_min": float(va_per_min) if va_per_min is not None else np.nan,
        "required_rate": float(required_rate) if required_rate is not None else np.nan,
        "be_rate": float(be_rate) if be_rate is not None else np.nan,
        "note": note,
        "recorded_at": pd.Timestamp.utcnow(),
    }
    history = st.session_state.get("monthly_trend")
    if history is None or getattr(history, "empty", True):
        history = pd.DataFrame(columns=list(record.keys()))
    else:
        history = history.copy()
        history["period"] = pd.to_datetime(history["period"])
    mask = (history["scenario"] == scenario) & (history["period"] == period)
    history = history[~mask]
    history = pd.concat([history, pd.DataFrame([record])], ignore_index=True)
    history = history.sort_values(["period", "scenario"]).reset_index(drop=True)
    st.session_state["monthly_trend"] = history
    return history


def _prepare_trend_dataframe(trend_df: pd.DataFrame, freq: str) -> pd.DataFrame:
    """Return data aggregated at the requested frequency for plotting."""

    if trend_df is None or trend_df.empty:
        return pd.DataFrame(columns=["scenario", "period", "ach_rate", "va_per_min", "required_rate", "be_rate"])
    df = trend_df.copy()
    df["period"] = pd.to_datetime(df["period"])
    df = df.dropna(subset=["period"])
    if freq == "å››åŠæœŸ":
        df["period"] = df["period"].dt.to_period("Q").dt.to_timestamp()
        grouped = (
            df.groupby(["scenario", "period"], as_index=False)
            .agg(
                ach_rate=("ach_rate", "mean"),
                va_per_min=("va_per_min", "mean"),
                required_rate=("required_rate", "mean"),
                be_rate=("be_rate", "mean"),
            )
        )
        return grouped.sort_values(["period", "scenario"])
    df["period"] = df["period"].dt.to_period("M").dt.to_timestamp()
    df = df.sort_values(["period", "scenario"])
    return df[["scenario", "period", "ach_rate", "va_per_min", "required_rate", "be_rate", "note", "recorded_at"]]


def _format_period_label(value: Any, freq: str) -> str:
    """Format a timestamp for display based on the selected frequency."""

    if value is None or (isinstance(value, float) and pd.isna(value)):
        return "-"
    try:
        ts = pd.Timestamp(value)
    except Exception:
        return str(value)
    if freq == "å››åŠæœŸ":
        return str(ts.to_period("Q"))
    return ts.strftime("%Y-%m")


def _build_yoy_summary(trend_df: pd.DataFrame, scenarios: List[str]) -> List[str]:
    """Create human-friendly YoY comparison sentences for the latest month."""

    if trend_df is None or trend_df.empty:
        return []
    df = trend_df.copy()
    df["period"] = pd.to_datetime(df["period"])
    df = df.dropna(subset=["period"])
    df["month"] = df["period"].dt.to_period("M")
    df = df.sort_values(["month", "scenario"])
    summaries: List[str] = []
    for scen in scenarios:
        scen_df = df[df["scenario"] == scen]
        if scen_df.empty:
            continue
        latest = scen_df.iloc[-1]
        prev_month = latest["month"] - 12
        prev_rows = scen_df[scen_df["month"] == prev_month]
        if prev_rows.empty:
            continue
        prev = prev_rows.iloc[-1]
        yoy_req = _pct_change(prev["required_rate"], latest["required_rate"])
        yoy_va = _pct_change(prev["va_per_min"], latest["va_per_min"])
        yoy_ach = latest["ach_rate"] - prev["ach_rate"]
        summaries.append(
            f"{scen}: å¿…è¦è³ƒç‡ {_format_delta(yoy_req, '%')} / VA/åˆ† {_format_delta(yoy_va, '%')} / é”æˆç‡ {_format_delta(yoy_ach, 'pt')}"
        )
    return summaries


def _generate_dashboard_comment(
    df: pd.DataFrame, metrics: Dict[str, float], insights: Dict[str, Any]
) -> str:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    client = OpenAI(api_key=api_key)
    sample = df.head(5).to_markdown(index=False)
    top_gaps: List[Dict[str, Any]] = insights.get("top_underperformers", [])
    anomaly_summary: List[Dict[str, Any]] = insights.get("anomaly_summary", [])
    anomaly_details: List[Dict[str, Any]] = insights.get("anomaly_records", [])
    dq_summary = insights.get("dq_summary", {})

    top_gap_lines = []
    for row in top_gaps:
        roi_txt = _format_roi(row.get("roi_months"))
        gap_val = row.get("gap")
        gap_txt = "N/A" if gap_val is None or pd.isna(gap_val) else f"{float(gap_val):.2f}å††/åˆ†"
        action_label = row.get("best_action_label")
        if action_label and action_label != "æ¨å¥¨ãªã—":
            action_txt = f", æ¨å¥¨ {action_label}"
        else:
            action_txt = ""
        benefit_txt = _format_currency(row.get("best_monthly_benefit"))
        top_gap_lines.append(
            f"- {row.get('product_name','ä¸æ˜')} (ã‚®ãƒ£ãƒƒãƒ— {gap_txt}, ROI {roi_txt}ãƒ¶æœˆ{action_txt}, æœˆæ¬¡åŠ¹æœ {benefit_txt})"
        )
    top_gap_text = "\n".join(top_gap_lines) or "- è©²å½“ãªã—"

    anomaly_summary_text = "\n".join(
        [
            f"- {row['metric']}: {int(row['count'])}ä»¶ (å¹³å‡é€¸è„± {row['severity_mean']:.1f})"
            for row in anomaly_summary
        ]
    ) or "- å¤§ããªé€¸è„±ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"

    anomaly_detail_lines = []
    for row in anomaly_details[:5]:
        value = row.get("value")
        median_val = row.get("median")
        val_txt = "N/A" if value is None or pd.isna(value) else f"{float(value):.2f}"
        median_txt = "N/A" if median_val is None or pd.isna(median_val) else f"{float(median_val):.2f}"
        anomaly_detail_lines.append(
            f"ãƒ»{row.get('product_name','ä¸æ˜')} ({row.get('metric','-')}) = {val_txt} â†’ ä¸­å¤®å€¤ {median_txt}"
        )
    anomaly_detail_text = "\n".join(anomaly_detail_lines) or "ãƒ»è©³ç´°ã‚µãƒ³ãƒ—ãƒ«ãªã—"

    dq_text = (
        f"æ¬ æ{dq_summary.get('missing',0)}ä»¶ / å¤–ã‚Œå€¤{dq_summary.get('negative',0)}ä»¶ / é‡è¤‡{dq_summary.get('duplicate',0)}SKU"
        if dq_summary
        else "ãªã—"
    )

    def _format_segment_line(row: Dict[str, Any]) -> str:
        segment = row.get("segment", "ä¸æ˜")
        pieces = []
        avg_va = row.get("avg_va_per_min")
        gap_val = row.get("avg_gap")
        ach_val = row.get("ach_rate_pct")
        roi_val = row.get("avg_roi_months")
        if avg_va is not None and not pd.isna(avg_va):
            pieces.append(f"VA/åˆ† {float(avg_va):.1f}å††")
        if gap_val is not None and not pd.isna(gap_val):
            pieces.append(f"å·® {float(gap_val):+.1f}å††")
        if ach_val is not None and not pd.isna(ach_val):
            pieces.append(f"é”æˆç‡ {float(ach_val):.1f}%")
        if roi_val is not None and not pd.isna(roi_val):
            pieces.append(f"ROI {float(roi_val):.1f}æœˆ")
        detail = " / ".join(pieces) if pieces else "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"
        return f"- {segment}: {detail}"

    category_text = "\n".join(
        [_format_segment_line(row) for row in insights.get("segment_category", [])[:3]]
    ) or "- æƒ…å ±ä¸è¶³"
    customer_text = "\n".join(
        [_format_segment_line(row) for row in insights.get("segment_customer", [])[:3]]
    ) or "- æƒ…å ±ä¸è¶³"

    prompt = (
        "ã‚ãªãŸã¯è£½é€ æ¥­å‘ã‘ã®çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "ä»¥ä¸‹ã®KPIã¨ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã€AIãŒæŠ½å‡ºã—ãŸè¿½åŠ ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’è¸ã¾ãˆã€"
        "ç¾çŠ¶è©•ä¾¡ã¨å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ãƒªã‚¹ã‚¯ã‚’3æ®µè½ã§æ§‹æˆã—ã€æœ€å¾Œã«æ¬¡ã®ä¸€æ­©ã‚’ç®‡æ¡æ›¸ãã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚\n"
        f"KPI: é”æˆç‡={metrics.get('ach_rate',0):.1f}%, "
        f"å¿…è¦è³ƒç‡={metrics.get('req_rate',0):.3f}, "
        f"æç›Šåˆ†å²è³ƒç‡={metrics.get('be_rate',0):.3f}\n"
        f"ãƒ‡ãƒ¼ã‚¿å“è³ªã‚µãƒãƒª: {dq_text}\n"
        f"ä¸»è¦æœªé”SKU:\n{top_gap_text}\n"
        f"ç•°å¸¸æ¤œçŸ¥ã‚µãƒãƒª:\n{anomaly_summary_text}\n"
        f"ç•°å¸¸å€¤ã‚µãƒ³ãƒ—ãƒ«:\n{anomaly_detail_text}\n"
        f"ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã‚µãƒãƒª:\n{category_text}\n"
        f"ä¸»è¦é¡§å®¢åˆ¥ã‚µãƒãƒª:\n{customer_text}\n"
        f"ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:\n{sample}\n"
        "å‡ºåŠ›å½¢å¼:\n"
        "1. 50æ–‡å­—ä»¥å†…ã®çŠ¶æ³ã‚¿ã‚¤ãƒˆãƒ«\n"
        "2. KPIã®è§£é‡ˆ (ç®‡æ¡æ›¸ã3ç‚¹ä»¥å†…)\n"
        "3. æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ (ç®‡æ¡æ›¸ã3ç‚¹ä»¥å†…)\n"
        "4. ãƒªã‚¹ã‚¯/ã‚±ã‚¢ã™ã¹ãç‚¹ (1-2ç‚¹)\n"
        "5. æ¬¡ã®ä¸€æ­© (1æ–‡)"
    )
    try:
        resp = client.responses.create(model="gpt-4o-mini", input=prompt)
        return resp.output_text.strip()
    except Exception as exc:
        return f"AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}"

render_sidebar_nav(page_key="dashboard")

header_col, help_col = st.columns([0.76, 0.24], gap="small")
with header_col:
    st.title("â‘¡ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

render_help_button("dashboard", container=help_col)

render_onboarding()
render_page_tutorial("dashboard")
render_stepper(4)
scenario_name = st.session_state.get("current_scenario", "ãƒ™ãƒ¼ã‚¹")
st.caption(f"é©ç”¨ä¸­ã‚·ãƒŠãƒªã‚ª: {scenario_name}")
st.session_state.setdefault("quick_price", 0)
st.session_state.setdefault("quick_ct", 0)
st.session_state.setdefault("quick_volume", 0)
st.session_state.setdefault("quick_material", 0)
st.session_state.setdefault("active_simulation", "ãƒ™ãƒ¼ã‚¹")
st.session_state.setdefault(
    "plotly_draw_tools", ["drawline", "drawrect", "drawopenpath", "drawcircle", "eraseshape"]
)
st.session_state.setdefault("show_rangeslider", True)
st.session_state.setdefault("show_spikelines", True)
scenario_store = st.session_state.setdefault("whatif_scenarios", {})

with st.sidebar.expander("ã‚°ãƒ©ãƒ•æ“ä½œã‚ªãƒ—ã‚·ãƒ§ãƒ³", expanded=False):
    st.session_state["show_spikelines"] = st.checkbox(
        "ãƒ›ãƒãƒ¼æ™‚ã«ã‚¬ã‚¤ãƒ‰ç·šã‚’è¡¨ç¤º", value=st.session_state["show_spikelines"], help="æ‹¡å¤§ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚X/Yæ–¹å‘ã®ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ©ã‚¤ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"
    )
    st.session_state["show_rangeslider"] = st.checkbox(
        "æ™‚ç³»åˆ—ã«ãƒ¬ãƒ³ã‚¸ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¡¨ç¤º", value=st.session_state["show_rangeslider"], help="æœˆæ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ãªã©ã‚’æ‹¡å¤§è¡¨ç¤ºã—ãŸéš›ã«ã‚‚ç¯„å›²ã‚’ç´ æ—©ãèª¿æ•´ã§ãã¾ã™ã€‚"
    )
    st.session_state["plotly_draw_tools"] = st.multiselect(
        "æç”»ãƒ„ãƒ¼ãƒ« (æ‹¡å¤§ãƒ¢ãƒ¼ãƒ‰ã«ã‚‚åæ˜ )",
        options=["drawline", "drawopenpath", "drawcircle", "drawrect", "eraseshape"],
        default=st.session_state["plotly_draw_tools"],
    )
    st.caption("è¨­å®šã¯å…¨Plotlyã‚°ãƒ©ãƒ•ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒãƒ¼ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚")


def reset_quick_params() -> None:
    """Reset quick simulation parameters to their default values."""
    st.session_state["quick_price"] = 0
    st.session_state["quick_ct"] = 0
    st.session_state["quick_volume"] = 0
    st.session_state["quick_material"] = 0
    st.session_state["active_simulation"] = "ãƒ™ãƒ¼ã‚¹"

if "df_products_raw" not in st.session_state or st.session_state["df_products_raw"] is None or len(st.session_state["df_products_raw"]) == 0:
    st.info("å…ˆã«ã€â‘  ãƒ‡ãƒ¼ã‚¿å…¥åŠ› & å–ã‚Šè¾¼ã¿ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

df_raw_all = st.session_state["df_products_raw"]
st.session_state.setdefault("anomaly_review", {})
excluded_skus = st.session_state.get("dq_exclude_skus", [])
df_products_raw = df_raw_all[~df_raw_all["product_no"].isin(excluded_skus)].copy()
dq_df = detect_quality_issues(df_products_raw)
miss_count = int((dq_df["type"] == "æ¬ æ").sum())
out_count = int((dq_df["type"] == "å¤–ã‚Œå€¤").sum())
dup_count = int((dq_df["type"] == "é‡è¤‡").sum())
affected_skus = dq_df["product_no"].nunique()
scenarios = st.session_state.get("scenarios", {scenario_name: st.session_state.get("sr_params", DEFAULT_PARAMS)})
st.session_state["scenarios"] = scenarios
base_params = scenarios.get(scenario_name, st.session_state.get("sr_params", DEFAULT_PARAMS))
base_params, warn_list = sanitize_params(base_params)
scenarios[scenario_name] = base_params
_, base_results = compute_rates(base_params)
be_rate = base_results["break_even_rate"]
req_rate = base_results["required_rate"]
for w in warn_list:
    st.warning(w)

# Baseline classification for reclassification counts
df_default = compute_results(df_products_raw, be_rate, req_rate)

# Threshold tuning slider within filter panel
dcol1, dcol2 = st.columns([2, 0.8])
delta_low, delta_high = dcol1.slider(
    "Î´ = VA/åˆ† Ã· å¿…è¦è³ƒç‡ ã®å¢ƒç•Œ",
    min_value=0.5,
    max_value=1.5,
    value=(0.95, 1.05),
    step=0.01,
)
df = compute_results(df_products_raw, be_rate, req_rate, delta_low, delta_high)
reclassified = int((df["rate_class"] != df_default["rate_class"]).sum())
dcol2.metric("å†åˆ†é¡SKU", reclassified)

with st.expander("ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®è¡¨ç¤ºèª¿æ•´", expanded=False):
    topn = int(
        st.slider("æœªé”SKUã®ä¸Šä½ä»¶æ•°ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ‘ãƒ¬ãƒ¼ãƒˆï¼‰", min_value=5, max_value=50, value=20, step=1)
    )

# Global filters with view save/share
classes = df["rate_class"].dropna().unique().tolist()
global_mpu_min = float(np.nan_to_num(df["minutes_per_unit"].min(), nan=0.0))
global_mpu_max = float(np.nan_to_num(df["minutes_per_unit"].max(), nan=10.0))
global_v_min = float(np.nan_to_num(df["va_per_min"].replace([np.inf,-np.inf], np.nan).min(), nan=0.0))
global_v_max = float(np.nan_to_num(df["va_per_min"].replace([np.inf,-np.inf], np.nan).max(), nan=10.0))
qparams = dict(st.query_params)
default_classes = qparams.get("classes", ",".join(classes)).split(",")
default_classes = [c for c in default_classes if c in classes]
default_search = qparams.get("search", "")
mpu_param = qparams.get("mpu", f"{global_mpu_min},{global_mpu_max}")
try:
    m_min_q, m_max_q = [float(x) for x in mpu_param.split(",")]
except Exception:
    m_min_q, m_max_q = global_mpu_min, global_mpu_max
vapm_param = qparams.get("vapm", f"{global_v_min},{global_v_max}")
try:
    v_min_q, v_max_q = [float(x) for x in vapm_param.split(",")]
except Exception:
    v_min_q, v_max_q = global_v_min, global_v_max
fcol1, fcol2, fcol3, fcol4, fcol5, fcol6 = st.columns([1,1,2,2,0.5,0.5])
selected_classes = fcol1.multiselect("é”æˆåˆ†é¡ã§çµã‚Šè¾¼ã¿", classes, default=default_classes)
search = fcol2.text_input("è£½å“å æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", default_search)
mpu_min, mpu_max = fcol3.slider(
    "åˆ†/å€‹ï¼ˆè£½é€ ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼‰ã®ç¯„å›²",
    global_mpu_min,
    global_mpu_max,
    value=(m_min_q, m_max_q)
)
vapm_min, vapm_max = fcol4.slider(
    "ä»˜åŠ ä¾¡å€¤/åˆ† ã®ç¯„å›²",
    global_v_min,
    global_v_max,
    value=(v_min_q, v_max_q)
)
save_btn = fcol5.button("ä¿å­˜")
share_btn = fcol6.button("å…±æœ‰")
if save_btn or share_btn:
    state = {
        "classes": ",".join(selected_classes),
        "search": search,
        "mpu": f"{mpu_min},{mpu_max}",
        "vapm": f"{vapm_min},{vapm_max}"
    }
    st.query_params = state
    if share_btn:
        st.session_state["share_link"] = "?" + urlencode(state)
        st.session_state["show_share"] = True
    if save_btn:
        st.session_state["show_saved"] = True
    st.rerun()
if st.session_state.pop("show_saved", False):
    st.success("ãƒ“ãƒ¥ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
if st.session_state.pop("show_share", False):
    st.code(st.session_state.pop("share_link", ""), language=None)

mask = df["rate_class"].isin(selected_classes)
if search:
    mask &= df["product_name"].astype(str).str.contains(search, na=False)
mask &= df["minutes_per_unit"].fillna(0.0).between(mpu_min, mpu_max)
mask &= df["va_per_min"].replace([np.inf,-np.inf], np.nan).fillna(0.0).between(vapm_min, vapm_max)
df_view_filtered = df[mask].copy()

# Quick simulation presets & toggles
st.markdown("#### ğŸ¯ What-ifã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
preset_cols = st.columns(len(SIMULATION_PRESETS))
for col, (label, preset) in zip(preset_cols, SIMULATION_PRESETS.items()):
    desc = preset.get("description")
    if col.button(label, help=desc):
        apply_simulation_preset(label)
        st.rerun()

qcol1, qcol2, qcol3, qcol4, qcol5 = st.columns([1.1, 1.1, 1.1, 1.1, 0.8])
with qcol1:
    st.slider(
        "è²©å£²ä¾¡æ ¼",
        min_value=-10,
        max_value=15,
        value=int(st.session_state.get("quick_price", 0)),
        step=1,
        format="%d%%",
        key="quick_price",
        help="è£½å“ä¾¡æ ¼ã‚’ä¸€å¾‹ã§å¢—æ¸›ã•ã›ã‚‹ç°¡æ˜“è©¦ç®—ã§ã™ã€‚",
    )
with qcol2:
    st.slider(
        "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ  (åˆ†/å€‹)",
        min_value=-30,
        max_value=30,
        value=int(st.session_state.get("quick_ct", 0)),
        step=1,
        format="%d%%",
        key="quick_ct",
        help="è£½å“1å€‹å½“ãŸã‚Šã®æ‰€è¦æ™‚é–“ï¼ˆåˆ†/å€‹ï¼‰ã‚’çŸ­ç¸®/å»¶é•·ã—ãŸå ´åˆã‚’æƒ³å®šã—ã¾ã™ã€‚",
    )
with qcol3:
    st.slider(
        "ç”Ÿç”£é‡ (æ—¥ç”£æ•°)",
        min_value=-30,
        max_value=30,
        value=int(st.session_state.get("quick_volume", 0)),
        step=1,
        format="%d%%",
        key="quick_volume",
        help="æ—¥ç”£æ•°ã‚’ä¸€å¾‹ã§å¢—æ¸›ã•ã›ãŸã¨ãã®å½±éŸ¿ã‚’è©¦ç®—ã—ã¾ã™ã€‚",
    )
with qcol4:
    st.slider(
        "ææ–™è²»",
        min_value=-10,
        max_value=10,
        value=int(st.session_state.get("quick_material", 0)),
        step=1,
        format="%d%%",
        key="quick_material",
        help="åŸææ–™ã‚³ã‚¹ãƒˆã‚’å…¨SKUã§åŒã˜å‰²åˆã ã‘å¢—æ¸›ã•ã›ã¾ã™ã€‚",
    )
with qcol5:
    st.button("ãƒªã‚»ãƒƒãƒˆ", on_click=reset_quick_params)

qp = st.session_state["quick_price"]
qc = st.session_state["quick_ct"]
qv = st.session_state["quick_volume"]
qm = st.session_state["quick_material"]
active_label = _resolve_scenario_label(qp, qc, qm, qv, scenario_store)
st.session_state["active_simulation"] = active_label
preset_desc = SIMULATION_PRESETS.get(active_label, {}).get("description", "")
summary_text = (
    f"è²©å£²ä¾¡æ ¼{qp:+d}%ï½œãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ {qc:+d}%ï½œç”Ÿç”£é‡{qv:+d}%ï½œææ–™è²»{qm:+d}%"
)
if active_label == "ãƒ™ãƒ¼ã‚¹":
    st.caption(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆ{summary_text}ï¼‰")
else:
    detail = f"ï½œ{preset_desc}" if preset_desc else ""
    st.caption(f"ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {active_label}ï¼ˆ{summary_text}ï¼‰{detail}")

feedback = st.session_state.pop("scenario_manager_feedback", None)
if feedback:
    level = feedback.get("type", "info") if isinstance(feedback, dict) else "info"
    message = feedback.get("message", "") if isinstance(feedback, dict) else str(feedback)
    notify = {"success": st.success, "warning": st.warning, "info": st.info}.get(level, st.info)
    if message:
        notify(message)

with st.expander("ğŸ’¾ ã‚·ãƒŠãƒªã‚ªç®¡ç†", expanded=False):
    st.caption("ç¾åœ¨ã®ã‚¯ã‚¤ãƒƒã‚¯èª¿æ•´ã‚’åå‰ã‚’ä»˜ã‘ã¦ä¿å­˜ã—ã€å¾Œã‹ã‚‰å‘¼ã³å‡ºã—ã¦æ¯”è¼ƒã§ãã¾ã™ã€‚")
    saved_names = list(scenario_store.keys())
    manage_cols = None
    selected_saved: Optional[str] = None
    if saved_names:
        selected_saved = st.selectbox(
            "ä¿å­˜æ¸ˆã¿ã‚·ãƒŠãƒªã‚ª",
            ["é¸æŠãªã—"] + saved_names,
            key="scenario_manager_select",
        )
        manage_cols = st.columns(2)
        if manage_cols[0].button("é©ç”¨", key="scenario_manager_load"):
            if selected_saved and selected_saved != "é¸æŠãªã—":
                config = scenario_store.get(selected_saved, {})
                st.session_state["quick_price"] = int(config.get("quick_price", 0))
                st.session_state["quick_ct"] = int(config.get("quick_ct", 0))
                st.session_state["quick_volume"] = int(config.get("quick_volume", 0))
                st.session_state["quick_material"] = int(config.get("quick_material", 0))
                st.session_state["scenario_manager_feedback"] = {
                    "type": "success",
                    "message": f"{selected_saved} ã‚’é©ç”¨ã—ã¾ã—ãŸã€‚",
                }
                st.rerun()
        if manage_cols[1].button("å‰Šé™¤", key="scenario_manager_delete"):
            if selected_saved and selected_saved != "é¸æŠãªã—":
                scenario_store.pop(selected_saved, None)
                st.session_state["whatif_scenarios"] = scenario_store
                st.session_state["scenario_manager_feedback"] = {
                    "type": "info",
                    "message": f"{selected_saved} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚",
                }
                st.rerun()
    else:
        st.caption("ä¿å­˜æ¸ˆã¿ã‚·ãƒŠãƒªã‚ªã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚ä¸‹ã§åå‰ã‚’å…¥åŠ›ã—ã¦ä¿å­˜ã—ã¦ãã ã•ã„ã€‚")

    if st.session_state.pop("scenario_manager_clear_input", False):
        st.session_state["scenario_save_name"] = ""

    new_name = st.text_input(
        "ã‚·ãƒŠãƒªã‚ªå",
        key="scenario_save_name",
        help="ä¾‹: æ–½ç­–A (ä¾¡æ ¼+5%)ã€æ–½ç­–B (CT-10%) ãªã©",
    )
    if st.button("ä¿å­˜/ä¸Šæ›¸ã", key="scenario_manager_save"):
        trimmed = new_name.strip()
        if not trimmed:
            st.warning("ã‚·ãƒŠãƒªã‚ªåã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            scenario_store[trimmed] = {
                "quick_price": int(qp),
                "quick_ct": int(qc),
                "quick_volume": int(qv),
                "quick_material": int(qm),
            }
            st.session_state["whatif_scenarios"] = scenario_store
            st.session_state["scenario_manager_feedback"] = {
                "type": "success",
                "message": f"{trimmed} ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚",
            }
            st.session_state["scenario_manager_clear_input"] = True
            st.rerun()

scenario_template = df_view_filtered.copy()
df_base, base_metrics = _simulate_scenario(
    scenario_template,
    price_pct=0,
    ct_pct=0,
    volume_pct=0,
    material_pct=0,
    be_rate=be_rate,
    req_rate=req_rate,
    delta_low=delta_low,
    delta_high=delta_high,
)
base_metrics_clean = _sanitize_metrics(base_metrics)
base_ach_rate = base_metrics_clean["ach_rate"]
base_avg_vapm = base_metrics_clean["avg_vapm"]
base_daily_va_total = base_metrics_clean["daily_va_total"]
base_avg_gap = base_metrics_clean.get("avg_gap", float("nan"))
base_avg_req_price = base_metrics_clean.get("avg_required_price", float("nan"))

df_view, active_metrics = _simulate_scenario(
    scenario_template,
    price_pct=qp,
    ct_pct=qc,
    volume_pct=qv,
    material_pct=qm,
    be_rate=be_rate,
    req_rate=req_rate,
    delta_low=delta_low,
    delta_high=delta_high,
)
active_metrics_clean = _sanitize_metrics(active_metrics)
ach_rate = active_metrics_clean["ach_rate"]
avg_vapm = active_metrics_clean["avg_vapm"]
sim_daily_va_total = active_metrics_clean["daily_va_total"]
avg_gap = active_metrics_clean.get("avg_gap", float("nan"))
avg_req_price = active_metrics_clean.get("avg_required_price", float("nan"))

daily_delta = (
    sim_daily_va_total - base_daily_va_total
    if np.isfinite(sim_daily_va_total) and np.isfinite(base_daily_va_total)
    else float("nan")
)
ach_delta = (
    ach_rate - base_ach_rate
    if np.isfinite(ach_rate) and np.isfinite(base_ach_rate)
    else float("nan")
)
vapm_delta = (
    avg_vapm - base_avg_vapm
    if np.isfinite(avg_vapm) and np.isfinite(base_avg_vapm)
    else float("nan")
)
gap_delta_metric = (
    avg_gap - base_avg_gap
    if np.isfinite(avg_gap) and np.isfinite(base_avg_gap)
    else float("nan")
)
req_price_delta_metric = (
    avg_req_price - base_avg_req_price
    if np.isfinite(avg_req_price) and np.isfinite(base_avg_req_price)
    else float("nan")
)

raw_working_days = base_params.get("working_days", DEFAULT_PARAMS["working_days"])
try:
    working_days = float(raw_working_days)
except (TypeError, ValueError):
    working_days = float("nan")
if not np.isfinite(working_days) or working_days <= 0:
    working_days = float("nan")

annual_base_va = (
    base_daily_va_total * working_days
    if np.isfinite(base_daily_va_total) and np.isfinite(working_days)
    else float("nan")
)
annual_sim_va = (
    sim_daily_va_total * working_days
    if np.isfinite(sim_daily_va_total) and np.isfinite(working_days)
    else float("nan")
)
annual_delta = (
    annual_sim_va - annual_base_va
    if np.isfinite(annual_sim_va) and np.isfinite(annual_base_va)
    else float("nan")
)

scenario_results: Dict[str, Dict[str, Any]] = {
    "ãƒ™ãƒ¼ã‚¹": {
        "df": df_base,
        "metrics": base_metrics_clean,
        "adjustments": {
            "quick_price": 0,
            "quick_ct": 0,
            "quick_volume": 0,
            "quick_material": 0,
        },
    }
}

for name, config in scenario_store.items():
    saved_df, saved_metrics = _simulate_scenario(
        scenario_template,
        price_pct=config.get("quick_price", 0),
        ct_pct=config.get("quick_ct", 0),
        volume_pct=config.get("quick_volume", 0),
        material_pct=config.get("quick_material", 0),
        be_rate=be_rate,
        req_rate=req_rate,
        delta_low=delta_low,
        delta_high=delta_high,
    )
    scenario_results[name] = {
        "df": saved_df,
        "metrics": _sanitize_metrics(saved_metrics),
        "adjustments": {
            "quick_price": int(config.get("quick_price", 0)),
            "quick_ct": int(config.get("quick_ct", 0)),
            "quick_volume": int(config.get("quick_volume", 0)),
            "quick_material": int(config.get("quick_material", 0)),
        },
    }

if active_label != "ãƒ™ãƒ¼ã‚¹":
    scenario_results[active_label] = {
        "df": df_view,
        "metrics": active_metrics_clean,
        "adjustments": {
            "quick_price": int(qp),
            "quick_ct": int(qc),
            "quick_volume": int(qv),
            "quick_material": int(qm),
        },
    }

option_candidates = ["ãƒ™ãƒ¼ã‚¹"] + list(scenario_store.keys())
if active_label and active_label not in option_candidates:
    option_candidates.append(active_label)
scenario_options = list(dict.fromkeys(option_candidates))

compare_key = "scenario_compare_selection"
if compare_key in st.session_state:
    current_selection = [
        scen for scen in st.session_state.get(compare_key, []) if scen in scenario_options
    ]
    if not current_selection:
        current_selection = scenario_options
    if set(current_selection) != set(st.session_state.get(compare_key, [])):
        st.session_state[compare_key] = current_selection
else:
    st.session_state[compare_key] = scenario_options

selected_scenarios = st.multiselect(
    "ã‚·ãƒŠãƒªã‚ªé¸æŠ",
    scenario_options,
    default=scenario_options,
    key=compare_key,
)

st.markdown("#### ğŸ“ ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")

comparison_records: List[Dict[str, Any]] = []
base_ach = base_metrics_clean["ach_rate"]
base_avg = base_metrics_clean["avg_vapm"]
base_daily = base_metrics_clean["daily_va_total"]

def _delta_or_nan(current: float, base_value: float) -> float:
    if np.isfinite(current) and np.isfinite(base_value):
        return float(current) - float(base_value)
    return float("nan")

for scen_name in selected_scenarios:
    scen_data = scenario_results.get(scen_name)
    if not scen_data:
        continue
    metrics = scen_data.get("metrics", {})
    adjustments = scen_data.get("adjustments", {})
    ach_val = float(metrics.get("ach_rate", np.nan))
    avg_val = float(metrics.get("avg_vapm", np.nan))
    daily_val = float(metrics.get("daily_va_total", np.nan))
    avg_req_price_val = float(metrics.get("avg_required_price", np.nan))
    avg_gap_val = float(metrics.get("avg_gap", np.nan))
    comparison_records.append(
        {
            "ã‚·ãƒŠãƒªã‚ª": scen_name,
            "èª¿æ•´ã‚µãƒãƒª": _format_adjustment_summary(adjustments),
            "è²©å£²ä¾¡æ ¼èª¿æ•´(%)": int(adjustments.get("quick_price", 0)),
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ èª¿æ•´(%)": int(adjustments.get("quick_ct", 0)),
            "ç”Ÿç”£é‡èª¿æ•´(%)": int(adjustments.get("quick_volume", 0)),
            "ææ–™è²»èª¿æ•´(%)": int(adjustments.get("quick_material", 0)),
            "å¿…è¦è³ƒç‡é”æˆç‡(%)": ach_val,
            "é”æˆç‡å·®åˆ†(pts)": 0.0
            if scen_name == "ãƒ™ãƒ¼ã‚¹" and np.isfinite(base_ach)
            else _delta_or_nan(ach_val, base_ach),
            "å¹³å‡VA/åˆ†(å††)": avg_val,
            "å¹³å‡VA/åˆ†å·®åˆ†(å††)": 0.0
            if scen_name == "ãƒ™ãƒ¼ã‚¹" and np.isfinite(base_avg)
            else _delta_or_nan(avg_val, base_avg),
            "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤(å††)": daily_val,
            "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤å·®åˆ†(å††)": 0.0
            if scen_name == "ãƒ™ãƒ¼ã‚¹" and np.isfinite(base_daily)
            else _delta_or_nan(daily_val, base_daily),
            "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡(å††)": avg_req_price_val,
            "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡å·®åˆ†(å††)": 0.0
            if scen_name == "ãƒ™ãƒ¼ã‚¹" and np.isfinite(base_avg_req_price)
            else _delta_or_nan(avg_req_price_val, base_avg_req_price),
            "å¹³å‡å¿…è¦è³ƒç‡å·®(å††/åˆ†)": avg_gap_val,
            "å¹³å‡å¿…è¦è³ƒç‡å·®åˆ†(å††/åˆ†)": 0.0
            if scen_name == "ãƒ™ãƒ¼ã‚¹" and np.isfinite(base_avg_gap)
            else _delta_or_nan(avg_gap_val, base_avg_gap),
        }
    )

if comparison_records:
    comparison_df = pd.DataFrame(comparison_records)
    styled = comparison_df.style.format(
        {
            "è²©å£²ä¾¡æ ¼èª¿æ•´(%)": "{:+d}",
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ èª¿æ•´(%)": "{:+d}",
            "ç”Ÿç”£é‡èª¿æ•´(%)": "{:+d}",
            "ææ–™è²»èª¿æ•´(%)": "{:+d}",
            "å¿…è¦è³ƒç‡é”æˆç‡(%)": "{:.1f}",
            "é”æˆç‡å·®åˆ†(pts)": "{:+.1f}",
            "å¹³å‡VA/åˆ†(å††)": "{:.2f}",
            "å¹³å‡VA/åˆ†å·®åˆ†(å††)": "{:+.2f}",
            "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤(å††)": "{:,.0f}",
            "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤å·®åˆ†(å††)": "{:+,.0f}",
            "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡(å††)": "{:,.0f}",
            "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡å·®åˆ†(å††)": "{:+,.0f}",
            "å¹³å‡å¿…è¦è³ƒç‡å·®(å††/åˆ†)": "{:+.2f}",
            "å¹³å‡å¿…è¦è³ƒç‡å·®åˆ†(å††/åˆ†)": "{:+.2f}",
        },
        na_rep="-",
    )
    st.dataframe(styled, use_container_width=True)

    now_str = datetime.now().strftime("%Y-%m-%d %H:%M")

    excel_buffer = BytesIO()
    with pd.ExcelWriter(excel_buffer, engine="openpyxl") as writer:
        comparison_df.to_excel(writer, sheet_name="æ¯”è¼ƒã‚µãƒãƒª", index=False)
        meta_df = pd.DataFrame(
            {
                "ç”Ÿæˆæ—¥æ™‚": [now_str],
                "é¸æŠã‚·ãƒŠãƒªã‚ª": [", ".join(selected_scenarios)],
                "åŸºæº–ã‚·ãƒŠãƒªã‚ª": ["ãƒ™ãƒ¼ã‚¹"],
            }
        )
        meta_df.to_excel(writer, sheet_name="ãƒ¡ã‚¿æƒ…å ±", index=False)
    excel_buffer.seek(0)

    try:
        pdfmetrics.getFont("HeiseiMin-W3")
    except KeyError:
        pdfmetrics.registerFont(UnicodeCIDFont("HeiseiMin-W3"))

    def _fmt(value: float, fmt: str) -> str:
        if value is None or not np.isfinite(value):
            return "-"
        return fmt.format(value)

    pdf_buffer = BytesIO()
    doc = SimpleDocTemplate(pdf_buffer, pagesize=A4, topMargin=36, bottomMargin=36)
    styles = getSampleStyleSheet()
    styles["Heading1"].fontName = "HeiseiMin-W3"
    styles["Heading2"].fontName = "HeiseiMin-W3"
    styles["Normal"].fontName = "HeiseiMin-W3"

    story = [
        Paragraph("ã‚·ãƒŠãƒªã‚ªæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ", styles["Heading1"]),
        Spacer(1, 12),
        Paragraph(f"ç”Ÿæˆæ—¥æ™‚: {now_str}", styles["Normal"]),
        Paragraph(f"åŸºæº–ã‚·ãƒŠãƒªã‚ª: ãƒ™ãƒ¼ã‚¹", styles["Normal"]),
        Paragraph(f"æ¯”è¼ƒå¯¾è±¡: {', '.join(selected_scenarios)}", styles["Normal"]),
        Spacer(1, 12),
    ]

    table_header = [
        "ã‚·ãƒŠãƒªã‚ª",
        "èª¿æ•´ã‚µãƒãƒª",
        "å¿…è¦è³ƒç‡é”æˆç‡(%)",
        "å¹³å‡VA/åˆ†(å††)",
        "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤(å††)",
        "é”æˆç‡å·®åˆ†(pts)",
        "VA/åˆ†å·®åˆ†(å††)",
        "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤å·®åˆ†(å††)",
        "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡(å††)",
        "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡å·®åˆ†(å††)",
        "å¹³å‡å¿…è¦è³ƒç‡å·®(å††/åˆ†)",
        "å¹³å‡å¿…è¦è³ƒç‡å·®åˆ†(å††/åˆ†)",
    ]
    table_rows = [table_header]
    for record in comparison_records:
        table_rows.append(
            [
                record["ã‚·ãƒŠãƒªã‚ª"],
                record["èª¿æ•´ã‚µãƒãƒª"],
                _fmt(record["å¿…è¦è³ƒç‡é”æˆç‡(%)"], "{:.1f}"),
                _fmt(record["å¹³å‡VA/åˆ†(å††)"], "{:.2f}"),
                _fmt(record["æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤(å††)"], "{:,.0f}"),
                _fmt(record["é”æˆç‡å·®åˆ†(pts)"], "{:+.1f}"),
                _fmt(record["å¹³å‡VA/åˆ†å·®åˆ†(å††)"], "{:+.2f}"),
                _fmt(record["æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤å·®åˆ†(å††)"], "{:+,.0f}"),
                _fmt(record["å¹³å‡å¿…è¦è²©å£²å˜ä¾¡(å††)"], "{:,.0f}"),
                _fmt(record["å¹³å‡å¿…è¦è²©å£²å˜ä¾¡å·®åˆ†(å††)"], "{:+,.0f}"),
                _fmt(record["å¹³å‡å¿…è¦è³ƒç‡å·®(å††/åˆ†)"], "{:+.2f}"),
                _fmt(record["å¹³å‡å¿…è¦è³ƒç‡å·®åˆ†(å††/åˆ†)"], "{:+.2f}"),
            ]
        )

    table = Table(table_rows, repeatRows=1)
    table.setStyle(
        TableStyle(
            [
                ("BACKGROUND", (0, 0), (-1, 0), colors.HexColor("#2F6776")),
                ("TEXTCOLOR", (0, 0), (-1, 0), colors.white),
                ("FONTNAME", (0, 0), (-1, 0), "HeiseiMin-W3"),
                ("FONTNAME", (0, 1), (-1, -1), "HeiseiMin-W3"),
                ("ALIGN", (2, 1), (-1, -1), "RIGHT"),
                ("VALIGN", (0, 0), (-1, -1), "MIDDLE"),
                ("ROWBACKGROUNDS", (0, 1), (-1, -1), [colors.whitesmoke, colors.HexColor("#F4F7FA")]),
                ("GRID", (0, 0), (-1, -1), 0.5, colors.HexColor("#D7E2EA")),
                ("LEFTPADDING", (0, 0), (-1, -1), 6),
                ("RIGHTPADDING", (0, 0), (-1, -1), 6),
            ]
        )
    )
    story.append(table)
    story.append(Spacer(1, 12))

    for record in comparison_records:
        if record["ã‚·ãƒŠãƒªã‚ª"] == "ãƒ™ãƒ¼ã‚¹":
            continue
        parts = [
            f"é”æˆç‡ {_fmt(record['é”æˆç‡å·®åˆ†(pts)'], '{:+.1f}')}pt",
            f"å¹³å‡VA {_fmt(record['å¹³å‡VA/åˆ†å·®åˆ†(å††)'], '{:+.2f}')}å††",
            f"æ—¥æ¬¡VA {_fmt(record['æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤å·®åˆ†(å††)'], '{:+,.0f}')}å††",
        ]
        req_price_part = _fmt(record["å¹³å‡å¿…è¦è²©å£²å˜ä¾¡å·®åˆ†(å††)"], "{:+,.0f}")
        if req_price_part != "-":
            parts.append(f"å¿…è¦è²©å£²å˜ä¾¡ {req_price_part}å††")
        gap_part = _fmt(record["å¹³å‡å¿…è¦è³ƒç‡å·®åˆ†(å††/åˆ†)"], "{:+.2f}")
        if gap_part != "-":
            parts.append(f"å¿…è¦è³ƒç‡å·® {gap_part}å††/åˆ†")
        summary_line = f"{record['ã‚·ãƒŠãƒªã‚ª']}: " + " / ".join(parts)
        story.append(Paragraph(summary_line, styles["Normal"]))

    doc.build(story)
    pdf_buffer.seek(0)

    download_cols = st.columns(2)
    with download_cols[0]:
        st.download_button(
            "Excelã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            data=excel_buffer.getvalue(),
            file_name="scenario_comparison.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )
    with download_cols[1]:
        st.download_button(
            "PDFã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            data=pdf_buffer.getvalue(),
            file_name="scenario_comparison.pdf",
            mime="application/pdf",
        )
else:
    st.info("æ¯”è¼ƒå¯¾è±¡ã®ã‚·ãƒŠãƒªã‚ªã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")

st.markdown("##### ğŸ“Š æ„Ÿåº¦åˆ†æãƒã‚¤ãƒ©ã‚¤ãƒˆ")
mcol1, mcol2, mcol3, mcol4 = st.columns(4)
mcol1.metric(
    "å¿…è¦è³ƒç‡é”æˆç‡",
    f"{ach_rate:.1f}%" if np.isfinite(ach_rate) else "N/A",
    delta=f"{ach_delta:+.1f}pt" if np.isfinite(ach_delta) else "N/A",
)
mcol2.metric(
    "å¹³å‡VA/åˆ†",
    f"{avg_vapm:.2f}å††" if np.isfinite(avg_vapm) else "N/A",
    delta=f"{vapm_delta:+.2f}å††" if np.isfinite(vapm_delta) else "N/A",
)
mcol3.metric(
    "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤",
    f"{sim_daily_va_total:,.0f}å††" if np.isfinite(sim_daily_va_total) else "N/A",
    delta=f"{daily_delta:+,.0f}å††" if np.isfinite(daily_delta) else "N/A",
)
annual_value = (
    f"{annual_sim_va / 10000:,.1f}ä¸‡å††" if np.isfinite(annual_sim_va) else "N/A"
)
annual_delta_text = (
    f"{annual_delta / 10000:+,.1f}ä¸‡å††" if np.isfinite(annual_delta) else "N/A"
)
mcol4.metric("å¹´é–“åˆ©ç›Šè¦‹è¾¼", annual_value, delta=annual_delta_text)

gcol1, gcol2 = st.columns(2)
gcol1.metric(
    "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡",
    f"{avg_req_price:,.0f}å††" if np.isfinite(avg_req_price) else "N/A",
    delta=(
        f"{req_price_delta_metric:+,.0f}å††"
        if np.isfinite(req_price_delta_metric)
        else "N/A"
    ),
)
gcol2.metric(
    "å¹³å‡å¿…è¦è³ƒç‡ã¨ã®å·®",
    f"{avg_gap:+.2f}å††/åˆ†" if np.isfinite(avg_gap) else "N/A",
    delta=(
        f"{gap_delta_metric:+.2f}å††/åˆ†"
        if np.isfinite(gap_delta_metric)
        else "N/A"
    ),
)

scenario_summary_text = _summarize_scenario_effect(
    ach_delta=ach_delta,
    vapm_delta=vapm_delta,
    daily_delta=daily_delta,
    annual_delta=annual_delta,
    req_price_delta=req_price_delta_metric,
    gap_delta=gap_delta_metric,
)
if scenario_summary_text:
    st.markdown(f"**KPIå¤‰åŒ–ã‚µãƒãƒª:** {scenario_summary_text}")

if active_label == "ãƒ™ãƒ¼ã‚¹" and not any([qp, qc, qv, qm]):
    st.caption("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¡ä»¶ã‚’å¤‰æ›´ã™ã‚‹ã¨å¹´é–“ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆã®æ¦‚ç®—ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
else:
    st.info(
        f"ãƒ•ã‚§ãƒ«ãƒŸæ¨å®š: {_format_fermi_estimate(daily_delta, working_days, active_label)}"
    )

driver_df, driver_messages = _analyze_driver_impacts(
    scenario_template,
    df_base,
    base_metrics_clean,
    price_pct=qp,
    ct_pct=qc,
    volume_pct=qv,
    material_pct=qm,
    be_rate=be_rate,
    req_rate=req_rate,
    delta_low=delta_low,
    delta_high=delta_high,
    working_days=working_days,
)

if driver_messages or not driver_df.empty:
    st.markdown("##### ğŸ§® æ„Ÿåº¦åˆ†æã‚µãƒãƒª")
    for msg in driver_messages:
        st.markdown(f"- {msg}")
    if not driver_df.empty:
        st.caption("å„æ–½ç­–ã‚’å˜ç‹¬ã§é©ç”¨ã—ãŸå ´åˆã®ä¸»è¦KPIå·®åˆ†ã§ã™ï¼ˆä»–ã®å¤‰æ•°ã¯ãƒ™ãƒ¼ã‚¹å€¤ã‚’ä½¿ç”¨ï¼‰ã€‚")
        driver_styled = driver_df.style.format(
            {
                "å¤‰åŒ–ç‡(%)": "{:+.0f}",
                "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤å·®(å††)": "{:+,.0f}",
                "å¹´é–“åˆ©ç›Šå·®(ä¸‡å††)": "{:+,.1f}",
                "å¹³å‡VA/åˆ†å·®(å††)": "{:+.2f}",
                "å¹³å‡å¿…è¦è³ƒç‡å·®(å††/åˆ†)": "{:+.2f}",
                "å¹³å‡å¿…è¦è²©å£²å˜ä¾¡å·®(å††)": "{:+,.0f}",
            },
            na_rep="-",
        )
        st.dataframe(driver_styled, use_container_width=True)

trend_history = st.session_state.get("monthly_trend")
if trend_history is None:
    trend_history = pd.DataFrame(
        columns=[
            "scenario",
            "period",
            "ach_rate",
            "va_per_min",
            "required_rate",
            "be_rate",
            "note",
            "recorded_at",
        ]
    )
    st.session_state["monthly_trend"] = trend_history

with st.expander("ğŸ“ˆ æœˆæ¬¡ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’è¨˜éŒ²", expanded=False):
    st.caption("ç¾åœ¨è¡¨ç¤ºä¸­ã®KPIã‚’å¯¾è±¡æœˆã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚å†åº¦åŒã˜æœˆã‚’ä¿å­˜ã™ã‚‹ã¨ä¸Šæ›¸ãã•ã‚Œã¾ã™ã€‚")
    default_month = st.session_state.get("trend_snapshot_month")
    if not isinstance(default_month, (datetime, date)):
        default_month = pd.Timestamp.today().to_pydatetime()
    col_t1, col_t2, col_t3, col_t4 = st.columns([1.3, 1.1, 1.1, 0.8])
    snapshot_month = col_t1.date_input("å¯¾è±¡å¹´æœˆ", value=default_month, key="trend_month_input")
    st.session_state["trend_snapshot_month"] = snapshot_month
    scen_default_idx = scenario_options.index(scenario_name) if scenario_name in scenario_options else 0
    scenario_for_snapshot = col_t2.selectbox(
        "å¯¾è±¡ã‚·ãƒŠãƒªã‚ª",
        options=scenario_options,
        index=scen_default_idx,
        key="trend_scenario_input",
    )
    note_value = col_t3.text_input("ãƒ¡ãƒ¢ (ä»»æ„)", key="trend_note_input")
    save_snapshot = col_t4.button("ä¿å­˜/æ›´æ–°", key="trend_save_btn")

    if save_snapshot:
        period = _normalize_month(snapshot_month)
        if period is None:
            st.warning("å¯¾è±¡å¹´æœˆã‚’æ­£ã—ãæŒ‡å®šã—ã¦ãã ã•ã„ã€‚")
        else:
            metrics_map = {
                name: (
                    data.get("metrics", {}).get("ach_rate", np.nan),
                    data.get("metrics", {}).get("avg_vapm", np.nan),
                    data.get("df", pd.DataFrame()),
                )
                for name, data in scenario_results.items()
            }
            ach_val, vapm_val, df_candidate = metrics_map.get(
                scenario_for_snapshot,
                (np.nan, np.nan, pd.DataFrame()),
            )
            if df_candidate.empty:
                st.warning("å¯¾è±¡ã‚·ãƒŠãƒªã‚ªã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
            else:
                trend_history = _upsert_trend_record(
                    scenario=scenario_for_snapshot,
                    period=period,
                    ach_rate=ach_val,
                    va_per_min=vapm_val,
                    required_rate=req_rate,
                    be_rate=be_rate,
                    note=note_value,
                )
                st.success(f"{period.strftime('%Y-%m')} ã® {scenario_for_snapshot} ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚")

    trend_history = st.session_state.get("monthly_trend", pd.DataFrame())
    if not trend_history.empty:
        history_display = trend_history.copy()
        history_display["period"] = pd.to_datetime(history_display["period"]).dt.strftime("%Y-%m")
        history_display["ach_rate"] = history_display["ach_rate"].map(lambda x: f"{x:.1f}%" if pd.notna(x) else "-")
        history_display["va_per_min"] = history_display["va_per_min"].map(lambda x: f"{x:.2f}" if pd.notna(x) else "-")
        history_display["required_rate"] = history_display["required_rate"].map(lambda x: f"{x:.3f}" if pd.notna(x) else "-")
        history_display["be_rate"] = history_display["be_rate"].map(lambda x: f"{x:.3f}" if pd.notna(x) else "-")
        history_display = history_display[["period", "scenario", "ach_rate", "va_per_min", "required_rate", "be_rate", "note"]]
        st.dataframe(history_display, use_container_width=True)

        option_map = {
            f"{pd.to_datetime(row['period']).strftime('%Y-%m')}ï½œ{row['scenario']}": (
                pd.to_datetime(row["period"]),
                row["scenario"],
            )
            for _, row in trend_history.sort_values(["period", "scenario"]).iterrows()
        }
        del_col1, del_col2 = st.columns([1.6, 0.4])
        delete_choice = del_col1.selectbox(
            "å‰Šé™¤ã™ã‚‹è¨˜éŒ²",
            options=["é¸æŠãªã—"] + list(option_map.keys()),
            key="trend_delete_select",
        )
        if del_col2.button("å‰Šé™¤", key="trend_delete_btn") and delete_choice != "é¸æŠãªã—":
            target_period, target_scenario = option_map[delete_choice]
            updated = trend_history[
                ~(
                    (trend_history["scenario"] == target_scenario)
                    & (pd.to_datetime(trend_history["period"]) == target_period)
                )
            ].reset_index(drop=True)
            st.session_state["monthly_trend"] = updated
            st.success(f"{target_period.strftime('%Y-%m')} ã® {target_scenario} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

# === KPI Targets & Cards ===
role = st.session_state.get("role", "ä¸€èˆ¬")
st.session_state.setdefault("target_req_rate", req_rate)
st.session_state.setdefault("target_ach_rate", ach_rate)
with st.sidebar.expander("KPIç›®æ¨™è¨­å®š", expanded=False):
    if role in ("çµŒå–¶è€…", "ç®¡ç†è€…"):
        st.session_state["target_req_rate"] = st.number_input(
            "ç›®æ¨™å¿…è¦è³ƒç‡ (å††/åˆ†)", value=st.session_state["target_req_rate"], format="%.3f"
        )
        st.session_state["target_ach_rate"] = st.number_input(
            "ç›®æ¨™é”æˆç‡ (%)", value=st.session_state["target_ach_rate"], format="%.1f"
        )
    else:
        st.number_input(
            "ç›®æ¨™å¿…è¦è³ƒç‡ (å††/åˆ†)", value=st.session_state["target_req_rate"], format="%.3f", disabled=True
        )
        st.number_input(
            "ç›®æ¨™é”æˆç‡ (%)", value=st.session_state["target_ach_rate"], format="%.1f", disabled=True
        )
target_req_rate = st.session_state["target_req_rate"]
target_ach_rate = st.session_state["target_ach_rate"]

anomaly_all_df = detect_anomalies(df_view)
review_state = st.session_state.get("anomaly_review", {})
legacy_refreshed = False
for _key, record in list(review_state.items()):
    if not isinstance(record, dict):
        continue
    resolved = _normalize_review_classification(record)
    if resolved and record.get("classification") != resolved:
        record["classification"] = resolved
        legacy_refreshed = True
    if resolved and not record.get("classification_label"):
        record["classification_label"] = ANOMALY_REVIEW_LABELS.get(resolved)
        legacy_refreshed = True
if legacy_refreshed:
    st.session_state["anomaly_review"] = review_state
if not anomaly_all_df.empty:
    key_series = anomaly_all_df["product_no"].apply(_sku_to_str) + "::" + anomaly_all_df["metric"].astype(str)
    anomaly_all_df = anomaly_all_df.assign(key=key_series)
    anomaly_all_df["decision"] = anomaly_all_df["key"].map(
        lambda k: review_state.get(k, {}).get("decision")
    )
    anomaly_all_df["classification"] = anomaly_all_df["key"].map(
        lambda k: _normalize_review_classification(review_state.get(k, {}))
    )
    anomaly_all_df["classification_label"] = anomaly_all_df["classification"].map(
        lambda code: ANOMALY_REVIEW_LABELS.get(code)
    )
    anomaly_all_df["note"] = anomaly_all_df["key"].map(lambda k: review_state.get(k, {}).get("note"))
    anomaly_all_df["corrected_value"] = anomaly_all_df["key"].map(
        lambda k: review_state.get(k, {}).get("corrected_value")
    )
    anomaly_all_df["last_decided_at"] = anomaly_all_df["key"].map(
        lambda k: review_state.get(k, {}).get("timestamp")
    )
    anomaly_df = anomaly_all_df[anomaly_all_df["classification"] != "exception"].copy()
else:
    anomaly_df = anomaly_all_df

if not anomaly_df.empty:
    anomaly_summary_stats = (
        anomaly_df.groupby("metric")
        .agg(count=("metric", "size"), severity_mean=("severity", "mean"))
        .reset_index()
        .sort_values(["count", "severity_mean"], ascending=[False, False])
    )
else:
    anomaly_summary_stats = pd.DataFrame(columns=["metric", "count", "severity_mean"])

gap_df = df_view.copy()
gap_df["va_per_min"] = pd.to_numeric(gap_df.get("va_per_min"), errors="coerce")
gap_df["gap"] = req_rate - gap_df["va_per_min"]
gap_df = gap_df[gap_df["gap"] > 0].copy()

empty_series = pd.Series(np.nan, index=gap_df.index, dtype="float64")
actual_price = pd.to_numeric(gap_df.get("actual_unit_price", empty_series), errors="coerce")
material_cost = pd.to_numeric(gap_df.get("material_unit_cost", empty_series), errors="coerce")
minutes_per_unit = pd.to_numeric(gap_df.get("minutes_per_unit", empty_series), errors="coerce")
daily_qty = pd.to_numeric(gap_df.get("daily_qty", empty_series), errors="coerce")
required_price = pd.to_numeric(gap_df.get("required_selling_price", empty_series), errors="coerce")
gp_per_unit = pd.to_numeric(gap_df.get("gp_per_unit", empty_series), errors="coerce")

gap_df["price_improve"] = (required_price - actual_price).clip(lower=0)
if req_rate:
    target_minutes = gp_per_unit / req_rate
else:
    target_minutes = pd.Series(np.nan, index=gap_df.index, dtype="float64")
gap_df["ct_improve"] = (minutes_per_unit - target_minutes).clip(lower=0)
gap_df["material_improve"] = (
    material_cost - (actual_price - req_rate * minutes_per_unit)
).clip(lower=0)

gap_df["price_improve"] = gap_df["price_improve"].fillna(0.0)
gap_df["ct_improve"] = gap_df["ct_improve"].fillna(0.0)
gap_df["material_improve"] = gap_df["material_improve"].fillna(0.0)

annual_days = float(base_params.get("working_days", DEFAULT_PARAMS["working_days"]))
default_monthly_days = max(1.0, round(annual_days / 12.0, 1))
priority_state = st.session_state.setdefault("priority_controls", {})
priority_state.setdefault("working_days_per_month", default_monthly_days)
priority_state.setdefault("price_cost", 200000.0)
priority_state.setdefault("ct_cost", 600000.0)
priority_state.setdefault("material_cost", 400000.0)
priority_state.setdefault("roi_limit", 3.0)
priority_state.setdefault("apply_roi_filter", False)
priority_state.setdefault("roi_priority_high", 2.0)
priority_state.setdefault("roi_priority_medium", 4.0)
priority_state.setdefault("investment_executable", 500000.0)
priority_state.setdefault(
    "action_filter",
    ["ä¾¡æ ¼æ”¹å–„", "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ æ”¹å–„", "ææ–™æ”¹å–„"],
)

action_labels = {
    "price": "ä¾¡æ ¼æ”¹å–„",
    "ct": "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ æ”¹å–„",
    "material": "ææ–™æ”¹å–„",
    "none": "æ¨å¥¨ãªã—",
}
action_primary = [action_labels["price"], action_labels["ct"], action_labels["material"]]
action_all_options = action_primary + [action_labels["none"]]

with st.expander("å„ªå…ˆé †ä½ä»˜ã‘ãƒ­ã‚¸ãƒƒã‚¯ & ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¨­å®š", expanded=False):
    st.markdown(
        """
        **ç®—å‡ºæ–¹æ³•**
        - ã‚®ãƒ£ãƒƒãƒ—ï¼ˆæœˆæ¬¡ä¸è¶³é¡ï¼‰= (å¿…è¦è³ƒç‡ âˆ’ ç¾çŠ¶VA/åˆ†) Ã— åˆ†/å€‹ Ã— æ—¥ç”£æ•° Ã— ç¨¼åƒæ—¥æ•°
        - ä¾¡æ ¼/ææ–™æ”¹å–„ã®æœˆæ¬¡åŠ¹æœ = å˜ä¾¡å·®é¡ Ã— æ—¥ç”£æ•° Ã— ç¨¼åƒæ—¥æ•°
        - ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ æ”¹å–„ã®æœˆæ¬¡åŠ¹æœ = æ”¹å–„åˆ†(åˆ†/å€‹) Ã— æ—¥ç”£æ•° Ã— ç¨¼åƒæ—¥æ•° Ã— å¿…è¦è³ƒç‡
        - å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ = æœˆæ¬¡åŠ¹æœ Ã· æƒ³å®šæŠ•è³‡é¡ï¼ˆ= 1ã‹æœˆã‚ãŸã‚Šã®ROIï¼‰
        - æƒ³å®šROI(æœˆ) = æƒ³å®šæŠ•è³‡é¡ Ã· æœˆæ¬¡åŠ¹æœ
        """
    )
    conf_left, conf_right = st.columns(2)
    with conf_left:
        priority_state["working_days_per_month"] = st.number_input(
            "æœˆã‚ãŸã‚Šç¨¼åƒæ—¥æ•°",
            min_value=1.0,
            max_value=31.0,
            value=float(priority_state["working_days_per_month"]),
            step=1.0,
        )
        priority_state["price_cost"] = st.number_input(
            "ä¾¡æ ¼æ”¹å–„ã®æƒ³å®šæŠ•è³‡é¡ (å††)",
            min_value=1.0,
            value=float(priority_state["price_cost"]),
            step=50000.0,
        )
        priority_state["ct_cost"] = st.number_input(
            "ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ æ”¹å–„ã®æƒ³å®šæŠ•è³‡é¡ (å††)",
            min_value=1.0,
            value=float(priority_state["ct_cost"]),
            step=50000.0,
        )
        priority_state["material_cost"] = st.number_input(
            "ææ–™æ”¹å–„ã®æƒ³å®šæŠ•è³‡é¡ (å††)",
            min_value=1.0,
            value=float(priority_state["material_cost"]),
            step=50000.0,
        )
    with conf_right:
        priority_state["roi_limit"] = st.number_input(
            "ROIä¸Šé™ (æœˆ)",
            min_value=0.5,
            value=float(priority_state["roi_limit"]),
            step=0.5,
            format="%.1f",
        )
        priority_state["apply_roi_filter"] = st.checkbox(
            "ROIä¸Šé™ã§çµã‚Šè¾¼ã‚€",
            value=bool(priority_state["apply_roi_filter"]),
        )
        roi_high_input = st.number_input(
            "å„ªå…ˆåº¦ã€é«˜ã€ã¨åˆ¤å®šã™ã‚‹ROIé–¾å€¤ (æœˆ)",
            min_value=0.5,
            value=float(priority_state["roi_priority_high"]),
            step=0.5,
            format="%.1f",
        )
        priority_state["roi_priority_high"] = roi_high_input
        roi_medium_default = max(
            float(priority_state.get("roi_priority_medium", roi_high_input)),
            roi_high_input,
        )
        roi_medium_input = st.number_input(
            "å„ªå…ˆåº¦ã€ä¸­ã€ã®ä¸Šé™ROIé–¾å€¤ (æœˆ)",
            min_value=roi_high_input,
            value=roi_medium_default,
            step=0.5,
            format="%.1f",
        )
        priority_state["roi_priority_medium"] = max(roi_medium_input, roi_high_input)
        priority_state["investment_executable"] = st.number_input(
            "å³å®Ÿè¡Œã§ãã‚‹æŠ•è³‡é¡ã®ä¸Šé™ (å††)",
            min_value=0.0,
            value=float(priority_state["investment_executable"]),
            step=50000.0,
            format="%.0f",
        )
        default_actions = [
            opt
            for opt in priority_state.get("action_filter", action_primary)
            if opt in action_all_options
        ]
        if not default_actions:
            default_actions = action_primary
        priority_state["action_filter"] = st.multiselect(
            "è¡¨ç¤ºã™ã‚‹æ–½ç­–ã‚¿ã‚¤ãƒ—",
            options=action_all_options,
            default=default_actions,
        )
    st.markdown(
        f"- ROIãŒ{priority_state['roi_priority_high']:.1f}ãƒ¶æœˆæœªæº€ãªã‚‰å„ªå…ˆåº¦ã€é«˜ã€ã€"
        f"{priority_state['roi_priority_medium']:.1f}ãƒ¶æœˆã¾ã§ã¯ã€ä¸­ã€ã€ãã‚Œä»¥ä¸Šã¯ã€ä½ã€ã¨å®šç¾©ã—ã¾ã™ã€‚"
    )
    st.markdown(
        f"- æƒ³å®šæŠ•è³‡é¡ãŒ{priority_state['investment_executable']:,.0f}å††ä»¥ä¸‹ãªã‚‰ã€å³å®Ÿè¡Œå¯ã€ã€"
        "è¶…ãˆã‚‹å ´åˆã¯ã€è¦æŠ•è³‡æ¤œè¨ã€ã¨è¡¨ç¤ºã—ã¾ã™ã€‚"
    )
    st.caption(
        "æŠ•è³‡é¡ã¯SKUã”ã¨ã®æœˆæ¬¡åŠ¹æœã«ä¸€å¾‹ã§é©ç”¨ã—ã¾ã™ã€‚ROI = æƒ³å®šæŠ•è³‡é¡ Ã· æœˆæ¬¡åŠ¹æœã€‚"
    )

working_days_per_month = float(priority_state.get("working_days_per_month", default_monthly_days))
price_cost = float(priority_state.get("price_cost", 1.0))
ct_cost = float(priority_state.get("ct_cost", 1.0))
material_cost = float(priority_state.get("material_cost", 1.0))
roi_priority_high = float(priority_state.get("roi_priority_high", 2.0))
roi_priority_medium = max(
    float(priority_state.get("roi_priority_medium", roi_priority_high * 2.0)),
    roi_priority_high,
)
investment_threshold = float(priority_state.get("investment_executable", 500000.0))
roi_limit = float(priority_state.get("roi_limit", 3.0))
raw_selected_actions = priority_state.get("action_filter", action_primary)
if not raw_selected_actions:
    selected_actions = action_all_options
else:
    selected_actions = [
        opt for opt in raw_selected_actions if opt in action_all_options
    ]
    if not selected_actions:
        selected_actions = action_all_options

gap_vals = pd.to_numeric(gap_df["gap"], errors="coerce").fillna(0.0)
minutes_vals = minutes_per_unit.fillna(0.0)
qty_vals = daily_qty.fillna(0.0)
price_vals = pd.to_numeric(gap_df["price_improve"], errors="coerce").fillna(0.0)
ct_vals = pd.to_numeric(gap_df["ct_improve"], errors="coerce").fillna(0.0)
material_vals = pd.to_numeric(gap_df["material_improve"], errors="coerce").fillna(0.0)

gap_df["monthly_shortfall_value"] = gap_vals * minutes_vals * qty_vals * working_days_per_month
gap_df["price_monthly_benefit"] = price_vals * qty_vals * working_days_per_month
gap_df["ct_monthly_benefit"] = ct_vals * req_rate * qty_vals * working_days_per_month
gap_df["material_monthly_benefit"] = material_vals * qty_vals * working_days_per_month

price_benefit = pd.to_numeric(gap_df["price_monthly_benefit"], errors="coerce")
ct_benefit = pd.to_numeric(gap_df["ct_monthly_benefit"], errors="coerce")
material_benefit = pd.to_numeric(gap_df["material_monthly_benefit"], errors="coerce")

gap_df["price_roi_months"] = np.where(price_benefit > 0, price_cost / price_benefit, np.nan)
gap_df["ct_roi_months"] = np.where(ct_benefit > 0, ct_cost / ct_benefit, np.nan)
gap_df["material_roi_months"] = np.where(
    material_benefit > 0, material_cost / material_benefit, np.nan
)

gap_df["price_score"] = np.where(price_benefit > 0, price_benefit / price_cost, 0.0)
gap_df["ct_score"] = np.where(ct_benefit > 0, ct_benefit / ct_cost, 0.0)
gap_df["material_score"] = np.where(
    material_benefit > 0, material_benefit / material_cost, 0.0
)

action_map = {
    "price": {
        "label": action_labels["price"],
        "score_col": "price_score",
        "roi_col": "price_roi_months",
        "benefit_col": "price_monthly_benefit",
        "cost": price_cost,
    },
    "ct": {
        "label": action_labels["ct"],
        "score_col": "ct_score",
        "roi_col": "ct_roi_months",
        "benefit_col": "ct_monthly_benefit",
        "cost": ct_cost,
    },
    "material": {
        "label": action_labels["material"],
        "score_col": "material_score",
        "roi_col": "material_roi_months",
        "benefit_col": "material_monthly_benefit",
        "cost": material_cost,
    },
}

score_cols = [meta["score_col"] for meta in action_map.values()]
score_df = gap_df[score_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0)
best_idx = score_df.idxmax(axis=1)
best_scores = score_df.max(axis=1)
gap_df["best_score"] = best_scores
gap_df["best_action_key"] = np.where(
    best_scores > 0, best_idx.str.replace("_score", "", regex=False), "none"
)
gap_df["best_action_label"] = gap_df["best_action_key"].map(
    {key: meta["label"] for key, meta in action_map.items()}
).fillna(action_labels["none"])
gap_df.loc[gap_df["best_action_key"] == "none", "best_action_label"] = action_labels["none"]

gap_df["best_roi_months"] = np.nan
gap_df["best_monthly_benefit"] = 0.0
gap_df["best_investment"] = np.nan
for key, meta in action_map.items():
    mask = gap_df["best_action_key"] == key
    gap_df.loc[mask, "best_roi_months"] = gap_df.loc[mask, meta["roi_col"]]
    gap_df.loc[mask, "best_monthly_benefit"] = gap_df.loc[mask, meta["benefit_col"]]
    gap_df.loc[mask, "best_investment"] = meta["cost"]
gap_df["best_roi_months"] = gap_df["best_roi_months"].replace([np.inf, -np.inf], np.nan)
gap_df["roi_months"] = gap_df["best_roi_months"]


def _classify_priority_rank(roi_value: Any) -> str:
    if roi_value is None or pd.isna(roi_value):
        return "æƒ…å ±ä¸è¶³"
    if roi_value <= roi_priority_high:
        return "é«˜"
    if roi_value <= roi_priority_medium:
        return "ä¸­"
    return "ä½"


def _classify_execution(cost_value: Any) -> str:
    if cost_value is None or pd.isna(cost_value):
        return "æŠ•è³‡é¡æœªè¨­å®š"
    if cost_value <= investment_threshold:
        return "å³å®Ÿè¡Œå¯"
    return "è¦æŠ•è³‡æ¤œè¨"


gap_df["priority_rank"] = gap_df["best_roi_months"].apply(_classify_priority_rank)
gap_df["execution_feasibility"] = gap_df["best_investment"].apply(_classify_execution)

filtered_gap_df = gap_df.copy()
if selected_actions:
    filtered_gap_df = filtered_gap_df[filtered_gap_df["best_action_label"].isin(selected_actions)]
if priority_state.get("apply_roi_filter", False):
    filtered_gap_df = filtered_gap_df[
        filtered_gap_df["best_roi_months"].notna() & (filtered_gap_df["best_roi_months"] <= roi_limit)
    ]

top_list = filtered_gap_df.sort_values(
    ["best_score", "best_monthly_benefit", "gap"], ascending=[False, False, False]
).head(20)
top_cards = top_list.head(5)

filter_summaries: List[str] = []
if priority_state.get("apply_roi_filter", False):
    filter_summaries.append(f"ROIâ‰¦{roi_limit:.1f}ãƒ¶æœˆ")
if set(selected_actions) != set(action_primary):
    filter_summaries.append("æ–½ç­–ã‚¿ã‚¤ãƒ—: " + ", ".join(selected_actions))

category_summary = summarize_segment_performance(df_view, req_rate, "category")
customer_summary = summarize_segment_performance(df_view, req_rate, "major_customer")


def _render_target_badge(col, text: str) -> None:
    col.markdown(
        f"<div class='metric-badge'><span style='background-color:#E0EEF4;padding:4px 10px;border-radius:999px;font-size:0.8em;'>ğŸ¯{text}</span></div>",
        unsafe_allow_html=True,
    )


def _format_segment_prefix(segment: Any, label: str) -> str:
    """Return a natural language prefix for segment commentary."""

    seg = "æœªè¨­å®š" if segment in [None, "", "nan"] else str(segment)
    if label == "ã‚«ãƒ†ã‚´ãƒªãƒ¼":
        return f"ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€{seg}ã€"
    if label == "ä¸»è¦é¡§å®¢":
        return f"ä¸»è¦é¡§å®¢ã€{seg}ã€å‘ã‘å•†å“"
    return f"{seg}{label}"


def _compose_segment_insight(summary_df: pd.DataFrame, label: str) -> str:
    if summary_df is None or summary_df.empty:
        return f"{label}åˆ¥ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Excelã«{label}åˆ—ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"

    df = summary_df.dropna(subset=["avg_va_per_min"]).copy()
    if df.empty:
        return f"{label}åˆ¥ã®å¹³å‡VA/åˆ†ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚"

    tol = 0.05
    df = df.sort_values("avg_gap", ascending=False).reset_index(drop=True)
    best = df.iloc[0]
    diff_best = float(best.get("avg_gap", 0.0))
    abs_best = abs(diff_best)

    if abs_best <= tol:
        first = (
            f"{_format_segment_prefix(best['segment'], label)}ã¯å¹³å‡VA/åˆ†ãŒ{best['avg_va_per_min']:.1f}å††ã§"
            f"å¿…è¦è³ƒç‡ã¨ã»ã¼åŒæ°´æº–ã§ã™ï¼ˆé”æˆç‡{best['ach_rate_pct']:.1f}%ï¼‰ã€‚"
        )
    elif diff_best > 0:
        first = (
            f"{_format_segment_prefix(best['segment'], label)}ã¯å¹³å‡VA/åˆ†ãŒ{best['avg_va_per_min']:.1f}å††ã§"
            f"å¿…è¦è³ƒç‡ã‚’{abs_best:.1f}å††ä¸Šå›ã£ã¦ã„ã‚‹ãŸã‚åˆ©ç›Šç‡ãŒé«˜ã„"
            f"ï¼ˆé”æˆç‡{best['ach_rate_pct']:.1f}%ï¼‰ã€‚"
        )
    else:
        first = (
            f"{_format_segment_prefix(best['segment'], label)}ã¯å¹³å‡VA/åˆ†ãŒ{best['avg_va_per_min']:.1f}å††ã§"
            f"å¿…è¦è³ƒç‡ã‚’{abs_best:.1f}å††ä¸‹å›ã£ã¦ã„ã‚‹ãŸã‚åç›Šæ€§ã«èª²é¡ŒãŒã‚ã‚Šã¾ã™"
            f"ï¼ˆé”æˆç‡{best['ach_rate_pct']:.1f}%ï¼‰ã€‚"
        )

    if len(df) == 1:
        return first

    negatives = df[df["avg_gap"] < -tol]
    if not negatives.empty:
        worst = negatives.sort_values("avg_gap").iloc[0]
        diff_worst = float(abs(worst.get("avg_gap", 0.0)))
        second = (
            f"ä¸€æ–¹ã€{_format_segment_prefix(worst['segment'], label)}ã¯å¹³å‡VA/åˆ†ãŒ{worst['avg_va_per_min']:.1f}å††ã§"
            f"å¿…è¦è³ƒç‡ã‚’{diff_worst:.1f}å††ä¸‹å›ã£ã¦ã„ã¾ã™"
        )
        roi = worst.get("avg_roi_months")
        if roi is not None and not pd.isna(roi):
            second += f"ï¼ˆæœªé”SKUã®å¹³å‡ROIå›å¾©æœŸé–“ã¯{float(roi):.1f}ãƒ¶æœˆï¼‰"
        second += "ã€‚"
        return f"{first} {second}"

    if (df["avg_gap"] > tol).all():
        return f"{first} å…¨ã¦ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒå¿…è¦è³ƒç‡ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã„ã¾ã™ã€‚"

    worst = df.sort_values("avg_gap").iloc[0]
    diff_worst = abs(float(worst.get("avg_gap", 0.0)))
    second = (
        f"ä»–ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚‚å¿…è¦è³ƒç‡ã¨ã®å·®ã¯æœ€å¤§ã§ã‚‚{diff_worst:.1f}å††ã«åã¾ã£ã¦ã„ã¾ã™ã€‚"
    )
    return f"{first} {second}"


def _build_segment_highlights(summary_df: pd.DataFrame, label: str) -> List[str]:
    """Create bullet style highlights for segment performance."""

    if summary_df is None or summary_df.empty:
        return []

    df = summary_df.dropna(subset=["avg_gap"]).copy()
    if df.empty:
        return []

    tol = 0.05
    highlights: List[str] = []

    positive = df[df["avg_gap"] > tol].sort_values("avg_gap", ascending=False)
    if not positive.empty:
        row = positive.iloc[0]
        gap_val = abs(float(row["avg_gap"]))
        highlights.append(
            f"{_format_segment_prefix(row['segment'], label)}ã¯å¿…è¦è³ƒç‡ã‚’{gap_val:.1f}å††ä¸Šå›ã‚Šã€é”æˆç‡ã¯{row['ach_rate_pct']:.1f}%ã§ã™ã€‚"
        )

    negative = df[df["avg_gap"] < -tol].sort_values("avg_gap")
    if not negative.empty:
        row = negative.iloc[0]
        gap_val = abs(float(row["avg_gap"]))
        roi = row.get("avg_roi_months")
        roi_txt = ""
        if roi is not None and not pd.isna(roi):
            roi_txt = f"ï¼ˆæœªé”SKUã®å¹³å‡ROI {float(roi):.1f}ãƒ¶æœˆï¼‰"
        highlights.append(
            f"{_format_segment_prefix(row['segment'], label)}ã¯å¿…è¦è³ƒç‡ã‚’{gap_val:.1f}å††ä¸‹å›ã£ã¦ãŠã‚Šæ”¹å–„ä½™åœ°ãŒã‚ã‚Šã¾ã™{roi_txt}ã€‚"
        )

    if not highlights:
        highlights.append(f"{label}åˆ¥ã§ã¯å¿…è¦è³ƒç‡ã¨ã®å·®ãŒå°ã•ãæ¦‚ã­åŸºæº–æ°´æº–ã§ã™ã€‚")

    return highlights


def _render_segment_tab(
    summary_df: pd.DataFrame, label: str, req_rate: float
) -> None:
    if summary_df is None or summary_df.empty:
        st.info(f"{label}æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚Excelã«{label}åˆ—ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        return

    chart_df = summary_df.copy()
    chart = (
        alt.Chart(chart_df)
        .mark_bar(color=PASTEL_ACCENT)
        .encode(
            x=alt.X("segment:N", sort="-y", title=label),
            y=alt.Y("avg_va_per_min:Q", title="å¹³å‡VA/åˆ† (å††)"),
            tooltip=[
                alt.Tooltip("segment:N", title=label),
                alt.Tooltip("avg_va_per_min:Q", title="å¹³å‡VA/åˆ†", format=".1f"),
                alt.Tooltip("ach_rate_pct:Q", title="é”æˆç‡", format=".1f"),
                alt.Tooltip("avg_gap:Q", title="å¿…è¦è³ƒç‡å·®", format="+.1f"),
            ],
        )
        .properties(height=360)
    )
    rule_df = pd.DataFrame({"req_rate": [req_rate]})
    rule = alt.Chart(rule_df).mark_rule(color="#E07A5F", strokeDash=[6, 4]).encode(
        y="req_rate:Q"
    )
    st.altair_chart(chart + rule, use_container_width=True)

    display = summary_df.copy()
    display = display.rename(columns={"segment": label, "sku_count": "SKUæ•°"})
    display["é”æˆç‡"] = display["ach_rate_pct"].map(
        lambda x: f"{x:.1f}%" if pd.notna(x) else "-"
    )
    display["å¹³å‡VA/åˆ†"] = display["avg_va_per_min"].map(
        lambda x: f"{x:.1f}" if pd.notna(x) else "-"
    )
    display["å¿…è¦è³ƒç‡å·®"] = display["avg_gap"].map(
        lambda x: f"{x:+.1f}" if pd.notna(x) else "-"
    )
    display["å¹³å‡ROI(æœˆ)"] = display["avg_roi_months"].map(
        lambda x: "-" if pd.isna(x) else f"{x:.1f}"
    )
    display = display[
        [label, "SKUæ•°", "é”æˆç‡", "å¹³å‡VA/åˆ†", "å¿…è¦è³ƒç‡å·®", "å¹³å‡ROI(æœˆ)"]
    ]
    st.dataframe(display, use_container_width=True)
    st.caption("â€» å¹³å‡ROI(æœˆ)ã¯æœªé”SKUã®ã¿ã‚’å¯¾è±¡ã¨ã—ãŸã‚®ãƒ£ãƒƒãƒ—è§£æ¶ˆã®ç›®å®‰ã§ã™ã€‚")
    st.info(_compose_segment_insight(summary_df, label))


col1, col2, col3, col5 = st.columns([1, 1, 1, 1])
_render_target_badge(col1, f"{target_req_rate:,.3f}")
col1.metric(
    "å¿…è¦è³ƒç‡ (å††/åˆ†)", f"{req_rate:,.3f}", delta=f"{req_rate - target_req_rate:+.3f}"
)
_render_target_badge(col2, f"{target_ach_rate:.1f}%")
col2.metric(
    "å¿…è¦è³ƒç‡é”æˆç‡ (%)", f"{ach_rate:.1f}", delta=f"{ach_rate - target_ach_rate:+.1f}"
)
col3.metric("æç›Šåˆ†å²è³ƒç‡ (å††/åˆ†)", f"{be_rate:,.3f}")
with col5:
    dq_label = f"æ¬ {miss_count} å¤–{out_count} é‡{dup_count} / {affected_skus}SKU"
    st.markdown(
        f"<a href='#dq_errors' style='background-color:#F28B82;color:#1F2A44;padding:6px 10px;border-radius:999px;text-decoration:none;font-weight:600;display:inline-block;'>{dq_label}</a>",
        unsafe_allow_html=True,
    )

kpi_records: List[Dict[str, Any]] = []
for scen_name in selected_scenarios:
    scen_data = scenario_results.get(scen_name)
    if not scen_data:
        continue
    metrics = scen_data.get("metrics", {})
    adjustments = scen_data.get("adjustments", {})
    display_name = scen_name
    if scen_name != "ãƒ™ãƒ¼ã‚¹":
        display_name = f"{scen_name} ({_format_adjustment_summary(adjustments)})"
    kpi_records.append(
        {
            "scenario": scen_name,
            "display": display_name,
            "KPI": "å¿…è¦è³ƒç‡é”æˆSKUæ¯”ç‡",
            "value": metrics.get("ach_rate", np.nan),
        }
    )
    kpi_records.append(
        {
            "scenario": scen_name,
            "display": display_name,
            "KPI": "å¹³å‡ ä»˜åŠ ä¾¡å€¤/åˆ†",
            "value": metrics.get("avg_vapm", np.nan),
        }
    )
kpi_df = pd.DataFrame(kpi_records)
if kpi_df.empty:
    st.info("æ¯”è¼ƒå¯¾è±¡ã®ã‚·ãƒŠãƒªã‚ªã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
else:
    fig_kpi = px.bar(
        kpi_df,
        x="KPI",
        y="value",
        color="display",
        barmode="group",
        color_discrete_sequence=PASTEL_PALETTE,
    )
    fig_kpi.update_traces(opacity=0.85)
    fig_kpi.update_yaxes(gridcolor="#D7E2EA")
    fig_kpi.update_xaxes(gridcolor="#D7E2EA")
    fig_kpi.update_layout(legend_title_text="ã‚·ãƒŠãƒªã‚ª")
    fig_kpi = _apply_plotly_theme(fig_kpi, legend_bottom=True)
    st.plotly_chart(fig_kpi, use_container_width=True, config=_build_plotly_config())

ai_insights = {
    "top_underperformers": top_list[
        ["product_name", "gap", "roi_months", "best_action_label", "best_monthly_benefit"]
    ].head(3).to_dict("records")
    if not top_list.empty
    else [],
    "anomaly_summary": anomaly_summary_stats.to_dict("records"),
    "anomaly_records": anomaly_df.sort_values("severity", ascending=False).head(5).to_dict("records")
    if not anomaly_df.empty
    else [],
    "dq_summary": {"missing": miss_count, "negative": out_count, "duplicate": dup_count},
    "segment_category": category_summary.head(5).to_dict("records"),
    "segment_customer": customer_summary.head(5).to_dict("records"),
}

st.subheader("AIã‚³ãƒ¡ãƒ³ãƒˆ")
if st.button("AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ"):
    with st.spinner("ç”Ÿæˆä¸­..."):
        st.session_state["dashboard_ai_comment"] = _generate_dashboard_comment(
            df_view,
            {"ach_rate": ach_rate, "req_rate": req_rate, "be_rate": be_rate},
            ai_insights,
        )
st.markdown(st.session_state.get("dashboard_ai_comment", ""))

st.markdown("<div id='dq_errors'></div>", unsafe_allow_html=True)
st.subheader("ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¨ãƒ©ãƒ¼ä¸€è¦§")
if dq_df.empty:
    st.success("ã‚¨ãƒ©ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    dq_display = dq_df.rename(
        columns={
            "product_no": "è£½å“ç•ªå·",
            "product_name": "è£½å“å",
            "type": "ç¨®åˆ¥",
            "column": "é …ç›®",
        }
    )
    dq_display.insert(0, "é™¤å¤–", dq_display["è£½å“ç•ªå·"].isin(excluded_skus))
    edited = st.data_editor(dq_display, use_container_width=True, key="dq_editor")
    new_excluded = edited[edited["é™¤å¤–"]]["è£½å“ç•ªå·"].unique().tolist()
    if set(new_excluded) != set(excluded_skus):
        st.session_state["dq_exclude_skus"] = new_excluded
        st.rerun()

st.subheader("ç•°å¸¸å€¤ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
if anomaly_df.empty:
    if anomaly_all_df.empty:
        st.success("çµ±è¨ˆçš„ãªç•°å¸¸å€¤ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("æ¤œå‡ºã•ã‚ŒãŸç•°å¸¸å€¤ã¯ã™ã¹ã¦ã€ä¾‹å¤–çš„ãªå€¤ã€ã¨ã—ã¦é™¤å¤–æ¸ˆã¿ã§ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ä¸‹éƒ¨ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰å†è©•ä¾¡ã§ãã¾ã™ã€‚")
else:
    highlight = anomaly_df.sort_values("severity", ascending=False).head(3)
    if not highlight.empty:
        cols = st.columns(len(highlight))
        for col, row in zip(cols, highlight.to_dict("records")):
            direction = "ä¸ŠæŒ¯ã‚Œ" if row.get("direction") == "high" else "ä¸‹æŒ¯ã‚Œ"
            val_txt = "N/A" if pd.isna(row.get("value")) else f"{row['value']:.2f}"
            col.metric(
                f"{row.get('product_name', 'ä¸æ˜')} ({row.get('metric', '-')})",
                val_txt,
                delta=f"{direction} zâ‰ˆ{row.get('severity', 0):.1f}",
            )

    if not anomaly_summary_stats.empty:
        summary_df = anomaly_summary_stats.rename(
            columns={"metric": "æŒ‡æ¨™", "count": "ä»¶æ•°", "severity_mean": "å¹³å‡é€¸è„±"}
        )
        st.dataframe(summary_df, use_container_width=True)

    detail_source = (
        anomaly_df.sort_values("severity", ascending=False)
        .head(20)
        .drop(
            columns=[
                "key",
                "decision",
                "classification",
                "classification_label",
                "note",
                "corrected_value",
                "last_decided_at",
            ],
            errors="ignore",
        )
    )
    detail_df = detail_source.rename(
        columns={
            "product_no": "è£½å“ç•ªå·",
            "product_name": "è£½å“å",
            "metric": "æŒ‡æ¨™",
            "value": "å€¤",
            "direction": "æ–¹å‘",
            "severity": "é€¸è„±åº¦",
            "median": "ä¸­å¤®å€¤",
            "iqr_lower": "IQRä¸‹é™",
            "iqr_upper": "IQRä¸Šé™",
        }
    )
    with st.expander("ç•°å¸¸å€¤è©³ç´° (ä¸Šä½20ä»¶)", expanded=False):
        st.dataframe(detail_df, use_container_width=True)

if not anomaly_all_df.empty:
    with st.expander("ç•°å¸¸å€¤ãƒ¬ãƒ“ãƒ¥ãƒ¼ / å‡¦ç½®", expanded=not anomaly_df.empty):
        review_candidates = anomaly_all_df.sort_values("severity", ascending=False).head(20)
        if review_candidates.empty:
            st.caption("ç¾åœ¨ãƒ¬ãƒ“ãƒ¥ãƒ¼å¯¾è±¡ã®ç•°å¸¸å€¤ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            records = review_candidates.to_dict("records")
            classification_labels = [choice["label"] for choice in ANOMALY_REVIEW_CHOICES]
            label_to_key = {choice["label"]: choice["key"] for choice in ANOMALY_REVIEW_CHOICES}
            options = [ANOMALY_REVIEW_UNSET_LABEL] + classification_labels
            decisions: List[Dict[str, Any]] = []
            with st.form("anomaly_review_form"):
                for idx, row in enumerate(records):
                    key = row["key"]
                    metric_label = METRIC_LABELS.get(row.get("metric"), row.get("metric"))
                    product_no = row.get("product_no")
                    product_no_display = _sku_to_str(product_no)
                    product_name = row.get("product_name") or "ä¸æ˜"
                    value = row.get("value")
                    median_val = row.get("median")
                    ratio = None
                    if (
                        value is not None
                        and median_val is not None
                        and not pd.isna(value)
                        and not pd.isna(median_val)
                        and median_val != 0
                    ):
                        ratio = float(value) / float(median_val)
                    row["ratio"] = ratio
                    ratio_txt = f"{ratio:.1f}å€" if ratio is not None else "ä¸­å¤®å€¤æƒ…å ±ãªã—"
                    severity = row.get("severity")
                    severity_txt = "N/A" if severity is None or pd.isna(severity) else f"{float(severity):.1f}"
                    direction = row.get("direction")
                    direction_txt = "ä¸ŠæŒ¯ã‚Œ" if direction == "high" else "ä¸‹æŒ¯ã‚Œ"
                    median_txt = _format_number(median_val)
                    value_txt = _format_number(value)
                    question = (
                        f"è£½å“ç•ªå·{product_no_display}ï¼ˆ{product_name}ï¼‰ã®{metric_label}ãŒ"
                        f"{median_txt}ã«å¯¾ã—ã¦{value_txt}ï¼ˆ{ratio_txt}ï¼‰ã§ã™ã€‚"
                    )
                    row["question"] = question
                    st.markdown(f"**{product_no_display}ï½œ{product_name}**")
                    st.caption(
                        f"{metric_label}: ç¾åœ¨å€¤ {value_txt} / ä¸­å¤®å€¤ {median_txt}ï½œ{direction_txt}ï½œZâ‰ˆ{severity_txt}"
                    )
                    st.caption(question)
                    existing = review_state.get(key, {})
                    existing_classification = _normalize_review_classification(existing)
                    default_index = 0
                    if existing_classification:
                        existing_label = ANOMALY_REVIEW_LABELS.get(existing_classification)
                        if existing_label and existing_label in classification_labels:
                            default_index = classification_labels.index(existing_label) + 1
                    choice_label = st.radio(
                        "åˆ†é¡ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
                        options=options,
                        index=default_index,
                        horizontal=True,
                        key=f"decision_{key}",
                    )
                    if choice_label == ANOMALY_REVIEW_UNSET_LABEL:
                        classification_key = None
                    else:
                        classification_key = label_to_key.get(choice_label)
                    if classification_key:
                        desc = ANOMALY_REVIEW_DESCRIPTIONS.get(classification_key)
                        if desc:
                            st.caption(f"åˆ†é¡ãƒ¡ãƒ¢: {desc}")
                    corrected_value = None
                    if classification_key == "input_error":
                        default_value = existing.get("corrected_value", value)
                        if default_value is None or pd.isna(default_value):
                            default_value = (
                                median_val if median_val is not None and not pd.isna(median_val) else 0.0
                            )
                        step = max(abs(float(default_value)) * 0.01, 0.01)
                        corrected_value = st.number_input(
                            f"è¨‚æ­£å¾Œã®å€¤ï¼ˆ{metric_label}ï¼‰ - {product_no_display}",
                            value=float(default_value),
                            step=float(step),
                            format="%.3f",
                            key=f"corrected_{key}",
                        )
                    note = st.text_input(
                        f"ãƒ¡ãƒ¢ï¼ˆä»»æ„ï¼‰ - {product_no_display}",
                        value=existing.get("note", ""),
                        key=f"note_{key}",
                    )
                    decisions.append(
                        {
                            "key": key,
                            "classification": classification_key,
                            "corrected_value": corrected_value,
                            "note": note,
                            "row": row,
                        }
                    )
                    if idx < len(records) - 1:
                        st.markdown("---")
                submitted = st.form_submit_button("ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’ä¿å­˜")

            if submitted:
                review_map = dict(review_state)
                df_full = st.session_state["df_products_raw"].copy()
                product_no_keys = (
                    df_full["product_no"].apply(_sku_to_str)
                    if "product_no" in df_full.columns
                    else None
                )
                dataset_changed = False
                decision_changed = False

                def _revert_previous(record: Dict[str, Any]) -> bool:
                    if (
                        not record
                        or _normalize_review_classification(record) != "input_error"
                        or record.get("original_value") is None
                        or product_no_keys is None
                    ):
                        return False
                    metric_prev = record.get("metric")
                    if metric_prev not in df_full.columns:
                        return False
                    sku_prev = _sku_to_str(record.get("product_no"))
                    mask_prev = product_no_keys == sku_prev
                    if mask_prev.any():
                        df_full.loc[mask_prev, metric_prev] = record.get("original_value")
                        return True
                    return False

                for entry in decisions:
                    key = entry["key"]
                    classification = entry["classification"]
                    corrected_value = entry.get("corrected_value")
                    note = entry.get("note")
                    row = entry.get("row", {})
                    existing = review_state.get(key)
                    if classification is None:
                        if key in review_map:
                            if _revert_previous(existing):
                                dataset_changed = True
                            del review_map[key]
                            decision_changed = True
                        continue

                    record = {
                        "product_no": row.get("product_no"),
                        "product_no_display": _sku_to_str(row.get("product_no")),
                        "product_name": row.get("product_name"),
                        "metric": row.get("metric"),
                        "metric_label": METRIC_LABELS.get(row.get("metric"), row.get("metric")),
                        "median": None if pd.isna(row.get("median")) else float(row.get("median")),
                        "severity": None if pd.isna(row.get("severity")) else float(row.get("severity")),
                        "direction": row.get("direction"),
                        "note": note,
                        "timestamp": datetime.now().isoformat(timespec="seconds"),
                        "question": row.get("question"),
                    }
                    ratio_val = row.get("ratio")
                    if ratio_val is not None and not pd.isna(ratio_val):
                        record["ratio_vs_median"] = float(ratio_val)
                    if (
                        existing
                        and existing.get("decision") == "corrected"
                        and existing.get("original_value") is not None
                    ):
                        record["original_value"] = existing.get("original_value")
                    else:
                        value_now = row.get("value")
                        record["original_value"] = (
                            None if pd.isna(value_now) else float(value_now)
                        )

                    record["classification"] = classification
                    record["classification_label"] = ANOMALY_REVIEW_LABELS.get(classification)
                    if classification == "exception":
                        record["decision"] = "exception"
                        if _revert_previous(existing):
                            dataset_changed = True
                        review_map[key] = record
                        decision_changed = True
                        continue
                    if classification == "monitor":
                        record["decision"] = "monitor"
                        if _revert_previous(existing):
                            dataset_changed = True
                        review_map[key] = record
                        decision_changed = True
                        continue
                    if classification != "input_error":
                        record["decision"] = classification or ""
                        review_map[key] = record
                        decision_changed = True
                        continue

                    if corrected_value is None:
                        continue
                    corrected_numeric = float(corrected_value)
                    record["decision"] = "corrected"
                    record["corrected_value"] = corrected_numeric
                    metric = row.get("metric")
                    if product_no_keys is not None and metric in df_full.columns:
                        sku_key = _sku_to_str(row.get("product_no"))
                        mask = product_no_keys == sku_key
                        if mask.any():
                            df_full.loc[mask, metric] = corrected_numeric
                            dataset_changed = True
                    review_map[key] = record
                    decision_changed = True

                if decision_changed:
                    st.session_state["anomaly_review"] = review_map
                    if dataset_changed:
                        st.session_state["df_products_raw"] = df_full
                    st.success("ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                    st.rerun()
                else:
                    st.info("å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

history_state = st.session_state.get("anomaly_review", {})
if history_state:
    history_records = []
    for key, info in history_state.items():
        classification_code = _normalize_review_classification(info)
        classification_label = info.get("classification_label") or ANOMALY_REVIEW_LABELS.get(
            classification_code, "-"
        )
        history_records.append(
            {
                "decision": info.get("decision"),
                "classification": classification_code,
                "åˆ†é¡": classification_label,
                "è£½å“ç•ªå·": info.get("product_no_display")
                or _sku_to_str(info.get("product_no")),
                "è£½å“å": info.get("product_name"),
                "æŒ‡æ¨™": info.get("metric_label")
                or METRIC_LABELS.get(info.get("metric"), info.get("metric")),
                "å…ƒã®å€¤": info.get("original_value"),
                "è¨‚æ­£å€¤": info.get("corrected_value"),
                "ä¸­å¤®å€¤": info.get("median"),
                "ä¸­å¤®å€¤æ¯”": info.get("ratio_vs_median"),
                "é€¸è„±åº¦": info.get("severity"),
                "åˆ¤å®šæ—¥æ™‚": info.get("timestamp"),
                "ãƒ¡ãƒ¢": info.get("note"),
            }
        )
    history_df = pd.DataFrame(history_records)
    if not history_df.empty:
        history_df = history_df.sort_values("åˆ¤å®šæ—¥æ™‚", ascending=False)

        def _prepare_history(df: pd.DataFrame) -> pd.DataFrame:
            if df.empty:
                return df
            df = df.copy()
            if "classification" in df.columns:
                df = df.drop(columns=["classification"])
            df["ä¸­å¤®å€¤æ¯”"] = df["ä¸­å¤®å€¤æ¯”"].apply(
                lambda v: f"{float(v):.2f}å€" if v is not None and not pd.isna(v) else "-"
            )
            df["å…ƒã®å€¤"] = df["å…ƒã®å€¤"].apply(_format_number)
            df["è¨‚æ­£å€¤"] = df["è¨‚æ­£å€¤"].apply(
                lambda v: "-" if v is None or pd.isna(v) else _format_number(v)
            )
            df["ä¸­å¤®å€¤"] = df["ä¸­å¤®å€¤"].apply(_format_number)
            df["é€¸è„±åº¦"] = df["é€¸è„±åº¦"].apply(
                lambda v: "-" if v is None or pd.isna(v) else f"{float(v):.1f}"
            )
            return df

        exceptions_history = history_df[history_df["classification"] == "exception"].copy()
        corrections_history = history_df[history_df["classification"] == "input_error"].copy()
        monitor_history = history_df[history_df["classification"] == "monitor"].copy()

        if not exceptions_history.empty:
            cols = [
                "åˆ†é¡",
                "è£½å“ç•ªå·",
                "è£½å“å",
                "æŒ‡æ¨™",
                "å…ƒã®å€¤",
                "ä¸­å¤®å€¤",
                "ä¸­å¤®å€¤æ¯”",
                "é€¸è„±åº¦",
                "åˆ¤å®šæ—¥æ™‚",
                "ãƒ¡ãƒ¢",
            ]
            with st.expander("ä¾‹å¤–ã¨ã—ã¦æ‰±ã†ç•°å¸¸å€¤", expanded=False):
                st.dataframe(_prepare_history(exceptions_history)[cols], use_container_width=True)

        if not corrections_history.empty:
            cols = [
                "åˆ†é¡",
                "è£½å“ç•ªå·",
                "è£½å“å",
                "æŒ‡æ¨™",
                "å…ƒã®å€¤",
                "è¨‚æ­£å€¤",
                "ä¸­å¤®å€¤",
                "ä¸­å¤®å€¤æ¯”",
                "é€¸è„±åº¦",
                "åˆ¤å®šæ—¥æ™‚",
                "ãƒ¡ãƒ¢",
            ]
            with st.expander("è¨‚æ­£æ¸ˆã¿ã®ç•°å¸¸å€¤", expanded=False):
                st.dataframe(_prepare_history(corrections_history)[cols], use_container_width=True)

        if not monitor_history.empty:
            cols = [
                "åˆ†é¡",
                "è£½å“ç•ªå·",
                "è£½å“å",
                "æŒ‡æ¨™",
                "å…ƒã®å€¤",
                "ä¸­å¤®å€¤",
                "ä¸­å¤®å€¤æ¯”",
                "é€¸è„±åº¦",
                "åˆ¤å®šæ—¥æ™‚",
                "ãƒ¡ãƒ¢",
            ]
            with st.expander("è¦èª¿æŸ»ã¨ã—ã¦è¨˜éŒ²ã—ãŸç•°å¸¸å€¤", expanded=False):
                st.dataframe(_prepare_history(monitor_history)[cols], use_container_width=True)

st.divider()

# Actionable SKU Top List
st.subheader("è¦å¯¾ç­–SKUãƒˆãƒƒãƒ—ãƒªã‚¹ãƒˆ")
st.caption(
    "ã‚®ãƒ£ãƒƒãƒ— = å¿…è¦è³ƒç‡ - ä»˜åŠ ä¾¡å€¤/åˆ†ã€‚å„ªå…ˆåº¦ã¯æ¨å®šæœˆæ¬¡åŠ¹æœ Ã· æƒ³å®šæŠ•è³‡é¡ã§ç®—å‡ºã—ã¦ã„ã¾ã™ã€‚\n"
    f"å„ªå…ˆåº¦ãƒ©ãƒ³ã‚¯: ROIâ‰¦{roi_priority_high:.1f}ãƒ¶æœˆã¯ã€é«˜ã€ã€ROIâ‰¦{roi_priority_medium:.1f}ãƒ¶æœˆã¾ã§ã¯ã€ä¸­ã€ã€ãã‚Œä»¥ä¸Šã¯ã€ä½ã€ã€‚\n"
    f"å®Ÿè¡Œå¯å¦: æƒ³å®šæŠ•è³‡é¡â‰¦{investment_threshold:,.0f}å††ãªã‚‰ã€å³å®Ÿè¡Œå¯ã€ã¨åˆ¤å®šã—ã¾ã™ã€‚"
)
if filter_summaries:
    st.caption("é©ç”¨ä¸­ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: " + " / ".join(filter_summaries))
top5 = top_cards
if len(top5) > 0:
    card_cols = st.columns(len(top5))
    for col, row in zip(card_cols, top5.to_dict("records")):
        roi_txt = _format_roi(row.get("best_roi_months"))
        gap_val = row.get("gap")
        gap_txt = "N/A" if pd.isna(gap_val) else f"{float(gap_val):.2f}å††/åˆ†"
        action_label = row.get("best_action_label") or "æ¨å¥¨ãªã—"
        if action_label == "æ¨å¥¨ãªã—":
            delta_label = "æ¨å¥¨æ–½ç­–ãªã—"
        else:
            delta_label = f"{action_label}ï½œROI {roi_txt}æœˆ"
        col.metric(row.get("product_name", "ä¸æ˜"), gap_txt, delta=delta_label)
        badge_parts: List[str] = []
        priority_label = row.get("priority_rank")
        execution_label = row.get("execution_feasibility")
        if priority_label and isinstance(priority_label, str):
            badge_parts.append(f"å„ªå…ˆåº¦:{priority_label}")
        if execution_label and isinstance(execution_label, str):
            badge_parts.append(execution_label)
        if badge_parts:
            _render_target_badge(col, " / ".join(badge_parts))

        price_val = row.get("price_improve")
        ct_val = row.get("ct_improve")
        material_val = row.get("material_improve")
        price_txt = (
            f"ä¾¡æ ¼+{float(price_val):,.0f}å††"
            if price_val is not None and not pd.isna(price_val) and float(price_val) > 0
            else "ä¾¡æ ¼æ”¹å–„æƒ…å ±ãªã—"
        )
        ct_txt = (
            f"CT-{float(ct_val):.2f}åˆ†"
            if ct_val is not None and not pd.isna(ct_val) and float(ct_val) > 0
            else "CTæ”¹å–„æƒ…å ±ãªã—"
        )
        material_txt = (
            f"ææ–™-{float(material_val):,.0f}å††"
            if material_val is not None and not pd.isna(material_val) and float(material_val) > 0
            else "ææ–™æ”¹å–„æƒ…å ±ãªã—"
        )
        benefit_txt = _format_currency(row.get("best_monthly_benefit"))
        col.caption(f"{' / '.join([price_txt, ct_txt, material_txt])}ï½œæœˆæ¬¡åŠ¹æœ â‰ˆ {benefit_txt}")

    rename_map = {
        "product_no": "è£½å“ç•ªå·",
        "product_name": "è£½å“å",
        "best_action_label": "æ¨å¥¨æ–½ç­–",
        "gap": "ã‚®ãƒ£ãƒƒãƒ—(å††/åˆ†)",
        "monthly_shortfall_value": "ä¸è¶³é¡/æœˆ(å††)",
        "price_improve": "ä¾¡æ ¼æ”¹å–„(å††/å€‹)",
        "ct_improve": "CTæ”¹å–„(åˆ†/å€‹)",
        "material_improve": "ææ–™æ”¹å–„(å††/å€‹)",
        "best_monthly_benefit": "æ¨å®šæœˆæ¬¡åŠ¹æœ(å††)",
        "best_investment": "æƒ³å®šæŠ•è³‡é¡(å††)",
        "best_roi_months": "æƒ³å®šROI(æœˆ)",
        "best_score": "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢(1/æœˆ)",
        "priority_rank": "å„ªå…ˆåº¦ãƒ©ãƒ³ã‚¯",
        "execution_feasibility": "å®Ÿè¡Œå¯å¦",
    }
    columns = [
        "product_no",
        "product_name",
        "best_action_label",
        "gap",
        "monthly_shortfall_value",
        "price_improve",
        "ct_improve",
        "material_improve",
        "best_monthly_benefit",
        "best_investment",
        "best_roi_months",
        "priority_rank",
        "execution_feasibility",
        "best_score",
    ]
    table = top_list[columns].rename(columns=rename_map)
    table.insert(0, "é¸æŠ", False)
    column_config = {
        "é¸æŠ": st.column_config.CheckboxColumn("é¸æŠ", help="ã‚·ãƒŠãƒªã‚ªã«è»¢é€ã™ã‚‹SKUã‚’é¸æŠ"),
        "è£½å“ç•ªå·": st.column_config.TextColumn("è£½å“ç•ªå·"),
        "è£½å“å": st.column_config.TextColumn("è£½å“å"),
        "æ¨å¥¨æ–½ç­–": st.column_config.TextColumn("æ¨å¥¨æ–½ç­–"),
        "ã‚®ãƒ£ãƒƒãƒ—(å††/åˆ†)": st.column_config.NumberColumn("ã‚®ãƒ£ãƒƒãƒ—(å††/åˆ†)", format="%.2f"),
        "ä¸è¶³é¡/æœˆ(å††)": st.column_config.NumberColumn(
            "ä¸è¶³é¡/æœˆ(å††)",
            format="%.0f",
            help="(å¿…è¦è³ƒç‡âˆ’ç¾çŠ¶VA/åˆ†)Ã—åˆ†/å€‹Ã—æ—¥ç”£æ•°Ã—ç¨¼åƒæ—¥æ•°",
        ),
        "ä¾¡æ ¼æ”¹å–„(å††/å€‹)": st.column_config.NumberColumn(
            "ä¾¡æ ¼æ”¹å–„(å††/å€‹)",
            format="%.0f",
            help="å¿…è¦è²©å£²å˜ä¾¡ âˆ’ ç¾åœ¨ã®è²©å£²å˜ä¾¡",
        ),
        "CTæ”¹å–„(åˆ†/å€‹)": st.column_config.NumberColumn(
            "CTæ”¹å–„(åˆ†/å€‹)",
            format="%.2f",
            help="ç¾çŠ¶åˆ†/å€‹ âˆ’ é”æˆã«å¿…è¦ãªåˆ†/å€‹",
        ),
        "ææ–™æ”¹å–„(å††/å€‹)": st.column_config.NumberColumn(
            "ææ–™æ”¹å–„(å††/å€‹)",
            format="%.0f",
            help="ç¾çŠ¶ææ–™è²» âˆ’ ç›®æ¨™ææ–™è²»",
        ),
        "æ¨å®šæœˆæ¬¡åŠ¹æœ(å††)": st.column_config.NumberColumn(
            "æ¨å®šæœˆæ¬¡åŠ¹æœ(å††)",
            format="%.0f",
            help="æ¨å¥¨æ–½ç­–ã‚’å®Ÿè¡Œã—ãŸå ´åˆã®æœˆæ¬¡ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆ",
        ),
        "æƒ³å®šæŠ•è³‡é¡(å††)": st.column_config.NumberColumn(
            "æƒ³å®šæŠ•è³‡é¡(å††)",
            format="%.0f",
            help="è¨­å®šã—ãŸæ–½ç­–åˆ¥ã®æƒ³å®šæŠ•è³‡é¡",
        ),
        "æƒ³å®šROI(æœˆ)": st.column_config.NumberColumn(
            "æƒ³å®šROI(æœˆ)",
            format="%.1f",
            help="æƒ³å®šæŠ•è³‡é¡ Ã· æ¨å®šæœˆæ¬¡åŠ¹æœ",
        ),
        "å„ªå…ˆåº¦ãƒ©ãƒ³ã‚¯": st.column_config.TextColumn(
            "å„ªå…ˆåº¦ãƒ©ãƒ³ã‚¯",
            help=(
                f"ROIâ‰¦{roi_priority_high:.1f}ãƒ¶æœˆã¯ã€é«˜ã€ã€ROIâ‰¦{roi_priority_medium:.1f}ãƒ¶æœˆã¾ã§ã¯ã€ä¸­ã€ã€"
                "ãã‚Œä»¥ä¸Šã¯ã€ä½ã€ã¨ã—ã¦åˆ¤å®š"
            ),
        ),
        "å®Ÿè¡Œå¯å¦": st.column_config.TextColumn(
            "å®Ÿè¡Œå¯å¦",
            help=(
                f"æƒ³å®šæŠ•è³‡é¡â‰¦{investment_threshold:,.0f}å††ã§ã€å³å®Ÿè¡Œå¯ã€ã€è¶…ãˆã‚‹å ´åˆã¯ã€è¦æŠ•è³‡æ¤œè¨ã€ã€‚"
                "æŠ•è³‡é¡ãŒæœªè¨­å®šã®æ–½ç­–ã¯ã€æŠ•è³‡é¡æœªè¨­å®šã€ã€‚"
            ),
        ),
        "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢(1/æœˆ)": st.column_config.NumberColumn(
            "å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢(1/æœˆ)",
            format="%.2f",
            help="æ¨å®šæœˆæ¬¡åŠ¹æœ Ã· æƒ³å®šæŠ•è³‡é¡ã€‚1.0ã§1ã‹æœˆå›å",
        ),
    }
    edited = st.data_editor(
        table,
        use_container_width=True,
        key="action_sku_editor",
        column_config=column_config,
        hide_index=True,
    )
    csv_top = edited.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "CSVå‡ºåŠ›",
        data=csv_top,
        file_name="action_sku_top20.csv",
        mime="text/csv",
    )
    selected = edited[edited["é¸æŠ"]]
    if st.button("ã‚·ãƒŠãƒªã‚ªã«åæ˜ "):
        st.session_state["selected_action_skus"] = selected
        st.success(f"{len(selected)}ä»¶ã‚’ã‚·ãƒŠãƒªã‚ªã«åæ˜ ã—ã¾ã—ãŸ")
elif gap_df.empty:
    st.info("è¦å¯¾ç­–SKUã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    st.info("è¨­å®šã—ãŸæ¡ä»¶ã«åˆè‡´ã™ã‚‹è¦å¯¾ç­–SKUã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

st.subheader("ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æï¼ˆã‚«ãƒ†ã‚´ãƒªãƒ¼/é¡§å®¢ï¼‰")
st.caption("å¹³å‡VA/åˆ†ã¨å¿…è¦è³ƒç‡ã¨ã®å·®ã€é”æˆç‡ã€ROIã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§æ¯”è¼ƒã—ã¾ã™ã€‚")

insight_sections = [
    ("ã‚«ãƒ†ã‚´ãƒªãƒ¼", _build_segment_highlights(category_summary, "ã‚«ãƒ†ã‚´ãƒªãƒ¼")),
    ("ä¸»è¦é¡§å®¢", _build_segment_highlights(customer_summary, "ä¸»è¦é¡§å®¢")),
]
for section_label, bullets in insight_sections:
    if not bullets:
        continue
    st.markdown(f"**{section_label}ã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ**")
    st.markdown("\n".join(f"- {line}" for line in bullets))

segment_tabs = st.tabs(["ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥", "ä¸»è¦é¡§å®¢åˆ¥"])
with segment_tabs[0]:
    _render_segment_tab(category_summary, "ã‚«ãƒ†ã‚´ãƒªãƒ¼", req_rate)
with segment_tabs[1]:
    _render_segment_tab(customer_summary, "ä¸»è¦é¡§å®¢", req_rate)

tabs = st.tabs(["å…¨ä½“åˆ†å¸ƒï¼ˆæ•£å¸ƒå›³ï¼‰", "æ™‚ç³»åˆ—", "é”æˆçŠ¶æ³ï¼ˆæ£’/å††ï¼‰", "æœªé”SKUï¼ˆãƒ‘ãƒ¬ãƒ¼ãƒˆï¼‰", "SKUãƒ†ãƒ¼ãƒ–ãƒ«", "ä»˜åŠ ä¾¡å€¤/åˆ†åˆ†å¸ƒ"])

with tabs[0]:
    st.caption(
        "æ¨ªè»¸=åˆ†/å€‹ï¼ˆè£½é€ ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼‰, ç¸¦è»¸=ä»˜åŠ ä¾¡å€¤/åˆ†ã€‚å¿…è¦è³ƒç‡Ã—Î´å¸¯ã¨æç›Šåˆ†å²è³ƒç‡ã‚’è¡¨ç¤ºã€‚"
    )
    scatter_frames: List[pd.DataFrame] = []
    for scen_name in selected_scenarios:
        scen_data = scenario_results.get(scen_name)
        if not scen_data:
            continue
        scen_df = scen_data.get("df")
        if scen_df is None or scen_df.empty:
            continue
        scen_copy = scen_df.copy()
        scen_copy["scenario"] = scen_name
        scatter_frames.append(scen_copy)
    if not scatter_frames:
        st.info("è¡¨ç¤ºå¯èƒ½ãªã‚·ãƒŠãƒªã‚ªãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        scatter_df = pd.concat(scatter_frames, ignore_index=True)
        scatter_df["margin_to_req"] = req_rate - scatter_df["va_per_min"]
        fig = px.scatter(
            scatter_df,
            x="minutes_per_unit",
            y="va_per_min",
            color="scenario",
            hover_data={
                "product_name": True,
                "minutes_per_unit": ":.2f",
                "va_per_min": ":.2f",
                "margin_to_req": ":.2f",
            },
            opacity=0.8,
            color_discrete_sequence=PASTEL_PALETTE,
            height=420,
        )
        fig.update_traces(marker=dict(size=9, line=dict(color="#FFFFFF", width=0.6)))
        fig.add_hrect(
            y0=req_rate * delta_low,
            y1=req_rate * delta_high,
            line_width=0,
            fillcolor="#9BC0A0",
            opacity=0.15,
        )
        fig.add_hline(y=req_rate, line_color="#2F6776", line_width=2)
        fig.add_hline(y=be_rate, line_color="#E7A07A", line_dash="dash")
        fig.update_xaxes(title="åˆ†/å€‹", gridcolor="#D7E2EA")
        fig.update_yaxes(title="ä»˜åŠ ä¾¡å€¤/åˆ†", gridcolor="#D7E2EA")
        fig = _apply_plotly_theme(fig, show_spikelines=st.session_state["show_spikelines"])
        st.plotly_chart(fig, use_container_width=True, config=_build_plotly_config())

with tabs[1]:
    st.caption("æœˆæ¬¡ãƒ»å››åŠæœŸã®KPIæ¨ç§»ã‚’ç¢ºèªã—ã€æ–½ç­–åŠ¹æœã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã—ã¾ã™ã€‚")
    trend_df = st.session_state.get("monthly_trend", pd.DataFrame())
    if trend_df.empty:
        st.info("ã€æœˆæ¬¡ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆã‚’è¨˜éŒ²ã€ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ã¨æ™‚ç³»åˆ—ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    else:
        available_scenarios = sorted(trend_df["scenario"].dropna().unique().tolist())
        filtered = trend_df[trend_df["scenario"].isin([s for s in selected_scenarios if s in available_scenarios])]
        if filtered.empty:
            st.warning("é¸æŠä¸­ã®ã‚·ãƒŠãƒªã‚ªã§ã¯æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            st.session_state.setdefault("trend_freq", "æœˆæ¬¡")
            freq_choice = st.radio(
                "é›†è¨ˆç²’åº¦",
                options=["æœˆæ¬¡", "å››åŠæœŸ"],
                horizontal=True,
                key="trend_freq",
            )
            plot_df = _prepare_trend_dataframe(filtered, freq_choice)
            if plot_df.empty:
                st.warning("è¡¨ç¤ºå¯¾è±¡ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
            else:
                pdca_df = _build_pdca_summary(plot_df)
                yoy_lines = _build_yoy_summary(
                    trend_df,
                    sorted(plot_df["scenario"].unique()),
                )
                if yoy_lines:
                    st.markdown("**å‰å¹´åŒæœˆæ¯”**")
                    st.markdown("\n".join(f"- {line}" for line in yoy_lines))
                if not pdca_df.empty:
                    latest_records = (
                        pdca_df.sort_values("period")
                        .groupby("scenario", as_index=False)
                        .tail(1)
                        .sort_values("scenario")
                    )
                    if not latest_records.empty:
                        st.markdown("**æœ€æ–°PDCAã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**")
                        st.markdown(
                            "\n".join(
                                f"- {row['scenario']}ï¼ˆ{_format_period_label(row['period'], freq_choice)}ï¼‰: {row['pdca_comment']}"
                                for _, row in latest_records.iterrows()
                            )
                        )
                fig_ts = make_subplots(specs=[[{"secondary_y": True}]])
                scenario_colors = {
                    scen: PASTEL_PALETTE[idx % len(PASTEL_PALETTE)]
                    for idx, scen in enumerate(sorted(plot_df["scenario"].unique()))
                }
                for scen, group in plot_df.groupby("scenario"):
                    g = group.sort_values("period")
                    fig_ts.add_trace(
                        go.Scatter(
                            x=g["period"],
                            y=g["va_per_min"],
                            mode="lines+markers",
                            name=f"{scen} VA/åˆ†",
                            line=dict(color=scenario_colors.get(scen), width=2.5),
                            marker=dict(size=8),
                        ),
                        secondary_y=False,
                    )
                    fig_ts.add_trace(
                        go.Scatter(
                            x=g["period"],
                            y=g["required_rate"],
                            mode="lines+markers",
                            name=f"{scen} å¿…è¦è³ƒç‡",
                            line=dict(color=scenario_colors.get(scen), width=2, dash="dash"),
                            marker=dict(size=7, symbol="diamond"),
                        ),
                        secondary_y=False,
                    )
                    fig_ts.add_trace(
                        go.Scatter(
                            x=g["period"],
                            y=g["ach_rate"],
                            mode="lines+markers",
                            name=f"{scen} é”æˆç‡",
                            line=dict(color=scenario_colors.get(scen), width=2, dash="dot"),
                            marker=dict(size=7),
                            opacity=0.8,
                        ),
                        secondary_y=True,
                    )
                fig_ts.update_yaxes(
                    title_text="VA/åˆ†ãƒ»å¿…è¦è³ƒç‡ (å††/åˆ†)",
                    secondary_y=False,
                    gridcolor="#D7E2EA",
                )
                fig_ts.update_yaxes(
                    title_text="å¿…è¦è³ƒç‡é”æˆç‡ (%)",
                    range=[0, 100],
                    secondary_y=True,
                    gridcolor="#D7E2EA",
                )
                fig_ts.update_xaxes(
                    gridcolor="#D7E2EA",
                    rangeslider=dict(visible=st.session_state["show_rangeslider"]),
                    rangeselector=dict(
                        buttons=[
                            dict(count=3, label="3M", step="month", stepmode="backward"),
                            dict(count=6, label="6M", step="month", stepmode="backward"),
                            dict(step="all", label="ALL"),
                        ],
                        bgcolor="rgba(47,103,118,0.08)",
                        activecolor="#2F6776",
                        font=dict(color="#1F2A44"),
                    ),
                )
                fig_ts = _apply_plotly_theme(
                    fig_ts, show_spikelines=st.session_state["show_spikelines"]
                )
                st.plotly_chart(fig_ts, use_container_width=True, config=_build_plotly_config())

                display_df = plot_df.copy()
                display_df["æœŸé–“"] = display_df["period"].map(
                    lambda v: _format_period_label(v, freq_choice)
                )
                display_df = display_df.sort_values(["period", "scenario"])
                summary_table = pd.DataFrame(
                    {
                        "æœŸé–“": display_df["æœŸé–“"],
                        "ã‚·ãƒŠãƒªã‚ª": display_df["scenario"],
                        "å¿…è¦è³ƒç‡ (å††/åˆ†)": display_df["required_rate"].map(
                            lambda x: f"{x:.3f}" if pd.notna(x) else "-"
                        ),
                        "å¹³å‡VA/åˆ†": display_df["va_per_min"].map(
                            lambda x: f"{x:.2f}" if pd.notna(x) else "-"
                        ),
                        "å¿…è¦è³ƒç‡é”æˆç‡": display_df["ach_rate"].map(
                            lambda x: f"{x:.1f}%" if pd.notna(x) else "-"
                        ),
                        "æç›Šåˆ†å²è³ƒç‡": display_df["be_rate"].map(
                            lambda x: f"{x:.3f}" if pd.notna(x) else "-"
                        ),
                    }
                )
                st.dataframe(summary_table, use_container_width=True)

                if not pdca_df.empty:
                    display_pdca = pdca_df.copy()
                    display_pdca["æœŸé–“"] = display_pdca["period"].map(
                        lambda v: _format_period_label(v, freq_choice)
                    )
                    display_pdca["P(å¿…è¦è³ƒç‡)"] = display_pdca["required_rate"].map(
                        lambda x: f"{x:.3f}" if pd.notna(x) else "-"
                    )
                    display_pdca["D(VA/åˆ†)"] = display_pdca["va_per_min"].map(
                        lambda x: f"{x:.2f}" if pd.notna(x) else "-"
                    )
                    display_pdca["C(é”æˆç‡)"] = display_pdca["ach_rate"].map(
                        lambda x: f"{x:.1f}%" if pd.notna(x) else "-"
                    )
                    display_pdca["Î”VA/åˆ†"] = display_pdca["delta_va"].map(
                        lambda x: f"{x:+.2f}" if pd.notna(x) else "-"
                    )
                    display_pdca["Î”é”æˆç‡"] = display_pdca["delta_ach"].map(
                        lambda x: f"{x:+.1f}pt" if pd.notna(x) else "-"
                    )
                    pdca_display_cols = [
                        "ã‚·ãƒŠãƒªã‚ª",
                        "æœŸé–“",
                        "P(å¿…è¦è³ƒç‡)",
                        "D(VA/åˆ†)",
                        "C(é”æˆç‡)",
                        "Î”VA/åˆ†",
                        "Î”é”æˆç‡",
                        "PDCAã‚³ãƒ¡ãƒ³ãƒˆ",
                    ]
                    display_pdca = display_pdca.rename(
                        columns={"scenario": "ã‚·ãƒŠãƒªã‚ª", "pdca_comment": "PDCAã‚³ãƒ¡ãƒ³ãƒˆ"}
                    )[pdca_display_cols]
                    st.markdown("**PDCAãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ**")
                    st.dataframe(display_pdca, use_container_width=True)

with tabs[2]:
    c1, c2 = st.columns([1.2,1])
    class_counts = df_view["rate_class"].value_counts().reset_index()
    class_counts.columns = ["rate_class", "count"]
    bar = alt.Chart(class_counts).mark_bar(color=PASTEL_ACCENT).encode(
        x=alt.X("rate_class:N", title="é”æˆåˆ†é¡"),
        y=alt.Y("count:Q", title="ä»¶æ•°"),
        tooltip=["rate_class","count"]
    ).properties(height=380)
    c1.altair_chart(bar, use_container_width=True)

    # Achievers vs Missed donut
    donut_df = pd.DataFrame({
        "group": ["é”æˆ", "æœªé”"],
        "value": [ (df_view["meets_required_rate"].sum()), ( (~df_view["meets_required_rate"]).sum() ) ]
    })
    donut = (
        alt.Chart(donut_df)
        .mark_arc(innerRadius=80)
        .encode(
            theta="value:Q",
            color=alt.Color(
                "group:N",
                scale=alt.Scale(range=[PASTEL_ACCENT, "#DDA0BC"]),
                title="é”æˆçŠ¶æ³",
            ),
            tooltip=["group", "value"],
        )
    )
    c2.altair_chart(donut, use_container_width=True)

with tabs[3]:
    miss = df_view[df_view["meets_required_rate"] == False].copy()
    miss = miss.sort_values("rate_gap_vs_required").head(topn)
    st.caption("ã€å¿…è¦è³ƒç‡å·®ã€ãŒå°ã•ã„ï¼ˆã¾ãŸã¯ãƒã‚¤ãƒŠã‚¹ãŒå¤§ï¼‰ã®é †ã€‚å³ã»ã©æ”¹å–„ä½™åœ°ãŒå¤§ã€‚")
    if len(miss)==0:
        st.success("æœªé”SKUã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        pareto = alt.Chart(miss).mark_bar(color=PASTEL_ACCENT).encode(
            x=alt.X("product_name:N", sort="-y", title="è£½å“å"),
            y=alt.Y("rate_gap_vs_required:Q", title="å¿…è¦è³ƒç‡å·®ï¼ˆä»˜åŠ ä¾¡å€¤/åˆ† - å¿…è¦è³ƒç‡ï¼‰"),
            tooltip=["product_name","rate_gap_vs_required"]
        ).properties(height=420)
        st.altair_chart(pareto, use_container_width=True)
        st.dataframe(miss[["product_no","product_name","minutes_per_unit","va_per_min","rate_gap_vs_required","price_gap_vs_required"]], use_container_width=True)

with tabs[4]:
    rename_map = {
        "product_no": "è£½å“ç•ªå·",
        "product_name": "è£½å“å",
        "category": "ã‚«ãƒ†ã‚´ãƒªãƒ¼",
        "major_customer": "ä¸»è¦é¡§å®¢",
        "actual_unit_price": "å®Ÿéš›å£²å˜ä¾¡",
        "material_unit_cost": "ææ–™åŸä¾¡",
        "minutes_per_unit": "åˆ†/å€‹",
        "daily_qty": "æ—¥ç”£æ•°",
        "daily_total_minutes": "æ—¥ç”£åˆè¨ˆ(åˆ†)",
        "gp_per_unit": "ç²—åˆ©/å€‹",
        "daily_va": "ä»˜åŠ ä¾¡å€¤(æ—¥ç”£)",
        "va_per_min": "ä»˜åŠ ä¾¡å€¤/åˆ†",
        "be_va_unit_price": "æç›Šåˆ†å²ä»˜åŠ ä¾¡å€¤å˜ä¾¡",
        "req_va_unit_price": "å¿…è¦ä»˜åŠ ä¾¡å€¤å˜ä¾¡",
        "required_selling_price": "å¿…è¦è²©å£²å˜ä¾¡",
        "price_gap_vs_required": "å¿…è¦è²©å£²å˜ä¾¡å·®é¡",
        "rate_gap_vs_required": "å¿…è¦è³ƒç‡å·®",
        "meets_required_rate": "å¿…è¦è³ƒç‡é”æˆ",
        "rate_class": "é”æˆåˆ†é¡",
    }
    ordered_cols = [
        "è£½å“ç•ªå·","è£½å“å","ã‚«ãƒ†ã‚´ãƒªãƒ¼","ä¸»è¦é¡§å®¢","å®Ÿéš›å£²å˜ä¾¡","å¿…è¦è²©å£²å˜ä¾¡","å¿…è¦è²©å£²å˜ä¾¡å·®é¡","ææ–™åŸä¾¡","ç²—åˆ©/å€‹",
        "åˆ†/å€‹","æ—¥ç”£æ•°","æ—¥ç”£åˆè¨ˆ(åˆ†)","ä»˜åŠ ä¾¡å€¤(æ—¥ç”£)","ä»˜åŠ ä¾¡å€¤/åˆ†",
        "æç›Šåˆ†å²ä»˜åŠ ä¾¡å€¤å˜ä¾¡","å¿…è¦ä»˜åŠ ä¾¡å€¤å˜ä¾¡","å¿…è¦è³ƒç‡å·®","å¿…è¦è³ƒç‡é”æˆ","é”æˆåˆ†é¡",
    ]
    df_table = df_view.rename(columns=rename_map)
    df_table = df_table[[c for c in ordered_cols if c in df_table.columns]]

    st.dataframe(df_table, use_container_width=True, height=520)
    csv = df_table.to_csv(index=False).encode("utf-8-sig")
    st.download_button("çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="calc_results.csv", mime="text/csv")

with tabs[5]:
    hist = alt.Chart(df_view).mark_bar(color=PASTEL_ACCENT).encode(
        x=alt.X("va_per_min:Q", bin=alt.Bin(maxbins=30), title="ä»˜åŠ ä¾¡å€¤/åˆ†"),
        y=alt.Y("count()", title="ä»¶æ•°"),
        tooltip=["count()"]
    ).properties(height=420)
    st.altair_chart(hist, use_container_width=True)

sync_offline_cache()

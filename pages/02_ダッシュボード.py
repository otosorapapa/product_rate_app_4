import sys
from pathlib import Path
BASE_DIR = Path(__file__).resolve().parents[1]
if str(BASE_DIR) not in sys.path:
    # Ensure our project root takes precedence so we import the local utils module
    # instead of any similarly named third-party package that might exist.
    sys.path.insert(0, str(BASE_DIR))

import numpy as np
import pandas as pd
import streamlit as st
import altair as alt
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from urllib.parse import urlencode

from utils import compute_results, detect_quality_issues, detect_anomalies
from standard_rate_core import DEFAULT_PARAMS, sanitize_params, compute_rates
from components import render_stepper, render_sidebar_nav
import os
from typing import Dict, Any, List

from openai import OpenAI

PASTEL_PALETTE = [
    "#2F6776",
    "#79A3B1",
    "#F2C57C",
    "#9BC0A0",
    "#DDA0BC",
    "#AEC9EB",
]
PASTEL_ACCENT = "#2F6776"
PASTEL_BG = "#F4F7FA"


if "pastel_mck" not in alt.themes.names():

    @alt.themes.register("pastel_mck")
    def _pastel_theme():
        return {
            "config": {
                "background": PASTEL_BG,
                "view": {"stroke": "transparent"},
                "range": {"category": PASTEL_PALETTE},
                "title": {"color": "#1F2A44"},
                "axis": {
                    "titleColor": "#1F2A44",
                    "labelColor": "#30405B",
                    "gridColor": "#D7E2EA",
                },
                "legend": {"labelColor": "#30405B", "titleColor": "#1F2A44"},
            }
        }


alt.themes.enable("pastel_mck")

st.markdown(
    f"""
    <style>
    .main > div {{
        background-color: {PASTEL_BG};
    }}
    [data-testid="stMetric"] {{
        background-color: #FFFFFF;
        border-radius: 18px;
        border: 1px solid #D7E2EA;
        padding: 12px 16px;
        box-shadow: 0 6px 12px rgba(31,42,68,0.06);
    }}
    [data-testid="stMetricDelta"] span {{
        font-weight: 600;
    }}
    .metric-badge {{
        text-align:right;
        color: #2F6776;
        font-weight: 600;
    }}
    </style>
    """,
    unsafe_allow_html=True,
)


def _apply_plotly_theme(fig: go.Figure, *, show_spikelines: bool = False, legend_bottom: bool = False) -> go.Figure:
    """Apply a consistent pastel style across plotly figures."""

    legend_conf = dict(
        orientation="h",
        yanchor="bottom",
        y=1.02,
        xanchor="right",
        x=1.0,
        bgcolor="rgba(255,255,255,0.6)",
        bordercolor="rgba(47,103,118,0.15)",
        borderwidth=1,
    )
    if legend_bottom:
        legend_conf.update({"y": -0.2, "x": 0.5, "xanchor": "center"})

    fig.update_layout(
        plot_bgcolor=PASTEL_BG,
        paper_bgcolor=PASTEL_BG,
        font=dict(color="#1F2A44"),
        legend=legend_conf,
        margin=dict(l=40, r=30, t=60, b=60),
    )
    if show_spikelines:
        fig.update_layout(
            hovermode="x unified",
            xaxis=dict(showspikes=True, spikethickness=1, spikedash="dot"),
        )
        if "yaxis" in fig.layout:
            fig.update_layout(yaxis=dict(showspikes=True, spikethickness=1, spikedash="dot"))
    else:
        fig.update_layout(hovermode="closest")
    return fig


def _build_plotly_config() -> Dict[str, Any]:
    draw_tools = st.session_state.get(
        "plotly_draw_tools",
        ["drawline", "drawrect", "drawopenpath", "drawcircle", "eraseshape"],
    )
    return {
        "displaylogo": False,
        "responsive": True,
        "scrollZoom": True,
        "modeBarButtonsToAdd": draw_tools,
        "toImageButtonOptions": {"format": "png", "scale": 2},
    }


def _generate_dashboard_comment(
    df: pd.DataFrame, metrics: Dict[str, float], insights: Dict[str, Any]
) -> str:
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    client = OpenAI(api_key=api_key)
    sample = df.head(5).to_markdown(index=False)
    top_gaps: List[Dict[str, Any]] = insights.get("top_underperformers", [])
    anomaly_summary: List[Dict[str, Any]] = insights.get("anomaly_summary", [])
    anomaly_details: List[Dict[str, Any]] = insights.get("anomaly_records", [])
    dq_summary = insights.get("dq_summary", {})

    top_gap_lines = []
    for row in top_gaps:
        roi = row.get("roi_months")
        roi_txt = "N/A" if roi is None or pd.isna(roi) else f"{float(roi):.1f}"
        gap_val = row.get("gap")
        gap_txt = "N/A" if gap_val is None or pd.isna(gap_val) else f"{float(gap_val):.2f}"
        top_gap_lines.append(
            f"- {row.get('product_name','ä¸æ˜')} (ã‚®ãƒ£ãƒƒãƒ— {gap_txt}, ROI {roi_txt}ãƒ¶æœˆ)"
        )
    top_gap_text = "\n".join(top_gap_lines) or "- è©²å½“ãªã—"

    anomaly_summary_text = "\n".join(
        [
            f"- {row['metric']}: {int(row['count'])}ä»¶ (å¹³å‡é€¸è„± {row['severity_mean']:.1f})"
            for row in anomaly_summary
        ]
    ) or "- å¤§ããªé€¸è„±ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"

    anomaly_detail_lines = []
    for row in anomaly_details[:5]:
        value = row.get("value")
        median_val = row.get("median")
        val_txt = "N/A" if value is None or pd.isna(value) else f"{float(value):.2f}"
        median_txt = "N/A" if median_val is None or pd.isna(median_val) else f"{float(median_val):.2f}"
        anomaly_detail_lines.append(
            f"ãƒ»{row.get('product_name','ä¸æ˜')} ({row.get('metric','-')}) = {val_txt} â†’ ä¸­å¤®å€¤ {median_txt}"
        )
    anomaly_detail_text = "\n".join(anomaly_detail_lines) or "ãƒ»è©³ç´°ã‚µãƒ³ãƒ—ãƒ«ãªã—"

    dq_text = (
        f"æ¬ æ{dq_summary.get('missing',0)}ä»¶ / å¤–ã‚Œå€¤{dq_summary.get('negative',0)}ä»¶ / é‡è¤‡{dq_summary.get('duplicate',0)}SKU"
        if dq_summary
        else "ãªã—"
    )

    prompt = (
        "ã‚ãªãŸã¯è£½é€ æ¥­å‘ã‘ã®çµŒå–¶ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚"
        "ä»¥ä¸‹ã®KPIã¨ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ã€AIãŒæŠ½å‡ºã—ãŸè¿½åŠ ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’è¸ã¾ãˆã€"
        "ç¾çŠ¶è©•ä¾¡ã¨å„ªå…ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ãƒªã‚¹ã‚¯ã‚’3æ®µè½ã§æ§‹æˆã—ã€æœ€å¾Œã«æ¬¡ã®ä¸€æ­©ã‚’ç®‡æ¡æ›¸ãã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚\n"
        f"KPI: é”æˆç‡={metrics.get('ach_rate',0):.1f}%, "
        f"å¿…è¦è³ƒç‡={metrics.get('req_rate',0):.3f}, "
        f"æç›Šåˆ†å²è³ƒç‡={metrics.get('be_rate',0):.3f}\n"
        f"ãƒ‡ãƒ¼ã‚¿å“è³ªã‚µãƒãƒª: {dq_text}\n"
        f"ä¸»è¦æœªé”SKU:\n{top_gap_text}\n"
        f"ç•°å¸¸æ¤œçŸ¥ã‚µãƒãƒª:\n{anomaly_summary_text}\n"
        f"ç•°å¸¸å€¤ã‚µãƒ³ãƒ—ãƒ«:\n{anomaly_detail_text}\n"
        f"ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:\n{sample}\n"
        "å‡ºåŠ›å½¢å¼:\n"
        "1. 50æ–‡å­—ä»¥å†…ã®çŠ¶æ³ã‚¿ã‚¤ãƒˆãƒ«\n"
        "2. KPIã®è§£é‡ˆ (ç®‡æ¡æ›¸ã3ç‚¹ä»¥å†…)\n"
        "3. æ”¹å–„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ (ç®‡æ¡æ›¸ã3ç‚¹ä»¥å†…)\n"
        "4. ãƒªã‚¹ã‚¯/ã‚±ã‚¢ã™ã¹ãç‚¹ (1-2ç‚¹)\n"
        "5. æ¬¡ã®ä¸€æ­© (1æ–‡)"
    )
    try:
        resp = client.responses.create(model="gpt-4o-mini", input=prompt)
        return resp.output_text.strip()
    except Exception as exc:
        return f"AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}"

st.title("â‘¡ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
render_sidebar_nav()
render_stepper(4)
scenario_name = st.session_state.get("current_scenario", "ãƒ™ãƒ¼ã‚¹")
st.caption(f"é©ç”¨ä¸­ã‚·ãƒŠãƒªã‚ª: {scenario_name}")
scenario_options = ["ãƒ™ãƒ¼ã‚¹", "æ–½ç­–A"]
selected_scenarios = st.multiselect(
    "ã‚·ãƒŠãƒªã‚ªé¸æŠ", scenario_options, default=scenario_options
)
st.session_state.setdefault("quick_price", 0)
st.session_state.setdefault("quick_ct", 0)
st.session_state.setdefault("quick_material", 0)
st.session_state.setdefault(
    "plotly_draw_tools", ["drawline", "drawrect", "drawopenpath", "drawcircle", "eraseshape"]
)
st.session_state.setdefault("show_rangeslider", True)
st.session_state.setdefault("show_spikelines", True)

with st.sidebar.expander("ã‚°ãƒ©ãƒ•æ“ä½œã‚ªãƒ—ã‚·ãƒ§ãƒ³", expanded=False):
    st.session_state["show_spikelines"] = st.checkbox(
        "ãƒ›ãƒãƒ¼æ™‚ã«ã‚¬ã‚¤ãƒ‰ç·šã‚’è¡¨ç¤º", value=st.session_state["show_spikelines"], help="æ‹¡å¤§ãƒ¢ãƒ¼ãƒ‰ã§ã‚‚X/Yæ–¹å‘ã®ã‚¹ãƒ‘ã‚¤ã‚¯ãƒ©ã‚¤ãƒ³ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"
    )
    st.session_state["show_rangeslider"] = st.checkbox(
        "æ™‚ç³»åˆ—ã«ãƒ¬ãƒ³ã‚¸ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¡¨ç¤º", value=st.session_state["show_rangeslider"], help="æœˆæ¬¡ãƒˆãƒ¬ãƒ³ãƒ‰ãªã©ã‚’æ‹¡å¤§è¡¨ç¤ºã—ãŸéš›ã«ã‚‚ç¯„å›²ã‚’ç´ æ—©ãèª¿æ•´ã§ãã¾ã™ã€‚"
    )
    st.session_state["plotly_draw_tools"] = st.multiselect(
        "æç”»ãƒ„ãƒ¼ãƒ« (æ‹¡å¤§ãƒ¢ãƒ¼ãƒ‰ã«ã‚‚åæ˜ )",
        options=["drawline", "drawopenpath", "drawcircle", "drawrect", "eraseshape"],
        default=st.session_state["plotly_draw_tools"],
    )
    st.caption("è¨­å®šã¯å…¨Plotlyã‚°ãƒ©ãƒ•ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ãƒãƒ¼ã«é©ç”¨ã•ã‚Œã¾ã™ã€‚")


def reset_quick_params() -> None:
    """Reset quick simulation parameters to their default values."""
    st.session_state["quick_price"] = 0
    st.session_state["quick_ct"] = 0
    st.session_state["quick_material"] = 0

if "df_products_raw" not in st.session_state or st.session_state["df_products_raw"] is None or len(st.session_state["df_products_raw"]) == 0:
    st.info("å…ˆã«ã€â‘  ãƒ‡ãƒ¼ã‚¿å…¥åŠ› & å–ã‚Šè¾¼ã¿ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

df_raw_all = st.session_state["df_products_raw"]
excluded_skus = st.session_state.get("dq_exclude_skus", [])
df_products_raw = df_raw_all[~df_raw_all["product_no"].isin(excluded_skus)].copy()
dq_df = detect_quality_issues(df_products_raw)
miss_count = int((dq_df["type"] == "æ¬ æ").sum())
out_count = int((dq_df["type"] == "å¤–ã‚Œå€¤").sum())
dup_count = int((dq_df["type"] == "é‡è¤‡").sum())
affected_skus = dq_df["product_no"].nunique()
scenarios = st.session_state.get("scenarios", {scenario_name: st.session_state.get("sr_params", DEFAULT_PARAMS)})
st.session_state["scenarios"] = scenarios
base_params = scenarios.get(scenario_name, st.session_state.get("sr_params", DEFAULT_PARAMS))
base_params, warn_list = sanitize_params(base_params)
scenarios[scenario_name] = base_params
_, base_results = compute_rates(base_params)
be_rate = base_results["break_even_rate"]
req_rate = base_results["required_rate"]
for w in warn_list:
    st.warning(w)

# Baseline classification for reclassification counts
df_default = compute_results(df_products_raw, be_rate, req_rate)

# Threshold tuning slider within filter panel
dcol1, dcol2 = st.columns([2, 0.8])
delta_low, delta_high = dcol1.slider(
    "Î´ = VA/åˆ† Ã· å¿…è¦è³ƒç‡ ã®å¢ƒç•Œ",
    min_value=0.5,
    max_value=1.5,
    value=(0.95, 1.05),
    step=0.01,
)
df = compute_results(df_products_raw, be_rate, req_rate, delta_low, delta_high)
reclassified = int((df["rate_class"] != df_default["rate_class"]).sum())
dcol2.metric("å†åˆ†é¡SKU", reclassified)

with st.expander("è¡¨ç¤ºè¨­å®š", expanded=False):
    topn = int(
        st.slider("æœªé”SKUã®ä¸Šä½ä»¶æ•°ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ‘ãƒ¬ãƒ¼ãƒˆï¼‰", min_value=5, max_value=50, value=20, step=1)
    )

# Global filters with view save/share
classes = df["rate_class"].dropna().unique().tolist()
global_mpu_min = float(np.nan_to_num(df["minutes_per_unit"].min(), nan=0.0))
global_mpu_max = float(np.nan_to_num(df["minutes_per_unit"].max(), nan=10.0))
global_v_min = float(np.nan_to_num(df["va_per_min"].replace([np.inf,-np.inf], np.nan).min(), nan=0.0))
global_v_max = float(np.nan_to_num(df["va_per_min"].replace([np.inf,-np.inf], np.nan).max(), nan=10.0))
qparams = dict(st.query_params)
default_classes = qparams.get("classes", ",".join(classes)).split(",")
default_classes = [c for c in default_classes if c in classes]
default_search = qparams.get("search", "")
mpu_param = qparams.get("mpu", f"{global_mpu_min},{global_mpu_max}")
try:
    m_min_q, m_max_q = [float(x) for x in mpu_param.split(",")]
except Exception:
    m_min_q, m_max_q = global_mpu_min, global_mpu_max
vapm_param = qparams.get("vapm", f"{global_v_min},{global_v_max}")
try:
    v_min_q, v_max_q = [float(x) for x in vapm_param.split(",")]
except Exception:
    v_min_q, v_max_q = global_v_min, global_v_max
fcol1, fcol2, fcol3, fcol4, fcol5, fcol6 = st.columns([1,1,2,2,0.5,0.5])
selected_classes = fcol1.multiselect("é”æˆåˆ†é¡ã§çµã‚Šè¾¼ã¿", classes, default=default_classes)
search = fcol2.text_input("è£½å“å æ¤œç´¢ï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰", default_search)
mpu_min, mpu_max = fcol3.slider(
    "åˆ†/å€‹ï¼ˆè£½é€ ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼‰ã®ç¯„å›²",
    global_mpu_min,
    global_mpu_max,
    value=(m_min_q, m_max_q)
)
vapm_min, vapm_max = fcol4.slider(
    "ä»˜åŠ ä¾¡å€¤/åˆ† ã®ç¯„å›²",
    global_v_min,
    global_v_max,
    value=(v_min_q, v_max_q)
)
save_btn = fcol5.button("ä¿å­˜")
share_btn = fcol6.button("å…±æœ‰")
if save_btn or share_btn:
    state = {
        "classes": ",".join(selected_classes),
        "search": search,
        "mpu": f"{mpu_min},{mpu_max}",
        "vapm": f"{vapm_min},{vapm_max}"
    }
    st.query_params = state
    if share_btn:
        st.session_state["share_link"] = "?" + urlencode(state)
        st.session_state["show_share"] = True
    if save_btn:
        st.session_state["show_saved"] = True
    st.rerun()
if st.session_state.pop("show_saved", False):
    st.success("ãƒ“ãƒ¥ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
if st.session_state.pop("show_share", False):
    st.code(st.session_state.pop("share_link", ""), language=None)

mask = df["rate_class"].isin(selected_classes)
if search:
    mask &= df["product_name"].astype(str).str.contains(search, na=False)
mask &= df["minutes_per_unit"].fillna(0.0).between(mpu_min, mpu_max)
mask &= df["va_per_min"].replace([np.inf,-np.inf], np.nan).fillna(0.0).between(vapm_min, vapm_max)
df_view_filtered = df[mask].copy()

# Quick simulation toggles
qcol1, qcol2, qcol3, qcol4 = st.columns([1,1,1,0.6])
with qcol1:
    st.radio(
        "ä¾¡æ ¼", options=[0,3,5,10], format_func=lambda x: f"+{x}%", key="quick_price", horizontal=True
    )
with qcol2:
    st.radio(
        "CT", options=[0,-5,-10], format_func=lambda x: f"{x}%", key="quick_ct", horizontal=True
    )
with qcol3:
    st.radio(
        "ææ–™", options=[0,-3,-5], format_func=lambda x: f"{x}%", key="quick_material", horizontal=True
    )
with qcol4:
    st.button("Undo", on_click=reset_quick_params)

qp = st.session_state["quick_price"]
qc = st.session_state["quick_ct"]
qm = st.session_state["quick_material"]
df_base = df_view_filtered.copy()
base_ach_rate = (df_base["meets_required_rate"].mean()*100.0) if len(df_base)>0 else 0.0
base_avg_vapm = df_base["va_per_min"].replace([np.inf,-np.inf], np.nan).dropna().mean() if "va_per_min" in df_base else 0.0
df_sim = df_base.copy()
if qp:
    df_sim["actual_unit_price"] *= (1 + qp/100.0)
if qc:
    df_sim["minutes_per_unit"] *= (1 + qc/100.0)
if qm:
    df_sim["material_unit_cost"] *= (1 + qm/100.0)
df_sim["gp_per_unit"] = df_sim["actual_unit_price"] - df_sim["material_unit_cost"]
df_sim["daily_total_minutes"] = df_sim["minutes_per_unit"] * df_sim["daily_qty"]
df_sim["daily_va"] = df_sim["gp_per_unit"] * df_sim["daily_qty"]
with np.errstate(divide='ignore', invalid='ignore'):
    df_sim["va_per_min"] = df_sim["daily_va"] / df_sim["daily_total_minutes"]
df_view = compute_results(df_sim, be_rate, req_rate, delta_low, delta_high)
ach_rate = (df_view["meets_required_rate"].mean()*100.0) if len(df_view)>0 else 0.0
avg_vapm = df_view["va_per_min"].replace([np.inf,-np.inf], np.nan).dropna().mean() if "va_per_min" in df_view else 0.0
if qp or qc or qm:
    st.caption(f"Quickè©¦ç®—ä¸­: ä¾¡æ ¼{qp:+d}%, CT{qc:+d}%, ææ–™{qm:+d}%")

# === KPI Targets & Cards ===
role = st.session_state.get("role", "ä¸€èˆ¬")
st.session_state.setdefault("target_req_rate", req_rate)
st.session_state.setdefault("target_ach_rate", ach_rate)
with st.sidebar.expander("KPIç›®æ¨™è¨­å®š", expanded=False):
    if role in ("çµŒå–¶è€…", "ç®¡ç†è€…"):
        st.session_state["target_req_rate"] = st.number_input(
            "ç›®æ¨™å¿…è¦è³ƒç‡ (å††/åˆ†)", value=st.session_state["target_req_rate"], format="%.3f"
        )
        st.session_state["target_ach_rate"] = st.number_input(
            "ç›®æ¨™é”æˆç‡ (%)", value=st.session_state["target_ach_rate"], format="%.1f"
        )
    else:
        st.number_input(
            "ç›®æ¨™å¿…è¦è³ƒç‡ (å††/åˆ†)", value=st.session_state["target_req_rate"], format="%.3f", disabled=True
        )
        st.number_input(
            "ç›®æ¨™é”æˆç‡ (%)", value=st.session_state["target_ach_rate"], format="%.1f", disabled=True
        )
target_req_rate = st.session_state["target_req_rate"]
target_ach_rate = st.session_state["target_ach_rate"]

anomaly_df = detect_anomalies(df_view)
if not anomaly_df.empty:
    anomaly_summary_stats = (
        anomaly_df.groupby("metric")
        .agg(count=("metric", "size"), severity_mean=("severity", "mean"))
        .reset_index()
        .sort_values(["count", "severity_mean"], ascending=[False, False])
    )
else:
    anomaly_summary_stats = pd.DataFrame(columns=["metric", "count", "severity_mean"])

gap_df = df_view.copy()
gap_df["gap"] = req_rate - gap_df["va_per_min"]
gap_df = gap_df[gap_df["gap"] > 0]
gap_df["price_improve"] = (gap_df["required_selling_price"] - gap_df["actual_unit_price"]).clip(lower=0)
gap_df["ct_improve"] = (gap_df["minutes_per_unit"] - (gap_df["gp_per_unit"] / req_rate)).clip(lower=0)
gap_df["material_improve"] = (
    gap_df["material_unit_cost"]
    - (gap_df["actual_unit_price"] - req_rate * gap_df["minutes_per_unit"])
).clip(lower=0)
gap_df["roi_months"] = gap_df["price_improve"].replace({0: np.nan}) / gap_df["gap"].replace({0: np.nan})
top_list = gap_df.sort_values("gap", ascending=False).head(20)
top_cards = top_list.head(5)


def _render_target_badge(col, text: str) -> None:
    col.markdown(
        f"<div class='metric-badge'><span style='background-color:#E0EEF4;padding:4px 10px;border-radius:999px;font-size:0.8em;'>ğŸ¯{text}</span></div>",
        unsafe_allow_html=True,
    )


col1, col2, col3, col5 = st.columns([1, 1, 1, 1])
_render_target_badge(col1, f"{target_req_rate:,.3f}")
col1.metric(
    "å¿…è¦è³ƒç‡ (å††/åˆ†)", f"{req_rate:,.3f}", delta=f"{req_rate - target_req_rate:+.3f}"
)
_render_target_badge(col2, f"{target_ach_rate:.1f}%")
col2.metric(
    "å¿…è¦è³ƒç‡é”æˆç‡ (%)", f"{ach_rate:.1f}", delta=f"{ach_rate - target_ach_rate:+.1f}"
)
col3.metric("æç›Šåˆ†å²è³ƒç‡ (å††/åˆ†)", f"{be_rate:,.3f}")
with col5:
    dq_label = f"æ¬ {miss_count} å¤–{out_count} é‡{dup_count} / {affected_skus}SKU"
    st.markdown(
        f"<a href='#dq_errors' style='background-color:#F28B82;color:#1F2A44;padding:6px 10px;border-radius:999px;text-decoration:none;font-weight:600;display:inline-block;'>{dq_label}</a>",
        unsafe_allow_html=True,
    )

kpi_data = [
    {"scenario": "ãƒ™ãƒ¼ã‚¹", "KPI": "å¿…è¦è³ƒç‡é”æˆSKUæ¯”ç‡", "value": base_ach_rate},
    {"scenario": "ãƒ™ãƒ¼ã‚¹", "KPI": "å¹³å‡ ä»˜åŠ ä¾¡å€¤/åˆ†", "value": base_avg_vapm},
    {"scenario": "æ–½ç­–A", "KPI": "å¿…è¦è³ƒç‡é”æˆSKUæ¯”ç‡", "value": ach_rate},
    {"scenario": "æ–½ç­–A", "KPI": "å¹³å‡ ä»˜åŠ ä¾¡å€¤/åˆ†", "value": avg_vapm},
]
kpi_df = pd.DataFrame(kpi_data)
kpi_df = kpi_df[kpi_df["scenario"].isin(selected_scenarios)]
fig_kpi = px.bar(
    kpi_df,
    x="KPI",
    y="value",
    color="scenario",
    barmode="group",
    color_discrete_sequence=PASTEL_PALETTE,
)
fig_kpi.update_traces(opacity=0.85)
fig_kpi.update_yaxes(gridcolor="#D7E2EA")
fig_kpi.update_xaxes(gridcolor="#D7E2EA")
fig_kpi = _apply_plotly_theme(fig_kpi, legend_bottom=True)
st.plotly_chart(fig_kpi, use_container_width=True, config=_build_plotly_config())

ai_insights = {
    "top_underperformers": top_list[["product_name", "gap", "roi_months"]].head(3).to_dict("records")
    if not top_list.empty
    else [],
    "anomaly_summary": anomaly_summary_stats.to_dict("records"),
    "anomaly_records": anomaly_df.head(5).to_dict("records"),
    "dq_summary": {"missing": miss_count, "negative": out_count, "duplicate": dup_count},
}

st.subheader("AIã‚³ãƒ¡ãƒ³ãƒˆ")
if st.button("AIã‚³ãƒ¡ãƒ³ãƒˆç”Ÿæˆ"):
    with st.spinner("ç”Ÿæˆä¸­..."):
        st.session_state["dashboard_ai_comment"] = _generate_dashboard_comment(
            df_view,
            {"ach_rate": ach_rate, "req_rate": req_rate, "be_rate": be_rate},
            ai_insights,
        )
st.markdown(st.session_state.get("dashboard_ai_comment", ""))

st.markdown("<div id='dq_errors'></div>", unsafe_allow_html=True)
st.subheader("ãƒ‡ãƒ¼ã‚¿å“è³ªã‚¨ãƒ©ãƒ¼ä¸€è¦§")
if dq_df.empty:
    st.success("ã‚¨ãƒ©ãƒ¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    dq_display = dq_df.rename(
        columns={
            "product_no": "è£½å“ç•ªå·",
            "product_name": "è£½å“å",
            "type": "ç¨®åˆ¥",
            "column": "é …ç›®",
        }
    )
    dq_display.insert(0, "é™¤å¤–", dq_display["è£½å“ç•ªå·"].isin(excluded_skus))
    edited = st.data_editor(dq_display, use_container_width=True, key="dq_editor")
    new_excluded = edited[edited["é™¤å¤–"]]["è£½å“ç•ªå·"].unique().tolist()
    if set(new_excluded) != set(excluded_skus):
        st.session_state["dq_exclude_skus"] = new_excluded
        st.rerun()

st.subheader("ç•°å¸¸å€¤ãƒã‚¤ãƒ©ã‚¤ãƒˆ")
if anomaly_df.empty:
    st.success("çµ±è¨ˆçš„ãªç•°å¸¸å€¤ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    highlight = anomaly_df.head(3)
    cols = st.columns(len(highlight))
    for col, row in zip(cols, highlight.to_dict("records")):
        direction = "ä¸ŠæŒ¯ã‚Œ" if row.get("direction") == "high" else "ä¸‹æŒ¯ã‚Œ"
        val_txt = "N/A" if pd.isna(row.get("value")) else f"{row['value']:.2f}"
        col.metric(
            f"{row.get('product_name', 'ä¸æ˜')} ({row.get('metric', '-')})",
            val_txt,
            delta=f"{direction} zâ‰ˆ{row.get('severity', 0):.1f}",
        )

    if not anomaly_summary_stats.empty:
        summary_df = anomaly_summary_stats.rename(
            columns={"metric": "æŒ‡æ¨™", "count": "ä»¶æ•°", "severity_mean": "å¹³å‡é€¸è„±"}
        )
        st.dataframe(summary_df, use_container_width=True)

    detail_df = anomaly_df.head(20).rename(
        columns={
            "product_no": "è£½å“ç•ªå·",
            "product_name": "è£½å“å",
            "metric": "æŒ‡æ¨™",
            "value": "å€¤",
            "direction": "æ–¹å‘",
            "severity": "é€¸è„±åº¦",
            "median": "ä¸­å¤®å€¤",
            "iqr_lower": "IQRä¸‹é™",
            "iqr_upper": "IQRä¸Šé™",
        }
    )
    with st.expander("ç•°å¸¸å€¤è©³ç´° (ä¸Šä½20ä»¶)", expanded=False):
        st.dataframe(detail_df, use_container_width=True)

st.divider()

# Actionable SKU Top List
st.subheader("è¦å¯¾ç­–SKUãƒˆãƒƒãƒ—ãƒªã‚¹ãƒˆ")
st.caption("ã‚®ãƒ£ãƒƒãƒ— = å¿…è¦è³ƒç‡ - ä»˜åŠ ä¾¡å€¤/åˆ†")
top5 = top_cards
if len(top5) > 0:
    card_cols = st.columns(len(top5))
    for col, row in zip(card_cols, top5.to_dict("records")):
        roi_txt = "N/A" if pd.isna(row.get("roi_months")) else f"{row['roi_months']:.1f}"
        gap_txt = "N/A" if pd.isna(row.get("gap")) else f"{row['gap']:.2f}"
        col.metric(row["product_name"], gap_txt, delta=f"ROI {roi_txt}æœˆ")
        col.caption(
            " / ".join(
                [
                    f"ä¾¡æ ¼+{row['price_improve']:.1f}" if not pd.isna(row.get("price_improve")) else "ä¾¡æ ¼æ”¹å–„æƒ…å ±ãªã—",
                    f"CT-{row['ct_improve']:.2f}" if not pd.isna(row.get("ct_improve")) else "CTæ”¹å–„æƒ…å ±ãªã—",
                    f"ææ–™-{row['material_improve']:.1f}" if not pd.isna(row.get("material_improve")) else "ææ–™æ”¹å–„æƒ…å ±ãªã—",
                ]
            )
        )

    table = top_list[[
        "product_no","product_name","gap","price_improve","ct_improve","material_improve","roi_months"
    ]].rename(columns={
        "product_no":"è£½å“ç•ªå·",
        "product_name":"è£½å“å",
        "gap":"ã‚®ãƒ£ãƒƒãƒ—",
        "price_improve":"ä¾¡æ ¼æ”¹å–„",
        "ct_improve":"CTæ”¹å–„",
        "material_improve":"ææ–™æ”¹å–„",
        "roi_months":"æƒ³å®šROI(æœˆ)"
    })
    table.insert(0, "é¸æŠ", False)
    edited = st.data_editor(table, use_container_width=True, key="action_sku_editor")
    csv_top = edited.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "CSVå‡ºåŠ›",
        data=csv_top,
        file_name="action_sku_top20.csv",
        mime="text/csv",
    )
    selected = edited[edited["é¸æŠ"]]
    if st.button("ã‚·ãƒŠãƒªã‚ªã«åæ˜ "):
        st.session_state["selected_action_skus"] = selected
        st.success(f"{len(selected)}ä»¶ã‚’ã‚·ãƒŠãƒªã‚ªã«åæ˜ ã—ã¾ã—ãŸ")
else:
    st.info("è¦å¯¾ç­–SKUã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

tabs = st.tabs(["å…¨ä½“åˆ†å¸ƒï¼ˆæ•£å¸ƒå›³ï¼‰", "æ™‚ç³»åˆ—", "é”æˆçŠ¶æ³ï¼ˆæ£’/å††ï¼‰", "æœªé”SKUï¼ˆãƒ‘ãƒ¬ãƒ¼ãƒˆï¼‰", "SKUãƒ†ãƒ¼ãƒ–ãƒ«", "ä»˜åŠ ä¾¡å€¤/åˆ†åˆ†å¸ƒ"])

with tabs[0]:
    st.caption(
        "æ¨ªè»¸=åˆ†/å€‹ï¼ˆè£½é€ ãƒªãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ï¼‰, ç¸¦è»¸=ä»˜åŠ ä¾¡å€¤/åˆ†ã€‚å¿…è¦è³ƒç‡Ã—Î´å¸¯ã¨æç›Šåˆ†å²è³ƒç‡ã‚’è¡¨ç¤ºã€‚"
    )
    df_base["scenario"] = "ãƒ™ãƒ¼ã‚¹"
    df_view["scenario"] = "æ–½ç­–A"
    scatter_df = pd.concat([df_base, df_view], ignore_index=True)
    scatter_df = scatter_df[scatter_df["scenario"].isin(selected_scenarios)].copy()
    scatter_df["margin_to_req"] = req_rate - scatter_df["va_per_min"]
    fig = px.scatter(
        scatter_df,
        x="minutes_per_unit",
        y="va_per_min",
        color="scenario",
        hover_data={
            "product_name": True,
            "minutes_per_unit": ":.2f",
            "va_per_min": ":.2f",
            "margin_to_req": ":.2f",
        },
        opacity=0.8,
        color_discrete_sequence=PASTEL_PALETTE,
        height=420,
    )
    fig.update_traces(marker=dict(size=9, line=dict(color="#FFFFFF", width=0.6)))
    fig.add_hrect(
        y0=req_rate * delta_low,
        y1=req_rate * delta_high,
        line_width=0,
        fillcolor="#9BC0A0",
        opacity=0.15,
    )
    fig.add_hline(y=req_rate, line_color="#2F6776", line_width=2)
    fig.add_hline(y=be_rate, line_color="#E7A07A", line_dash="dash")
    fig.update_xaxes(title="åˆ†/å€‹", gridcolor="#D7E2EA")
    fig.update_yaxes(title="ä»˜åŠ ä¾¡å€¤/åˆ†", gridcolor="#D7E2EA")
    fig = _apply_plotly_theme(fig, show_spikelines=st.session_state["show_spikelines"])
    st.plotly_chart(fig, use_container_width=True, config=_build_plotly_config())

with tabs[1]:
    st.caption("æœˆæ¬¡ã®é”æˆSKUæ¯”ç‡ã¨å¹³å‡VA/åˆ†ã®æ¨ç§»ã€‚ãƒ™ãƒ¼ã‚¹ã¨æ–½ç­–Aã‚’æ¯”è¼ƒã€‚")
    trend_df = st.session_state.get("monthly_trend")
    if trend_df is None or trend_df.empty:
        months = pd.date_range(end=pd.Timestamp.today(), periods=6, freq="M")
        base = pd.DataFrame({
            "month": months,
            "achieved_ratio": np.linspace(0.6, 0.7, len(months)),
            "va_per_min": np.linspace(100, 110, len(months)),
            "scenario": "ãƒ™ãƒ¼ã‚¹",
        })
        plan = base.copy()
        plan["achieved_ratio"] += 0.05
        plan["va_per_min"] += 5
        plan["scenario"] = "æ–½ç­–A"
        trend_df = pd.concat([base, plan], ignore_index=True)
    fig_ts = make_subplots(specs=[[{"secondary_y": True}]])
    scenario_colors = {
        scen: PASTEL_PALETTE[idx % len(PASTEL_PALETTE)]
        for idx, scen in enumerate(sorted(trend_df["scenario"].unique()))
    }
    for scen, g in trend_df.groupby("scenario"):
        fig_ts.add_trace(
            go.Scatter(
                x=g["month"],
                y=g["achieved_ratio"],
                mode="lines+markers",
                name=f"{scen} é”æˆæ¯”ç‡",
                line=dict(color=scenario_colors.get(scen), width=2.5),
                marker=dict(size=8),
            ),
            secondary_y=False,
        )
        fig_ts.add_trace(
            go.Scatter(
                x=g["month"],
                y=g["va_per_min"],
                mode="lines+markers",
                name=f"{scen} å¹³å‡VA/åˆ†",
                line=dict(color=scenario_colors.get(scen, PASTEL_ACCENT), width=2, dash="dot"),
                marker=dict(size=8, symbol="diamond"),
            ),
            secondary_y=True,
        )
    fig_ts.update_yaxes(title_text="é”æˆSKUæ¯”ç‡", range=[0,1], secondary_y=False)
    fig_ts.update_yaxes(title_text="å¹³å‡VA/åˆ†", secondary_y=True)
    fig_ts.update_xaxes(
        gridcolor="#D7E2EA",
        rangeslider=dict(visible=st.session_state["show_rangeslider"]),
        rangeselector=dict(
            buttons=[
                dict(count=3, label="3M", step="month", stepmode="backward"),
                dict(count=6, label="6M", step="month", stepmode="backward"),
                dict(step="all", label="ALL"),
            ],
            bgcolor="rgba(47,103,118,0.08)",
            activecolor="#2F6776",
            font=dict(color="#1F2A44"),
        ),
    )
    fig_ts.update_yaxes(gridcolor="#D7E2EA", secondary_y=False)
    fig_ts.update_yaxes(gridcolor="#D7E2EA", secondary_y=True)
    fig_ts = _apply_plotly_theme(fig_ts, show_spikelines=st.session_state["show_spikelines"])
    st.plotly_chart(fig_ts, use_container_width=True, config=_build_plotly_config())

with tabs[2]:
    c1, c2 = st.columns([1.2,1])
    class_counts = df_view["rate_class"].value_counts().reset_index()
    class_counts.columns = ["rate_class", "count"]
    bar = alt.Chart(class_counts).mark_bar(color=PASTEL_ACCENT).encode(
        x=alt.X("rate_class:N", title="é”æˆåˆ†é¡"),
        y=alt.Y("count:Q", title="ä»¶æ•°"),
        tooltip=["rate_class","count"]
    ).properties(height=380)
    c1.altair_chart(bar, use_container_width=True)

    # Achievers vs Missed donut
    donut_df = pd.DataFrame({
        "group": ["é”æˆ", "æœªé”"],
        "value": [ (df_view["meets_required_rate"].sum()), ( (~df_view["meets_required_rate"]).sum() ) ]
    })
    donut = (
        alt.Chart(donut_df)
        .mark_arc(innerRadius=80)
        .encode(
            theta="value:Q",
            color=alt.Color(
                "group:N",
                scale=alt.Scale(range=[PASTEL_ACCENT, "#DDA0BC"]),
                title="é”æˆçŠ¶æ³",
            ),
            tooltip=["group", "value"],
        )
    )
    c2.altair_chart(donut, use_container_width=True)

with tabs[3]:
    miss = df_view[df_view["meets_required_rate"] == False].copy()
    miss = miss.sort_values("rate_gap_vs_required").head(topn)
    st.caption("ã€å¿…è¦è³ƒç‡å·®ã€ãŒå°ã•ã„ï¼ˆã¾ãŸã¯ãƒã‚¤ãƒŠã‚¹ãŒå¤§ï¼‰ã®é †ã€‚å³ã»ã©æ”¹å–„ä½™åœ°ãŒå¤§ã€‚")
    if len(miss)==0:
        st.success("æœªé”SKUã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        pareto = alt.Chart(miss).mark_bar(color=PASTEL_ACCENT).encode(
            x=alt.X("product_name:N", sort="-y", title="è£½å“å"),
            y=alt.Y("rate_gap_vs_required:Q", title="å¿…è¦è³ƒç‡å·®ï¼ˆä»˜åŠ ä¾¡å€¤/åˆ† - å¿…è¦è³ƒç‡ï¼‰"),
            tooltip=["product_name","rate_gap_vs_required"]
        ).properties(height=420)
        st.altair_chart(pareto, use_container_width=True)
        st.dataframe(miss[["product_no","product_name","minutes_per_unit","va_per_min","rate_gap_vs_required","price_gap_vs_required"]], use_container_width=True)

with tabs[4]:
    rename_map = {
        "product_no": "è£½å“ç•ªå·",
        "product_name": "è£½å“å",
        "actual_unit_price": "å®Ÿéš›å£²å˜ä¾¡",
        "material_unit_cost": "ææ–™åŸä¾¡",
        "minutes_per_unit": "åˆ†/å€‹",
        "daily_qty": "æ—¥ç”£æ•°",
        "daily_total_minutes": "æ—¥ç”£åˆè¨ˆ(åˆ†)",
        "gp_per_unit": "ç²—åˆ©/å€‹",
        "daily_va": "ä»˜åŠ ä¾¡å€¤(æ—¥ç”£)",
        "va_per_min": "ä»˜åŠ ä¾¡å€¤/åˆ†",
        "be_va_unit_price": "æç›Šåˆ†å²ä»˜åŠ ä¾¡å€¤å˜ä¾¡",
        "req_va_unit_price": "å¿…è¦ä»˜åŠ ä¾¡å€¤å˜ä¾¡",
        "required_selling_price": "å¿…è¦è²©å£²å˜ä¾¡",
        "price_gap_vs_required": "å¿…è¦è²©å£²å˜ä¾¡å·®é¡",
        "rate_gap_vs_required": "å¿…è¦è³ƒç‡å·®",
        "meets_required_rate": "å¿…è¦è³ƒç‡é”æˆ",
        "rate_class": "é”æˆåˆ†é¡",
    }
    ordered_cols = [
        "è£½å“ç•ªå·","è£½å“å","å®Ÿéš›å£²å˜ä¾¡","å¿…è¦è²©å£²å˜ä¾¡","å¿…è¦è²©å£²å˜ä¾¡å·®é¡","ææ–™åŸä¾¡","ç²—åˆ©/å€‹",
        "åˆ†/å€‹","æ—¥ç”£æ•°","æ—¥ç”£åˆè¨ˆ(åˆ†)","ä»˜åŠ ä¾¡å€¤(æ—¥ç”£)","ä»˜åŠ ä¾¡å€¤/åˆ†",
        "æç›Šåˆ†å²ä»˜åŠ ä¾¡å€¤å˜ä¾¡","å¿…è¦ä»˜åŠ ä¾¡å€¤å˜ä¾¡","å¿…è¦è³ƒç‡å·®","å¿…è¦è³ƒç‡é”æˆ","é”æˆåˆ†é¡",
    ]
    df_table = df_view.rename(columns=rename_map)
    df_table = df_table[[c for c in ordered_cols if c in df_table.columns]]

    st.dataframe(df_table, use_container_width=True, height=520)
    csv = df_table.to_csv(index=False).encode("utf-8-sig")
    st.download_button("çµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="calc_results.csv", mime="text/csv")

with tabs[5]:
    hist = alt.Chart(df_view).mark_bar(color=PASTEL_ACCENT).encode(
        x=alt.X("va_per_min:Q", bin=alt.Bin(maxbins=30), title="ä»˜åŠ ä¾¡å€¤/åˆ†"),
        y=alt.Y("count()", title="ä»¶æ•°"),
        tooltip=["count()"]
    ).properties(height=420)
    st.altair_chart(hist, use_container_width=True)

import sys
from pathlib import Path
sys.path.append(str(Path(__file__).resolve().parents[1]))

from datetime import date, datetime, timedelta

import streamlit as st
import pandas as pd
from data_integrations import (
    IntegrationConfig,
    SUPPORTED_ACCOUNTING_APPS,
    SUPPORTED_POS_SYSTEMS,
    apply_transaction_summary_to_products,
    extract_transaction_period,
    load_transactions_for_sync,
    summarize_transactions,
)
from utils import (
    read_excel_safely,
    parse_hyochin,
    parse_products,
    generate_product_template,
    get_product_template_guide,
    validate_product_dataframe,
    infer_category_from_name,
    infer_major_customer,
)
from components import (
    apply_user_theme,
    render_help_button,
    render_onboarding,
    render_page_tutorial,
    render_stepper,
    render_sidebar_nav,
)

apply_user_theme()

st.title("â‘  ãƒ‡ãƒ¼ã‚¿å…¥åŠ› & å–ã‚Šè¾¼ã¿")
render_sidebar_nav(page_key="data")
render_help_button("data")

render_onboarding()
render_page_tutorial("data")
render_stepper(1)

st.subheader("Excelãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ")
st.markdown(
    "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã¯å¿…é ˆé …ç›®ã®èª¬æ˜ã¨ã‚µãƒ³ãƒ—ãƒ«å€¤ã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚"
    " è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã™ã‚‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ—åã¨å˜ä½ã‚’å¤‰æ›´ã—ãªã„ã‚ˆã†ã”æ³¨æ„ãã ã•ã„ã€‚"
)

guide_df = get_product_template_guide()
st.table(guide_df)

template_bytes = generate_product_template()
st.download_button(
    "ğŸ“„ è£½å“ãƒã‚¹ã‚¿å…¥åŠ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    data=template_bytes,
    file_name="product_master_template.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

st.caption("â€»ã€æ¨™è³ƒã€ã‚·ãƒ¼ãƒˆã«ã‚‚ã‚µãƒ³ãƒ—ãƒ«å€¤ã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦å®Ÿç¸¾å€¤ã¸ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚")

st.divider()

default_path = "data/sample.xlsx"
file = st.file_uploader("Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæœªæŒ‡å®šãªã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ï¼‰", type=["xlsx"])

if file is not None or "df_products_raw" not in st.session_state:
    if file is None:
        st.info("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        xls = read_excel_safely(default_path)
        st.session_state["using_sample_data"] = True
    else:
        xls = read_excel_safely(file)
        st.session_state["using_sample_data"] = False

    if xls is None:
        st.error("Excel èª­è¾¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒ»ã‚·ãƒ¼ãƒˆåã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        st.stop()

    with st.spinner("ã€æ¨™è³ƒã€ã‚’è§£æä¸­..."):
        calc_params, sr_params, warn1 = parse_hyochin(xls)

    with st.spinner("ã€R6.12ã€è£½å“ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­..."):
        df_products, warn2 = parse_products(xls, sheet_name="R6.12")

    for w in (warn1 + warn2):
        st.warning(w)

    if st.session_state.get("using_sample_data"):
        df_products = df_products.copy()
        if "category" not in df_products.columns or df_products["category"].isna().all():
            df_products["category"] = df_products["product_name"].apply(
                infer_category_from_name
            )
        if "major_customer" not in df_products.columns or df_products["major_customer"].isna().all():
            df_products["major_customer"] = [
                infer_major_customer(no, name)
                for no, name in zip(
                    df_products.get("product_no"), df_products.get("product_name")
                )
            ]
        st.caption(
            "â€» ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ã¯è£½å“åã‹ã‚‰æ¨å®šã—ãŸã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ä¸»è¦é¡§å®¢ã‚’è‡ªå‹•ä»˜ä¸ã—ã¦ã„ã¾ã™ã€‚"
        )

    errors, val_warnings, detail_df = validate_product_dataframe(df_products)
    for msg in val_warnings:
        st.warning(msg)
    for msg in errors:
        st.error(msg)

    if not detail_df.empty:
        with st.expander("æ¤œçŸ¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆã®è©³ç´°", expanded=bool(errors)):
            st.dataframe(detail_df, use_container_width=True)

    if errors:
        st.stop()
    elif not val_warnings:
        st.success("ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚’é€šéã—ã¾ã—ãŸã€‚")

    st.session_state["sr_params"] = sr_params
    st.session_state["df_products_raw"] = df_products
    st.session_state["calc_params"] = calc_params
else:
    sr_params = st.session_state["sr_params"]
    df_products = st.session_state["df_products_raw"]
    calc_params = st.session_state.get("calc_params", {})

if "scenarios" not in st.session_state:
    st.session_state["scenarios"] = {"ãƒ™ãƒ¼ã‚¹": sr_params.copy()}
    st.session_state["current_scenario"] = "ãƒ™ãƒ¼ã‚¹"
else:
    st.session_state["scenarios"]["ãƒ™ãƒ¼ã‚¹"] = sr_params.copy()
if "current_scenario" not in st.session_state:
    st.session_state["current_scenario"] = "ãƒ™ãƒ¼ã‚¹"

st.session_state.setdefault("external_sync_history", [])
st.session_state.setdefault("external_sync_last_summary", [])
st.session_state.setdefault("external_sync_last_transactions", None)

st.caption(f"é©ç”¨ä¸­ã‚·ãƒŠãƒªã‚ª: {st.session_state['current_scenario']}")

c1, c2, c3 = st.columns(3)
c1.metric("å›ºå®šè²»è¨ˆ (åƒå††/å¹´)", f"{calc_params.get('fixed_total', 0)/1000:,.0f}")
c2.metric("å¿…è¦åˆ©ç›Šè¨ˆ (åƒå††/å¹´)", f"{calc_params.get('required_profit_total', 0)/1000:,.0f}")
c3.metric("å¹´é–“æ¨™æº–ç¨¼åƒåˆ† (åˆ†/å¹´)", f"{calc_params.get('annual_minutes', 0):,.0f}")

st.divider()
st.subheader("è£½å“ãƒ‡ãƒ¼ã‚¿")
keyword = st.text_input("è£½å“ç•ªå·ã¾ãŸã¯åç§°ã§æ¤œç´¢", "")
if keyword:
    mask = (
        df_products["product_no"].astype(str).str.contains(keyword, regex=False)
        | df_products["product_name"].astype(str).str.contains(keyword, regex=False)
    )
    df_view = df_products[mask]
else:
    df_view = df_products
st.dataframe(df_view, use_container_width=True)

with st.expander("æ–°è¦è£½å“ã‚’è¿½åŠ ", expanded=False):
    with st.form("add_product_form"):
        col_a, col_b = st.columns(2)
        product_no = col_a.text_input("è£½å“ç•ªå·", "")
        product_name = col_b.text_input("è£½å“å", "")
        actual_unit_price = st.number_input("å®Ÿéš›å£²å˜ä¾¡", value=0.0, step=1.0)
        material_unit_cost = st.number_input("ææ–™åŸä¾¡", value=0.0, step=1.0)
        minutes_per_unit = st.number_input("åˆ†/å€‹", value=0.0, step=0.1)
        daily_qty = st.number_input("æ—¥ç”£æ•°", value=0.0, step=1.0)
        col_c, col_d = st.columns(2)
        category = col_c.text_input("ã‚«ãƒ†ã‚´ãƒªãƒ¼", "")
        major_customer = col_d.text_input("ä¸»è¦é¡§å®¢", "")
        submitted = st.form_submit_button("è¿½åŠ ")
    if submitted:
        gp_per_unit = actual_unit_price - material_unit_cost
        daily_total_minutes = minutes_per_unit * daily_qty
        daily_va = gp_per_unit * daily_qty
        va_per_min = daily_va / daily_total_minutes if daily_total_minutes else 0.0
        new_row = {
            "product_no": product_no,
            "product_name": product_name,
            "actual_unit_price": actual_unit_price,
            "material_unit_cost": material_unit_cost,
            "minutes_per_unit": minutes_per_unit,
            "daily_qty": daily_qty,
            "daily_total_minutes": daily_total_minutes,
            "gp_per_unit": gp_per_unit,
            "daily_va": daily_va,
            "va_per_min": va_per_min,
            "category": category,
            "major_customer": major_customer,
        }
        df_products = pd.concat([df_products, pd.DataFrame([new_row])], ignore_index=True)
        st.session_state["df_products_raw"] = df_products
        st.success("è£½å“ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
        st.rerun()

st.divider()
st.subheader("ç”Ÿç”£ãƒ»è²©å£²ã‚·ã‚¹ãƒ†ãƒ ã¨ã®ãƒ‡ãƒ¼ã‚¿é€£æº")
st.caption(
    "å¼¥ç”Ÿä¼šè¨ˆã‚„freeeãªã©ã®ä¼šè¨ˆã‚½ãƒ•ãƒˆã€POSã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å£²ä¸Šãƒ»åŸä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸã—ã€"
    "æœ€æ–°ã®è£½å“æŒ‡æ¨™ã‚’è‡ªå‹•åæ˜ ã§ãã¾ã™ã€‚"
)

feedback = st.session_state.pop("external_sync_feedback", None)
if feedback:
    level = feedback.get("level", "info")
    message = feedback.get("message", "")
    display = getattr(st, level, st.info)
    if message:
        display(message)

latest_summary_records = st.session_state.get("external_sync_last_summary") or []
if latest_summary_records:
    latest_summary_df = pd.DataFrame(latest_summary_records)
    if not latest_summary_df.empty:
        st.markdown("**ç›´è¿‘ã®åŒæœŸçµæœï¼ˆSKUåˆ¥é›†è¨ˆï¼‰**")
        st.dataframe(latest_summary_df, use_container_width=True)

latest_transactions = st.session_state.get("external_sync_last_transactions")
if isinstance(latest_transactions, pd.DataFrame) and not latest_transactions.empty:
    with st.expander("ç›´è¿‘ã®å–ã‚Šè¾¼ã¿æ˜ç´°ã‚’è¡¨ç¤º", expanded=False):
        st.dataframe(latest_transactions, use_container_width=True)

tab_api, tab_csv = st.tabs(["APIé€£æº", "CSVè‡ªå‹•å–ã‚Šè¾¼ã¿"])

with tab_api:
    st.write(
        "APIãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç™»éŒ²ã™ã‚‹ã¨ã‚µãƒ³ãƒ—ãƒ«APIã‹ã‚‰æŒ‡å®šæœŸé–“ã®å£²ä¸Šãƒ»åŸä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã™ã€‚"
        " æœ¬ç•ªç’°å¢ƒã§ã¯å„ã‚·ã‚¹ãƒ†ãƒ ã®APIã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    )
    api_system_label = st.radio(
        "é€£æºã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ç¨®åˆ¥",
        options=("ä¼šè¨ˆã‚½ãƒ•ãƒˆ", "POS"),
        horizontal=True,
        key="api_system_type",
    )
    api_source_type = "accounting" if api_system_label == "ä¼šè¨ˆã‚½ãƒ•ãƒˆ" else "pos"
    api_vendor_options = (
        list(SUPPORTED_ACCOUNTING_APPS.keys())
        if api_source_type == "accounting"
        else list(SUPPORTED_POS_SYSTEMS.keys())
    )
    api_vendor = st.selectbox("ã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠ", api_vendor_options, key="api_vendor")
    api_token = st.text_input("APIãƒˆãƒ¼ã‚¯ãƒ³ (ä»»æ„)", value="", type="password")
    today = date.today()
    default_start = today - timedelta(days=6)
    api_period = st.date_input(
        "åŒæœŸæœŸé–“",
        value=(default_start, today),
        key="api_period",
    )
    if isinstance(api_period, (tuple, list)):
        api_start, api_end = api_period
    else:
        api_start = api_end = api_period
    api_frequency_label = st.selectbox(
        "åŒæœŸé »åº¦",
        options=["æ—¥æ¬¡", "é€±æ¬¡", "æœˆæ¬¡"],
        index=0 if api_source_type == "pos" else 2,
        key="api_frequency",
    )
    if st.button("APIã‹ã‚‰åŒæœŸ", key="api_sync_button"):
        config = IntegrationConfig(
            source_type=api_source_type,
            vendor=api_vendor,
            credential_key=api_token or None,
            schedule={"æ—¥æ¬¡": "daily", "é€±æ¬¡": "weekly", "æœˆæ¬¡": "monthly"}.get(
                api_frequency_label, "daily"
            ),
        )
        try:
            transactions = load_transactions_for_sync(
                config, start_date=api_start, end_date=api_end
            )
        except FileNotFoundError:
            st.error(
                "ã‚µãƒ³ãƒ—ãƒ«APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚CSVå–ã‚Šè¾¼ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
            )
        except ValueError as exc:
            st.error(str(exc))
        else:
            summary = summarize_transactions(transactions)
            if summary.empty:
                st.warning("åŒæœŸå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æœŸé–“ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
            else:
                updated_df = apply_transaction_summary_to_products(
                    df_products,
                    summary,
                    vendor=api_vendor,
                    synced_at=datetime.now(),
                )
                st.session_state["df_products_raw"] = updated_df
                st.session_state["external_sync_last_summary"] = summary.to_dict(
                    "records"
                )
                st.session_state["external_sync_last_transactions"] = (
                    transactions.head(500).reset_index(drop=True)
                )
                period_start, period_end = extract_transaction_period(transactions)
                st.session_state["external_sync_history"].append(
                    {
                        "synced_at": datetime.now().isoformat(timespec="seconds"),
                        "mode": "API",
                        "source_type": api_system_label,
                        "vendor": api_vendor,
                        "records": int(len(transactions)),
                        "updated_products": int(summary["product_no"].nunique()),
                        "period_start": period_start.isoformat()
                        if period_start
                        else None,
                        "period_end": period_end.isoformat() if period_end else None,
                        "frequency": api_frequency_label,
                    }
                )
                st.session_state["external_sync_feedback"] = {
                    "level": "success",
                    "message": f"{api_vendor}ã‹ã‚‰{int(summary['product_no'].nunique())}ä»¶ã®SKUã‚’åŒæœŸã—ã¾ã—ãŸã€‚",
                }
                st.rerun()

with tab_csv:
    st.write(
        "ãƒ•ã‚©ãƒ«ãƒ€ã«å‡ºåŠ›ã•ã‚ŒãŸCSVã‚’æŒ‡å®šã™ã‚‹ã¨ã€è‡ªå‹•ã§ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è§£æã—æ—¥æ¬¡ãƒ»æœˆæ¬¡ã®æ›´æ–°ã‚’å–ã‚Šè¾¼ã‚ã¾ã™ã€‚"
    )
    csv_system_label = st.radio(
        "å–ã‚Šè¾¼ã¿å…ƒã®ç¨®åˆ¥",
        options=("ä¼šè¨ˆã‚½ãƒ•ãƒˆ", "POS"),
        horizontal=True,
        key="csv_system_type",
    )
    csv_source_type = "accounting" if csv_system_label == "ä¼šè¨ˆã‚½ãƒ•ãƒˆ" else "pos"
    csv_vendor_options = (
        list(SUPPORTED_ACCOUNTING_APPS.keys())
        if csv_source_type == "accounting"
        else list(SUPPORTED_POS_SYSTEMS.keys())
    )
    csv_vendor = st.selectbox("å–è¾¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", csv_vendor_options, key="csv_vendor")
    csv_file = st.file_uploader(
        "å£²ä¸Šãƒ»åŸä¾¡CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"], key="csv_file"
    )
    csv_frequency_label = st.selectbox(
        "æ›´æ–°é »åº¦",
        options=["æ—¥æ¬¡", "é€±æ¬¡", "æœˆæ¬¡"],
        index=0 if csv_source_type == "pos" else 2,
        key="csv_frequency",
    )
    if st.button("CSVã‚’å–ã‚Šè¾¼ã‚€", key="csv_sync_button", disabled=csv_file is None):
        if csv_file is None:
            st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            config = IntegrationConfig(source_type=csv_source_type, vendor=csv_vendor)
            try:
                transactions = load_transactions_for_sync(config, csv_file=csv_file)
            except ValueError as exc:
                st.error(str(exc))
            else:
                summary = summarize_transactions(transactions)
                if summary.empty:
                    st.warning("CSVã«åŒæœŸå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚")
                else:
                    updated_df = apply_transaction_summary_to_products(
                        df_products,
                        summary,
                        vendor=csv_vendor,
                        synced_at=datetime.now(),
                    )
                    st.session_state["df_products_raw"] = updated_df
                    st.session_state["external_sync_last_summary"] = summary.to_dict(
                        "records"
                    )
                    st.session_state["external_sync_last_transactions"] = (
                        transactions.head(500).reset_index(drop=True)
                    )
                    period_start, period_end = extract_transaction_period(transactions)
                    st.session_state["external_sync_history"].append(
                        {
                            "synced_at": datetime.now().isoformat(timespec="seconds"),
                            "mode": "CSV",
                            "source_type": csv_system_label,
                            "vendor": csv_vendor,
                            "records": int(len(transactions)),
                            "updated_products": int(summary["product_no"].nunique()),
                            "period_start": period_start.isoformat()
                            if period_start
                            else None,
                            "period_end": period_end.isoformat()
                            if period_end
                            else None,
                            "frequency": csv_frequency_label,
                        }
                    )
                    st.session_state["external_sync_feedback"] = {
                        "level": "success",
                        "message": f"CSVã‹ã‚‰{int(summary['product_no'].nunique())}ä»¶ã®SKUã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚",
                    }
                    st.rerun()

history = st.session_state.get("external_sync_history", [])
if history:
    history_df = pd.DataFrame(history)
    if not history_df.empty:
        history_df = history_df.sort_values("synced_at", ascending=False)
        st.markdown("**åŒæœŸå±¥æ­´**")
        st.dataframe(history_df, use_container_width=True)

st.success("ä¿å­˜ã—ã¾ã—ãŸã€‚ä¸Šéƒ¨ã®ãƒŠãƒ“ã‹ã‚‰ã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã€ã¸é€²ã‚“ã§ãã ã•ã„ã€‚")

import sys
from pathlib import Path

ROOT_DIR = str(Path(__file__).resolve().parents[1])
if ROOT_DIR not in sys.path:
    sys.path.insert(0, ROOT_DIR)

from datetime import date, datetime, timedelta
from io import BytesIO
from typing import Any, Dict, List

import numpy as np
import pandas as pd
import streamlit as st
from data_integrations import (
    IntegrationConfig,
    SUPPORTED_ACCOUNTING_APPS,
    SUPPORTED_POS_SYSTEMS,
    auto_sync_transactions,
    apply_transaction_summary_to_products,
    extract_transaction_period,
    load_transactions_for_sync,
    summarize_transactions,
)
from utils import (
    generate_product_template,
    get_product_template_guide,
    get_template_field_anchor,
    get_template_field_info,
    infer_category_from_name,
    infer_major_customer,
    list_template_presets,
    parse_hyochin,
    parse_products,
    read_excel_safely,
    validate_product_dataframe,
)
from components import (
    apply_user_theme,
    render_glossary_popover,
    render_help_button,
    render_onboarding,
    render_page_tutorial,
    render_stepper,
    render_sidebar_nav,
)
from offline import (
    mark_restore_notice_shown,
    restore_session_state_from_cache,
    should_show_restore_notice,
    sync_offline_cache,
)


def _format_fermi_value(value: Any) -> str:
    if pd.isna(value):
        return ""
    if isinstance(value, (int, np.integer)):
        return f"{int(value):,}"
    try:
        number = float(value)
    except (TypeError, ValueError):
        return str(value)
    if abs(number - round(number)) < 1e-6:
        return f"{int(round(number)):,}"
    return f"{number:,.2f}"


apply_user_theme()

render_sidebar_nav(page_key="data")

header_col, help_col = st.columns([0.78, 0.22], gap="small")
with header_col:
    st.title("â‘  ãƒ‡ãƒ¼ã‚¿å…¥åŠ› & å–ã‚Šè¾¼ã¿")

render_help_button("data", container=help_col)

render_onboarding()
render_page_tutorial("data")
render_stepper(1)

restored_from_cache = False
if "df_products_raw" not in st.session_state:
    restored_from_cache = restore_session_state_from_cache()

if restored_from_cache and should_show_restore_notice():
    timestamp = st.session_state.get("offline_cache_timestamp")
    if timestamp:
        st.success(f"ãƒ–ãƒ©ã‚¦ã‚¶ã«ä¿å­˜ã—ã¦ã„ãŸ {timestamp} æ™‚ç‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã—ã¾ã—ãŸã€‚")
    else:
        st.success("ãƒ–ãƒ©ã‚¦ã‚¶ã«ä¿å­˜ã—ã¦ã„ãŸç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒã—ã¾ã—ãŸã€‚")
    st.caption("é€šä¿¡ãŒä¸å®‰å®šãªç’°å¢ƒã§ã‚‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰ã€ã‹ã‚‰æœ€æ–°ç‰ˆã‚’æ›´æ–°ã§ãã¾ã™ã€‚")
    mark_restore_notice_shown()

template_header_col, template_help_col = st.columns([0.74, 0.26], gap="small")
with template_header_col:
    st.subheader("Excelãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ")
with template_help_col:
    render_glossary_popover(
        ["å¿…è¦è³ƒç‡", "ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¤ãƒ¼ãƒ–ãƒ³è³ƒç‡", "ä»˜åŠ ä¾¡å€¤/åˆ†"],
        label="é–¢é€£ç”¨èªã®è§£èª¬",
        container=template_help_col,
    )

st.markdown(
    "ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«ã¯å¿…é ˆé …ç›®ã®èª¬æ˜ã¨ã‚µãƒ³ãƒ—ãƒ«å€¤ã€å…¥åŠ›å˜ä½ã‚’è¨˜è¼‰ã—ã¦ã„ã¾ã™ã€‚"
    " è‡ªç¤¾ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã™ã‚‹å‰ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ—åã¨å˜ä½ã‚’å¤‰æ›´ã—ãªã„ã‚ˆã†ã”æ³¨æ„ãã ã•ã„ã€‚"
    " ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«ã¯å¿…é ˆé …ç›®ã®æ¬ æã‚„å˜ä½ã®èª¤ã‚Šã‚’è‡ªå‹•ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚"
)

presets = list_template_presets()
preset_keys = [preset["key"] for preset in presets]
preset_label_map = {preset["key"]: preset["label"] for preset in presets}
default_key = st.session_state.get("template_preset_key", "general")
if default_key not in preset_label_map:
    default_key = "general"
default_index = preset_keys.index(default_key) if default_key in preset_keys else 0
selected_key = st.selectbox(
    "æ¥­ç¨®åˆ¥ã®ã‚µãƒ³ãƒ—ãƒ«å€¤ã‚’é¸æŠ",
    options=preset_keys,
    index=default_index,
    key="template_preset_key",
    format_func=lambda key: preset_label_map.get(key, key),
)
selected_preset = next((preset for preset in presets if preset["key"] == selected_key), presets[0])

if selected_preset.get("description"):
    st.caption(f"æƒ³å®šã‚·ãƒŠãƒªã‚ª: {selected_preset['description']}")

fermi_records = selected_preset.get("fermi_assumptions") or []
if fermi_records:
    fermi_df = pd.DataFrame(fermi_records)
    fermi_display = fermi_df.copy()
    if "æ¨å®šå€¤" in fermi_display.columns:
        fermi_display["æ¨å®šå€¤"] = fermi_display["æ¨å®šå€¤"].apply(_format_fermi_value)
    st.dataframe(fermi_display, use_container_width=True)
    st.caption("â€» æ¨å®šå€¤ã¯ä¸€èˆ¬çš„ãªãƒ•ã‚§ãƒ«ãƒŸæ¨å®šã§ã™ã€‚è‡ªç¤¾ã®å®Ÿç¸¾å€¤ã§ä¸Šæ›¸ãã—ã¦ãã ã•ã„ã€‚")

guide_df = get_product_template_guide()
guide_display = guide_df[["Excelåˆ—å", "èª¬æ˜", "å˜ä½/å½¢å¼", "å¿…é ˆ", "ã‚µãƒ³ãƒ—ãƒ«å€¤"]]
st.dataframe(guide_display, use_container_width=True)

with st.expander("åˆ—åˆ¥ã®è¨˜å…¥ãƒã‚¤ãƒ³ãƒˆã‚’è©³ã—ãè¦‹ã‚‹", expanded=False):
    st.caption("ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ—ã¨åŒã˜é †ç•ªã§è¨˜å…¥æ–¹æ³•ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™ã€‚")
    for row in guide_df.to_dict("records"):
        anchor = row.get("ã‚¢ãƒ³ã‚«ãƒ¼")
        if anchor:
            st.markdown(f"<div id='{anchor}'></div>", unsafe_allow_html=True)
        st.markdown(f"**{row['Excelåˆ—å']}** ({row['å˜ä½/å½¢å¼']})")
        st.caption(row["èª¬æ˜"])
        st.caption(f"ã‚µãƒ³ãƒ—ãƒ«å€¤: {row['ã‚µãƒ³ãƒ—ãƒ«å€¤']}")

template_bytes = generate_product_template(selected_key)
st.download_button(
    "ğŸ“„ è£½å“ãƒã‚¹ã‚¿å…¥åŠ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    data=template_bytes,
    file_name=f"product_master_template_{selected_key}.xlsx",
    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
)

st.caption("â€»ã€æ¨™è³ƒã€ã‚·ãƒ¼ãƒˆã«ã‚‚ã‚µãƒ³ãƒ—ãƒ«å€¤ã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦å®Ÿç¸¾å€¤ã¸ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚")

st.divider()

default_path = "data/sample.xlsx"
file = st.file_uploader("Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆæœªæŒ‡å®šãªã‚‰ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨ï¼‰", type=["xlsx"])

if file is not None or "df_products_raw" not in st.session_state:
    if file is None:
        st.info("ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        xls = read_excel_safely(default_path)
        st.session_state["using_sample_data"] = True
    else:
        xls = read_excel_safely(file)
        st.session_state["using_sample_data"] = False

    if xls is None:
        st.error("Excel èª­è¾¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ãƒ»ã‚·ãƒ¼ãƒˆåã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        st.stop()

    with st.spinner("ã€æ¨™è³ƒã€ã‚’è§£æä¸­..."):
        calc_params, sr_params, warn1 = parse_hyochin(xls)

    with st.spinner("ã€R6.12ã€è£½å“ãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­..."):
        df_products, warn2 = parse_products(xls, sheet_name="R6.12")

    for w in (warn1 + warn2):
        st.warning(w)

    if st.session_state.get("using_sample_data"):
        df_products = df_products.copy()
        if "category" not in df_products.columns or df_products["category"].isna().all():
            df_products["category"] = df_products["product_name"].apply(
                infer_category_from_name
            )
        if "major_customer" not in df_products.columns or df_products["major_customer"].isna().all():
            df_products["major_customer"] = [
                infer_major_customer(no, name)
                for no, name in zip(
                    df_products.get("product_no"), df_products.get("product_name")
                )
            ]
        st.caption(
            "â€» ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã«ã¯è£½å“åã‹ã‚‰æ¨å®šã—ãŸã‚«ãƒ†ã‚´ãƒªãƒ¼ã¨ä¸»è¦é¡§å®¢ã‚’è‡ªå‹•ä»˜ä¸ã—ã¦ã„ã¾ã™ã€‚"
        )

        unit_info = df_products.attrs.get("column_unit_info")
        if not isinstance(unit_info, dict):
            unit_info = {}

        def _ensure_unit(column_key: str, unit_label: str) -> None:
            entry = unit_info.get(column_key)
            if not isinstance(entry, dict):
                entry = {"unit": None, "source": "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿"}
            if not entry.get("unit"):
                entry["unit"] = unit_label
            entry.setdefault("source", "ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿")
            unit_info[column_key] = entry

        sample_unit_defaults = {
            "product_no": "ã‚³ãƒ¼ãƒ‰",
            "product_name": "ãƒ†ã‚­ã‚¹ãƒˆ",
            "actual_unit_price": "å††/å€‹",
            "material_unit_cost": "å††/å€‹",
            "minutes_per_unit": "åˆ†/å€‹",
            "daily_qty": "å€‹/æ—¥",
        }
        for key, unit_label in sample_unit_defaults.items():
            _ensure_unit(key, unit_label)

        df_products.attrs["column_unit_info"] = unit_info

    column_unit_info = df_products.attrs.get("column_unit_info")
    if not isinstance(column_unit_info, dict):
        column_unit_info = {}

    column_labels = {
        "product_no": "è£½å“ç•ªå·",
        "product_name": "è£½å“å",
        "actual_unit_price": "è²©å£²å˜ä¾¡ï¼ˆå††/å€‹ï¼‰",
        "material_unit_cost": "ææ–™è²»ï¼ˆå††/å€‹ï¼‰",
        "minutes_per_unit": "åˆ†/å€‹",
        "daily_qty": "æ—¥ç”£æ•°ï¼ˆå€‹/æ—¥ï¼‰",
        "category": "ã‚«ãƒ†ã‚´ãƒªãƒ¼",
        "major_customer": "ä¸»è¦é¡§å®¢",
        "notes": "å‚™è€ƒ",
    }
    derived_labels = {
        "gp_per_unit": "ç²—åˆ©ï¼ˆå††/å€‹ï¼‰",
        "daily_total_minutes": "æ—¥ç”£åˆè¨ˆæ™‚é–“ï¼ˆåˆ†ï¼‰",
        "daily_va": "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤ï¼ˆå††ï¼‰",
        "va_per_min": "ä»˜åŠ ä¾¡å€¤/åˆ†ï¼ˆå††ï¼‰",
    }
    number_formats = {
        "actual_unit_price": "%.2f",
        "material_unit_cost": "%.2f",
        "minutes_per_unit": "%.2f",
        "daily_qty": "%.0f",
        "gp_per_unit": "%.2f",
        "daily_total_minutes": "%.2f",
        "daily_va": "%.2f",
        "va_per_min": "%.2f",
    }
    derived_help = {
        "gp_per_unit": "è²©å£²å˜ä¾¡âˆ’ææ–™è²»ã§è‡ªå‹•è¨ˆç®—ã•ã‚Œã¾ã™ã€‚",
        "daily_total_minutes": "åˆ†/å€‹Ã—æ—¥ç”£æ•°ã§è‡ªå‹•è¨ˆç®—ã•ã‚Œã¾ã™ã€‚",
        "daily_va": "ç²—åˆ©Ã—æ—¥ç”£æ•°ã§è‡ªå‹•è¨ˆç®—ã•ã‚Œã¾ã™ã€‚",
        "va_per_min": "æ—¥æ¬¡ä»˜åŠ ä¾¡å€¤Ã·åˆè¨ˆæ™‚é–“ã§è‡ªå‹•è¨ˆç®—ã•ã‚Œã¾ã™ã€‚",
    }

    column_config: Dict[str, Any] = {}
    for col, label in column_labels.items():
        if col not in df_products.columns:
            continue
        info = get_template_field_info(label)
        help_text = info.get("èª¬æ˜") if info else None
        if col in {"actual_unit_price", "material_unit_cost", "minutes_per_unit", "daily_qty"}:
            column_config[col] = st.column_config.NumberColumn(
                label,
                help=help_text,
                format=number_formats.get(col),
            )
        else:
            column_config[col] = st.column_config.TextColumn(label, help=help_text)
    for col, label in derived_labels.items():
        if col not in df_products.columns:
            continue
        column_config[col] = st.column_config.NumberColumn(
            label,
            format=number_formats.get(col),
            help=derived_help.get(col),
            disabled=True,
        )

    edited_df = df_products
    with st.expander("ã‚¢ãƒ—ãƒªå†…ã§ç›´æ¥ç·¨é›†ãƒ»è¿½åŠ å…¥åŠ›", expanded=False):
        st.caption(
            "Excelã«æˆ»ã‚‰ãšã«ä¸»è¦åˆ—ã‚’æ›´æ–°ã§ãã¾ã™ã€‚æ•°å€¤ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¨åŒã˜å˜ä½ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        )
        edited_df = st.data_editor(
            df_products,
            num_rows="dynamic",
            use_container_width=True,
            key="inline_products_editor",
            column_config=column_config,
            hide_index=True,
        )
        export_buffer = BytesIO()
        export_df = edited_df.copy()
        export_df.to_excel(export_buffer, index=False, sheet_name="products")
        st.download_button(
            "ç·¨é›†å†…å®¹ã‚’Excelã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ",
            data=export_buffer.getvalue(),
            file_name="edited_products.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    if isinstance(edited_df, pd.DataFrame):
        df_products = edited_df.copy()
    else:
        df_products = pd.DataFrame(edited_df)
    df_products.attrs["column_unit_info"] = column_unit_info

    numeric_cols = [
        "actual_unit_price",
        "material_unit_cost",
        "minutes_per_unit",
        "daily_qty",
        "gp_per_unit",
        "daily_total_minutes",
        "daily_va",
        "va_per_min",
    ]
    for col in numeric_cols:
        if col in df_products.columns:
            df_products[col] = pd.to_numeric(df_products[col], errors="coerce")

    if {"actual_unit_price", "material_unit_cost"}.issubset(df_products.columns):
        df_products["gp_per_unit"] = df_products["actual_unit_price"] - df_products["material_unit_cost"]
    if {"minutes_per_unit", "daily_qty"}.issubset(df_products.columns):
        df_products["daily_total_minutes"] = df_products["minutes_per_unit"] * df_products["daily_qty"]
    if {"gp_per_unit", "daily_qty"}.issubset(df_products.columns):
        df_products["daily_va"] = df_products["gp_per_unit"] * df_products["daily_qty"]
    if {"daily_va", "daily_total_minutes"}.issubset(df_products.columns):
        with np.errstate(divide="ignore", invalid="ignore"):
            df_products["va_per_min"] = df_products["daily_va"] / df_products["daily_total_minutes"].replace(
                {0: np.nan}
            )

    errors, val_warnings, detail_df = validate_product_dataframe(df_products)
    for msg in val_warnings:
        st.warning(msg)
    for msg in errors:
        st.error(msg)

    if not detail_df.empty:
        level_map = {"ã‚¨ãƒ©ãƒ¼": "è‡´å‘½çš„", "è­¦å‘Š": "æ³¨æ„"}
        display_df = detail_df.copy()
        display_df["é‡è¦åº¦"] = display_df["ãƒ¬ãƒ™ãƒ«"].map(level_map).fillna(display_df["ãƒ¬ãƒ™ãƒ«"])
        display_df["Excelåˆ—"] = display_df["é …ç›®"].map(
            lambda label: (info := get_template_field_info(label)) and info.get("excel_column")
        )
        display_df["å…¥åŠ›ã‚¬ã‚¤ãƒ‰"] = display_df["é …ç›®"].map(
            lambda label: get_template_field_anchor(label) or ""
        )
        display_df = display_df.drop(columns=["ãƒ¬ãƒ™ãƒ«"])
        ordered_columns = [
            "é‡è¦åº¦",
            "è£½å“ç•ªå·",
            "è£½å“å",
            "é …ç›®",
            "Excelåˆ—",
            "åŸå› /çŠ¶æ³",
            "å…¥åŠ›å€¤",
            "å¯¾å‡¦æ–¹æ³•",
            "å…¥åŠ›ã‚¬ã‚¤ãƒ‰",
        ]
        display_df = display_df[[col for col in ordered_columns if col in display_df.columns]]

        def _highlight_issue(row: pd.Series) -> List[str]:
            level = row.get("é‡è¦åº¦")
            color = "#FDEAEA" if level == "è‡´å‘½çš„" else "#FFF7E1"
            return [f"background-color: {color}"] * len(row)

        def _format_anchor_cell(anchor: str) -> str:
            if not anchor:
                return "â€•"
            return f'<a href="#{anchor}">ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆåˆ—ã¸ç§»å‹•</a>'

        styled = display_df.style.apply(_highlight_issue, axis=1).format(
            {"å…¥åŠ›ã‚¬ã‚¤ãƒ‰": _format_anchor_cell}, escape=False
        )
        with st.expander("æ¤œçŸ¥ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å“è³ªã‚¢ãƒ©ãƒ¼ãƒˆã®è©³ç´°", expanded=bool(errors)):
            st.caption("è‡´å‘½çš„ãªé …ç›®ã¯èµ¤ã€æ³¨æ„é …ç›®ã¯é»„ã§ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¦ã„ã¾ã™ã€‚")
            st.markdown(styled.to_html(index=False), unsafe_allow_html=True)
            option_labels = [
                f"{row.get('é‡è¦åº¦', '-') } | {row.get('é …ç›®', '-') } | {row.get('è£½å“ç•ªå·', 'å…¨ä½“')}"
                for row in display_df.to_dict("records")
            ]
            if option_labels:
                with st.popover("ğŸ› ï¸ ä¿®æ­£ãƒ’ãƒ³ãƒˆã‚’ç¢ºèª"):
                    st.caption("å¯¾è±¡è¡Œã‚’é¸ã¶ã¨åŸå› ã¨ä¿®æ­£æ–¹æ³•ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                    selected_index = st.selectbox(
                        "å¯¾è±¡è¡Œ",
                        options=list(range(len(option_labels))),
                        format_func=lambda idx: option_labels[idx],
                    )
                    issue_row = detail_df.iloc[int(selected_index)]
                    st.markdown(
                        f"**å¯¾è±¡è£½å“:** {issue_row.get('è£½å“ç•ªå·', 'å…¨ä½“')} {issue_row.get('è£½å“å', '')}"
                    )
                    st.markdown(f"**åŸå› /çŠ¶æ³:** {issue_row.get('åŸå› /çŠ¶æ³')}")
                    st.markdown(f"**å¯¾å‡¦æ–¹æ³•:** {issue_row.get('å¯¾å‡¦æ–¹æ³•')}")
                    anchor = get_template_field_anchor(issue_row.get("é …ç›®", ""))
                    info = get_template_field_info(issue_row.get("é …ç›®", ""))
                    if anchor:
                        label_text = info.get("excel_column") if info else issue_row.get("é …ç›®")
                        st.markdown(f"[ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€{label_text}ã€ã®èª¬æ˜ã«ç§»å‹•](#{anchor})")

    if errors:
        st.stop()
    elif not val_warnings:
        st.success("ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯ã‚’é€šéã—ã¾ã—ãŸã€‚")

    st.session_state["sr_params"] = sr_params
    st.session_state["df_products_raw"] = df_products
    st.session_state["calc_params"] = calc_params
else:
    sr_params = st.session_state["sr_params"]
    df_products = st.session_state["df_products_raw"]
    calc_params = st.session_state.get("calc_params", {})

if "scenarios" not in st.session_state:
    st.session_state["scenarios"] = {"ãƒ™ãƒ¼ã‚¹": sr_params.copy()}
    st.session_state["current_scenario"] = "ãƒ™ãƒ¼ã‚¹"
else:
    st.session_state["scenarios"]["ãƒ™ãƒ¼ã‚¹"] = sr_params.copy()
if "current_scenario" not in st.session_state:
    st.session_state["current_scenario"] = "ãƒ™ãƒ¼ã‚¹"

st.session_state.setdefault("external_sync_history", [])
st.session_state.setdefault("external_sync_last_summary", [])
st.session_state.setdefault("external_sync_last_transactions", None)
st.session_state.setdefault("external_sync_last_run_logs", [])

st.caption(f"é©ç”¨ä¸­ã‚·ãƒŠãƒªã‚ª: {st.session_state['current_scenario']}")

c1, c2, c3 = st.columns(3)
c1.metric("å›ºå®šè²»è¨ˆ (åƒå††/å¹´)", f"{calc_params.get('fixed_total', 0)/1000:,.0f}")
c2.metric("å¿…è¦åˆ©ç›Šè¨ˆ (åƒå††/å¹´)", f"{calc_params.get('required_profit_total', 0)/1000:,.0f}")
c3.metric("å¹´é–“æ¨™æº–ç¨¼åƒåˆ† (åˆ†/å¹´)", f"{calc_params.get('annual_minutes', 0):,.0f}")

st.divider()
st.subheader("è£½å“ãƒ‡ãƒ¼ã‚¿")
keyword = st.text_input("è£½å“ç•ªå·ã¾ãŸã¯åç§°ã§æ¤œç´¢", "")
if keyword:
    mask = (
        df_products["product_no"].astype(str).str.contains(keyword, regex=False)
        | df_products["product_name"].astype(str).str.contains(keyword, regex=False)
    )
    df_view = df_products[mask]
else:
    df_view = df_products
st.dataframe(df_view, use_container_width=True)

with st.expander("æ–°è¦è£½å“ã‚’è¿½åŠ ", expanded=False):
    with st.form("add_product_form"):
        col_a, col_b = st.columns(2)
        product_no = col_a.text_input("è£½å“ç•ªå·", "")
        product_name = col_b.text_input("è£½å“å", "")
        actual_unit_price = st.number_input("å®Ÿéš›å£²å˜ä¾¡", value=0.0, step=1.0)
        material_unit_cost = st.number_input("ææ–™åŸä¾¡", value=0.0, step=1.0)
        minutes_per_unit = st.number_input("åˆ†/å€‹", value=0.0, step=0.1)
        daily_qty = st.number_input("æ—¥ç”£æ•°", value=0.0, step=1.0)
        col_c, col_d = st.columns(2)
        category = col_c.text_input("ã‚«ãƒ†ã‚´ãƒªãƒ¼", "")
        major_customer = col_d.text_input("ä¸»è¦é¡§å®¢", "")
        submitted = st.form_submit_button("è¿½åŠ ")
    if submitted:
        gp_per_unit = actual_unit_price - material_unit_cost
        daily_total_minutes = minutes_per_unit * daily_qty
        daily_va = gp_per_unit * daily_qty
        va_per_min = daily_va / daily_total_minutes if daily_total_minutes else 0.0
        new_row = {
            "product_no": product_no,
            "product_name": product_name,
            "actual_unit_price": actual_unit_price,
            "material_unit_cost": material_unit_cost,
            "minutes_per_unit": minutes_per_unit,
            "daily_qty": daily_qty,
            "daily_total_minutes": daily_total_minutes,
            "gp_per_unit": gp_per_unit,
            "daily_va": daily_va,
            "va_per_min": va_per_min,
            "category": category,
            "major_customer": major_customer,
        }
        df_products = pd.concat([df_products, pd.DataFrame([new_row])], ignore_index=True)
        st.session_state["df_products_raw"] = df_products
        st.success("è£½å“ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
        st.rerun()

st.divider()
st.subheader("ç”Ÿç”£ãƒ»è²©å£²ã‚·ã‚¹ãƒ†ãƒ ã¨ã®ãƒ‡ãƒ¼ã‚¿é€£æº")
st.caption(
    "å¼¥ç”Ÿä¼šè¨ˆã‚„freeeãªã©ã®ä¼šè¨ˆã‚½ãƒ•ãƒˆã€POSã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å£²ä¸Šãƒ»åŸä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸã—ã€"
    "æœ€æ–°ã®è£½å“æŒ‡æ¨™ã‚’è‡ªå‹•åæ˜ ã§ãã¾ã™ã€‚"
)

feedback = st.session_state.pop("external_sync_feedback", None)
if feedback:
    level = feedback.get("level", "info")
    message = feedback.get("message", "")
    display = getattr(st, level, st.info)
    if message:
        display(message)

latest_summary_records = st.session_state.get("external_sync_last_summary") or []
if latest_summary_records:
    latest_summary_df = pd.DataFrame(latest_summary_records)
    if not latest_summary_df.empty:
        st.markdown("**ç›´è¿‘ã®åŒæœŸçµæœï¼ˆSKUåˆ¥é›†è¨ˆï¼‰**")
        st.dataframe(latest_summary_df, use_container_width=True)

latest_transactions = st.session_state.get("external_sync_last_transactions")
if isinstance(latest_transactions, pd.DataFrame) and not latest_transactions.empty:
    with st.expander("ç›´è¿‘ã®å–ã‚Šè¾¼ã¿æ˜ç´°ã‚’è¡¨ç¤º", expanded=False):
        st.dataframe(latest_transactions, use_container_width=True)

latest_run_logs = st.session_state.get("external_sync_last_run_logs") or []
if latest_run_logs:
    log_df = pd.DataFrame(latest_run_logs)
    if not log_df.empty:
        st.markdown("**å–ã‚Šè¾¼ã¿ã‚·ã‚¹ãƒ†ãƒ åˆ¥ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**")
        st.dataframe(log_df, use_container_width=True)

tab_api, tab_csv = st.tabs(["APIé€£æº", "CSVè‡ªå‹•å–ã‚Šè¾¼ã¿"])

with tab_api:
    st.write(
        "APIãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç™»éŒ²ã™ã‚‹ã¨ã‚µãƒ³ãƒ—ãƒ«APIã‹ã‚‰æŒ‡å®šæœŸé–“ã®å£²ä¸Šãƒ»åŸä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã™ã€‚"
        " æœ¬ç•ªç’°å¢ƒã§ã¯å„ã‚·ã‚¹ãƒ†ãƒ ã®APIã‚¯ãƒ¬ãƒ‡ãƒ³ã‚·ãƒ£ãƒ«ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
    )
    api_system_label = st.radio(
        "é€£æºã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã®ç¨®åˆ¥",
        options=("ä¼šè¨ˆã‚½ãƒ•ãƒˆ", "POS"),
        horizontal=True,
        key="api_system_type",
    )
    api_source_type = "accounting" if api_system_label == "ä¼šè¨ˆã‚½ãƒ•ãƒˆ" else "pos"
    api_vendor_options = (
        list(SUPPORTED_ACCOUNTING_APPS.keys())
        if api_source_type == "accounting"
        else list(SUPPORTED_POS_SYSTEMS.keys())
    )
    api_vendor = st.selectbox("ã‚µãƒ¼ãƒ“ã‚¹ã‚’é¸æŠ", api_vendor_options, key="api_vendor")
    api_token = st.text_input("APIãƒˆãƒ¼ã‚¯ãƒ³ (ä»»æ„)", value="", type="password")
    today = date.today()
    default_start = today - timedelta(days=6)
    api_period = st.date_input(
        "åŒæœŸæœŸé–“",
        value=(default_start, today),
        key="api_period",
    )
    if isinstance(api_period, (tuple, list)):
        api_start, api_end = api_period
    else:
        api_start = api_end = api_period
    api_frequency_label = st.selectbox(
        "åŒæœŸé »åº¦",
        options=["æ—¥æ¬¡", "é€±æ¬¡", "æœˆæ¬¡"],
        index=0 if api_source_type == "pos" else 2,
        key="api_frequency",
    )
    if st.button("APIã‹ã‚‰åŒæœŸ", key="api_sync_button"):
        config = IntegrationConfig(
            source_type=api_source_type,
            vendor=api_vendor,
            credential_key=api_token or None,
            schedule={"æ—¥æ¬¡": "daily", "é€±æ¬¡": "weekly", "æœˆæ¬¡": "monthly"}.get(
                api_frequency_label, "daily"
            ),
        )
        try:
            transactions = load_transactions_for_sync(
                config, start_date=api_start, end_date=api_end
            )
        except FileNotFoundError:
            st.error(
                "ã‚µãƒ³ãƒ—ãƒ«APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚CSVå–ã‚Šè¾¼ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
            )
            st.session_state["external_sync_last_run_logs"] = []
        except ValueError as exc:
            st.error(str(exc))
            st.session_state["external_sync_last_run_logs"] = []
        else:
            summary = summarize_transactions(transactions)
            if summary.empty:
                st.warning("åŒæœŸå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æœŸé–“ã‚’è¦‹ç›´ã—ã¦ãã ã•ã„ã€‚")
                st.session_state["external_sync_last_run_logs"] = []
            else:
                updated_df = apply_transaction_summary_to_products(
                    df_products,
                    summary,
                    vendor=api_vendor,
                    synced_at=datetime.now(),
                )
                st.session_state["df_products_raw"] = updated_df
                st.session_state["external_sync_last_summary"] = summary.to_dict(
                    "records"
                )
                st.session_state["external_sync_last_transactions"] = (
                    transactions.head(500).reset_index(drop=True)
                )
                st.session_state["external_sync_last_run_logs"] = [
                    {
                        "vendor": api_vendor,
                        "source_type": api_source_type,
                        "schedule": config.schedule,
                        "status": "success",
                        "records": int(len(transactions)),
                        "period_start": api_start.isoformat()
                        if isinstance(api_start, date)
                        else None,
                        "period_end": api_end.isoformat()
                        if isinstance(api_end, date)
                        else None,
                    }
                ]
                period_start, period_end = extract_transaction_period(transactions)
                st.session_state["external_sync_history"].append(
                    {
                        "synced_at": datetime.now().isoformat(timespec="seconds"),
                        "mode": "API",
                        "source_type": api_system_label,
                        "vendor": api_vendor,
                        "records": int(len(transactions)),
                        "updated_products": int(summary["product_no"].nunique()),
                        "period_start": period_start.isoformat()
                        if period_start
                        else None,
                        "period_end": period_end.isoformat() if period_end else None,
                        "frequency": api_frequency_label,
                    }
                )
                st.session_state["external_sync_feedback"] = {
                    "level": "success",
                    "message": f"{api_vendor}ã‹ã‚‰{int(summary['product_no'].nunique())}ä»¶ã®SKUã‚’åŒæœŸã—ã¾ã—ãŸã€‚",
                }
                st.rerun()

    st.divider()
    st.markdown("### æ—¥æ¬¡è‡ªå‹•å–å¾—")
    st.caption(
        "å¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ã‚’ã¾ã¨ã‚ã¦æŒ‡å®šã™ã‚‹ã¨ã€é¸æŠæœŸé–“ã®å£²ä¸Šãƒ»åŸä¾¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€æ‹¬å–å¾—ã—ã¾ã™ã€‚"
        " ã‚¯ãƒ©ã‚¦ãƒ‰é€£æºã§æ‰‹å‹•å…¥åŠ›ã‚’æ¸›ã‚‰ã—ã€å¸¸ã«æœ€æ–°ã®å®Ÿç¸¾ã§åˆ†æã§ãã¾ã™ã€‚"
    )

    auto_accounting_targets = st.multiselect(
        "å¯¾è±¡ã®ä¼šè¨ˆã‚½ãƒ•ãƒˆ",
        options=list(SUPPORTED_ACCOUNTING_APPS.keys()),
        default=list(SUPPORTED_ACCOUNTING_APPS.keys()),
        key="auto_accounting_targets",
    )
    auto_pos_targets = st.multiselect(
        "å¯¾è±¡ã®POSã‚·ã‚¹ãƒ†ãƒ ",
        options=list(SUPPORTED_POS_SYSTEMS.keys()),
        default=list(SUPPORTED_POS_SYSTEMS.keys()),
        key="auto_pos_targets",
    )
    auto_days = st.slider(
        "å–å¾—æœŸé–“ï¼ˆæ—¥æ•°ï¼‰",
        min_value=1,
        max_value=31,
        value=7,
        help="é€šå¸¸ã¯ç›´è¿‘7æ—¥é–“ã‚’å–å¾—ã—ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦æ—¥æ•°ã‚’èª¿æ•´ã—ã¦ãã ã•ã„ã€‚",
        key="auto_days",
    )
    if st.button("é¸æŠã—ãŸã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰è‡ªå‹•å–å¾—", key="auto_sync_button"):
        targets: list[IntegrationConfig] = []
        for vendor in auto_accounting_targets:
            targets.append(
                IntegrationConfig(
                    source_type="accounting",
                    vendor=vendor,
                    schedule="daily",
                )
            )
        for vendor in auto_pos_targets:
            targets.append(
                IntegrationConfig(
                    source_type="pos",
                    vendor=vendor,
                    schedule="daily",
                )
            )

        if not targets:
            st.warning("è‡ªå‹•å–å¾—ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            auto_end = today
            auto_start = today - timedelta(days=int(auto_days) - 1)
            try:
                result = auto_sync_transactions(
                    targets, start_date=auto_start, end_date=auto_end
                )
            except ValueError as exc:
                st.error(str(exc))
            else:
                transactions = result.transactions
                summary = result.summary
                st.session_state["external_sync_last_run_logs"] = result.logs

                if summary.empty or transactions.empty:
                    st.warning(
                        "é¸æŠã—ãŸæœŸé–“ãƒ»ã‚·ã‚¹ãƒ†ãƒ ã«åŒæœŸå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
                    )
                else:
                    updated_df = apply_transaction_summary_to_products(
                        df_products,
                        summary,
                        vendor="è‡ªå‹•åŒæœŸ",
                        synced_at=datetime.now(),
                    )
                    st.session_state["df_products_raw"] = updated_df
                    st.session_state["external_sync_last_summary"] = summary.to_dict(
                        "records"
                    )
                    st.session_state["external_sync_last_transactions"] = (
                        transactions.head(500).reset_index(drop=True)
                    )
                    period_start, period_end = extract_transaction_period(transactions)
                    joined_vendors = ", ".join(
                        log["vendor"]
                        for log in result.logs
                        if log.get("status") == "success"
                    ) or "å¯¾è±¡ãªã—"
                    st.session_state["external_sync_history"].append(
                        {
                            "synced_at": datetime.now().isoformat(timespec="seconds"),
                            "mode": "AUTO",
                            "source_type": "è‡ªå‹•é€£æº",
                            "vendor": joined_vendors,
                            "records": int(len(transactions)),
                            "updated_products": int(
                                summary["product_no"].nunique()
                            ),
                            "period_start": period_start.isoformat()
                            if period_start
                            else None,
                            "period_end": period_end.isoformat()
                            if period_end
                            else None,
                            "frequency": "æ—¥æ¬¡",
                        }
                    )
                    st.session_state["external_sync_feedback"] = {
                        "level": "success",
                        "message": (
                            f"{joined_vendors}ã‹ã‚‰{int(summary['product_no'].nunique())}ä»¶ã®SKUã‚’"
                            "è‡ªå‹•æ›´æ–°ã—ã¾ã—ãŸã€‚"
                        ),
                    }
                    st.rerun()

with tab_csv:
    st.write(
        "ãƒ•ã‚©ãƒ«ãƒ€ã«å‡ºåŠ›ã•ã‚ŒãŸCSVã‚’æŒ‡å®šã™ã‚‹ã¨ã€è‡ªå‹•ã§ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è§£æã—æ—¥æ¬¡ãƒ»æœˆæ¬¡ã®æ›´æ–°ã‚’å–ã‚Šè¾¼ã‚ã¾ã™ã€‚"
    )
    csv_system_label = st.radio(
        "å–ã‚Šè¾¼ã¿å…ƒã®ç¨®åˆ¥",
        options=("ä¼šè¨ˆã‚½ãƒ•ãƒˆ", "POS"),
        horizontal=True,
        key="csv_system_type",
    )
    csv_source_type = "accounting" if csv_system_label == "ä¼šè¨ˆã‚½ãƒ•ãƒˆ" else "pos"
    csv_vendor_options = (
        list(SUPPORTED_ACCOUNTING_APPS.keys())
        if csv_source_type == "accounting"
        else list(SUPPORTED_POS_SYSTEMS.keys())
    )
    csv_vendor = st.selectbox("å–è¾¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ", csv_vendor_options, key="csv_vendor")
    csv_file = st.file_uploader(
        "å£²ä¸Šãƒ»åŸä¾¡CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"], key="csv_file"
    )
    csv_frequency_label = st.selectbox(
        "æ›´æ–°é »åº¦",
        options=["æ—¥æ¬¡", "é€±æ¬¡", "æœˆæ¬¡"],
        index=0 if csv_source_type == "pos" else 2,
        key="csv_frequency",
    )
    if st.button("CSVã‚’å–ã‚Šè¾¼ã‚€", key="csv_sync_button", disabled=csv_file is None):
        if csv_file is None:
            st.error("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            config = IntegrationConfig(source_type=csv_source_type, vendor=csv_vendor)
            try:
                transactions = load_transactions_for_sync(config, csv_file=csv_file)
            except ValueError as exc:
                st.error(str(exc))
                st.session_state["external_sync_last_run_logs"] = []
            else:
                summary = summarize_transactions(transactions)
                if summary.empty:
                    st.warning("CSVã«åŒæœŸå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.session_state["external_sync_last_run_logs"] = []
                else:
                    updated_df = apply_transaction_summary_to_products(
                        df_products,
                        summary,
                        vendor=csv_vendor,
                        synced_at=datetime.now(),
                    )
                    st.session_state["df_products_raw"] = updated_df
                    st.session_state["external_sync_last_summary"] = summary.to_dict(
                        "records"
                    )
                    st.session_state["external_sync_last_transactions"] = (
                        transactions.head(500).reset_index(drop=True)
                    )
                    st.session_state["external_sync_last_run_logs"] = [
                        {
                            "vendor": csv_vendor,
                            "source_type": csv_source_type,
                            "schedule": config.schedule,
                            "status": "success",
                            "records": int(len(transactions)),
                        }
                    ]
                    period_start, period_end = extract_transaction_period(transactions)
                    st.session_state["external_sync_history"].append(
                        {
                            "synced_at": datetime.now().isoformat(timespec="seconds"),
                            "mode": "CSV",
                            "source_type": csv_system_label,
                            "vendor": csv_vendor,
                            "records": int(len(transactions)),
                            "updated_products": int(summary["product_no"].nunique()),
                            "period_start": period_start.isoformat()
                            if period_start
                            else None,
                            "period_end": period_end.isoformat()
                            if period_end
                            else None,
                            "frequency": csv_frequency_label,
                        }
                    )
                    st.session_state["external_sync_feedback"] = {
                        "level": "success",
                        "message": f"CSVã‹ã‚‰{int(summary['product_no'].nunique())}ä»¶ã®SKUã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚",
                    }
                    st.rerun()

history = st.session_state.get("external_sync_history", [])
if history:
    history_df = pd.DataFrame(history)
    if not history_df.empty:
        history_df = history_df.sort_values("synced_at", ascending=False)
        st.markdown("**åŒæœŸå±¥æ­´**")
        st.dataframe(history_df, use_container_width=True)

st.success("ä¿å­˜ã—ã¾ã—ãŸã€‚ä¸Šéƒ¨ã®ãƒŠãƒ“ã‹ã‚‰ã€ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã€ã¸é€²ã‚“ã§ãã ã•ã„ã€‚")

sync_offline_cache()
